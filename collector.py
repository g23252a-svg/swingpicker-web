# -*- coding: utf-8 -*-
"""
LDY Pro Trader: Nightly Collector (KRX)
- ë§¤ì¼ ì¥ë§ˆê° í›„: ìœ ë™ì„± ìƒìœ„(TV ìƒìœ„) ì¢…ëª© nê°œ ì„ ì •
- ê° ì¢…ëª© 60ê±°ë˜ì¼ OHLCV ìˆ˜ì§‘ í›„ ë‹¹ì¼ ìŠ¤ëƒ…ìƒ· ì§€í‘œ/ì ìˆ˜(EBS) ê³„ì‚°
- ì¶”ì²œë§¤ìˆ˜/ë§¤ë„/ì†ì ˆ ê°€ê²© ì»¬ëŸ¼ê¹Œì§€ í¬í•¨í•œ CSV ì €ì¥
- data/krx_codes.csv(ì¢…ëª©ëª… ë§µ) ìƒì„± ë° ë³‘í•©
"""

import os
import time
import math
import numpy as np
import pandas as pd
from datetime import datetime, timedelta, timezone
from pykrx import stock

# ------------------------------- ì„¤ì • -------------------------------
KST = timezone(timedelta(hours=9))
LOOKBACK_DAYS = 60         # ì¡°íšŒì¼ìˆ˜
TOP_N = 600                # ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ìƒ˜í”Œ í¬ê¸°(300~800 ê¶Œì¥)
MIN_TURNOVER_EOK = 50      # ê±°ë˜ëŒ€ê¸ˆ í•˜í•œ(ì–µì›)
MIN_MCAP_EOK = 1000        # ì‹œì´ í•˜í•œ(ì–µì›)
RSI_LOW, RSI_HIGH = 45, 65 # RSI ë²”ìœ„
PASS_SCORE = 4             # í†µê³¼ì ìˆ˜(ìµœì¢… EBS)
SLEEP_SEC = 0.02           # API call ê°„ ì§§ì€ ë”œë ˆì´
OUT_DIR = "data"

# ------------------------------- ìœ í‹¸ -------------------------------
def log(msg: str):
    print(f"[{datetime.now(KST)}] {msg}")

def ensure_dir(path: str):
    os.makedirs(path, exist_ok=True)

def ema(s, span):
    return s.ewm(span=span, adjust=False).mean()

def calc_rsi(close: pd.Series, period: int = 14):
    delta = close.diff()
    up = delta.clip(lower=0)
    down = -delta.clip(upper=0)
    ma_up = up.rolling(period).mean()
    ma_down = down.rolling(period).mean()
    rs = ma_up / (ma_down.replace(0, np.nan))
    rsi = 100 - 100 / (1 + rs)
    return rsi

def calc_atr(high, low, close, period: int = 14):
    prev_close = close.shift(1)
    tr = pd.concat([
        (high - low),
        (high - prev_close).abs(),
        (low - prev_close).abs()
    ], axis=1).max(axis=1)
    atr = tr.rolling(period).mean()
    return atr

def round_to_tick(price: float) -> int:
    # ê°„ë‹¨í•œ í‹±(10ì› ë‹¨ìœ„) ë°˜ì˜¬ë¦¼
    return int(round(price / 10.0) * 10)

# ------------------------------- ì¢…ëª©ëª… ë§µ ìƒì„± -------------------------------
def build_name_map_and_save():
    """
    data/krx_codes.csv ìƒì„±:
      ì¢…ëª©ì½”ë“œ, ì¢…ëª©ëª…, ì‹œì¥(KOSPI/KOSDAQ/KONEX)
    """
    try:
        today = datetime.now(KST).strftime("%Y%m%d")
        codes = []
        for m in ["KOSPI", "KOSDAQ", "KONEX"]:
            try:
                lst = stock.get_market_ticker_list(today, market=m)
                codes.extend([(str(c).zfill(6), m) for c in lst])
            except Exception:
                pass

        rows = []
        for t, m in codes:
            try:
                nm = stock.get_market_ticker_name(t)
            except Exception:
                nm = None
            rows.append({"ì¢…ëª©ì½”ë“œ": t, "ì¢…ëª©ëª…": nm, "ì‹œì¥": m})
            time.sleep(0.005)  # ê³¼ë‹¤í˜¸ì¶œ ë°©ì§€

        ensure_dir(OUT_DIR)
        pd.DataFrame(rows).drop_duplicates("ì¢…ëª©ì½”ë“œ").to_csv(
            os.path.join(OUT_DIR, "krx_codes.csv"),
            index=False, encoding="utf-8-sig"
        )
        log("ğŸ·ï¸ ì½”ë“œë§µ ìƒì„± ì™„ë£Œ â†’ data/krx_codes.csv")
    except Exception as e:
        log(f"ì½”ë“œë§µ ìƒì„± ì‹¤íŒ¨(ë¬´ì‹œ ê°€ëŠ¥): {e}")

def load_name_map() -> pd.DataFrame:
    """
    data/krx_codes.csv ì½ê¸°. ì—†ìœ¼ë©´ ìƒì„± ì‹œë„ í›„ ì½ê¸°.
    """
    ensure_dir(OUT_DIR)
    path = os.path.join(OUT_DIR, "krx_codes.csv")
    if not os.path.exists(path):
        log("ğŸ·ï¸ ì½”ë“œë§µ ìƒì„±/ë¡œë”©â€¦")
        build_name_map_and_save()
    try:
        nm = pd.read_csv(path, dtype={"ì¢…ëª©ì½”ë“œ": str})
        nm["ì¢…ëª©ì½”ë“œ"] = nm["ì¢…ëª©ì½”ë“œ"].str.zfill(6)
        return nm
    except Exception as e:
        log(f"ì½”ë“œë§µ ë¡œë“œ ì‹¤íŒ¨: {e}")
        # ë¹„ìƒìš© ë¹ˆ DF
        return pd.DataFrame(columns=["ì¢…ëª©ì½”ë“œ", "ì¢…ëª©ëª…", "ì‹œì¥"])

# ------------------------------- ìƒìœ„ ê±°ë˜ëŒ€ê¸ˆ ì¶”ì¶œ -------------------------------
def pick_top_by_trading_value(date_yyyymmdd: str, top_n: int) -> pd.DataFrame:
    """
    íˆ¬ìì£¼ì²´ë³„ ë§¤ë§¤ê¸ˆì•¡ by 'ì „ì²´ ì‹œì¥' ìŠ¤ëƒ…ìƒ·ì—ì„œ ìƒìœ„ ì¶”ì¶œ.
    ì¼ë¶€ pykrx ë²„ì „ì€ 2-argë¡œ ë™ì‘. (start, end)
    ë°˜í™˜: ['ì¢…ëª©ì½”ë“œ','ê±°ë˜ëŒ€ê¸ˆ(ì›)']
    """
    # ê¸°ë³¸ ì‹œë„ (ê³¼ê±° ì„±ê³µ ë¡œê·¸ ê¸°ë°˜)
    try:
        tv = stock.get_market_trading_value_by_date(date_yyyymmdd, date_yyyymmdd)
    except TypeError:
        # í™˜ê²½ì— ë”°ë¼ ì‹œê·¸ë‹ˆì²˜ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë©”ì‹œì§€ ë‚¨ê¸°ê³  ì¬ì‹œë„ ë¶ˆê°€ ì²˜ë¦¬
        raise RuntimeError("pykrx.get_market_trading_value_by_date ì‹œê·¸ë‹ˆì²˜ê°€ ë‹¤ë¥¸ í™˜ê²½ì…ë‹ˆë‹¤. "
                           "pykrx==1.0.51ì„ ìœ ì§€í•˜ì„¸ìš”.")

    tv = tv.reset_index()
    # ì»¬ëŸ¼ëª… ë³´ì •
    if "í‹°ì»¤" in tv.columns and "ì¢…ëª©ì½”ë“œ" not in tv.columns:
        tv = tv.rename(columns={"í‹°ì»¤": "ì¢…ëª©ì½”ë“œ"}, errors="ignore")
    if "ì¢…ëª©ì½”ë“œ" not in tv.columns:
        # indexë¡œ ë“¤ì–´ì˜¨ ê²½ìš°
        if "index" in tv.columns:
            tv = tv.rename(columns={"index": "ì¢…ëª©ì½”ë“œ"})
        else:
            tv.insert(0, "ì¢…ëª©ì½”ë“œ", tv.index)

    tv["ì¢…ëª©ì½”ë“œ"] = tv["ì¢…ëª©ì½”ë“œ"].astype(str).str.zfill(6)

    # 'ì „ì²´' í•©ì´ ì—†ìœ¼ë©´ í•©ì‚°
    if "ì „ì²´" not in tv.columns:
        value_cols = [c for c in tv.columns if c not in ["ì¢…ëª©ì½”ë“œ"]]
        tv["ì „ì²´"] = tv[value_cols].sum(axis=1)

    out = tv[["ì¢…ëª©ì½”ë“œ", "ì „ì²´"]].rename(columns={"ì „ì²´": "ê±°ë˜ëŒ€ê¸ˆ(ì›)"})
    out = out.sort_values("ê±°ë˜ëŒ€ê¸ˆ(ì›)", ascending=False).head(top_n).reset_index(drop=True)
    return out

def get_market_sets(date_yyyymmdd: str):
    kospi = set(stock.get_market_ticker_list(date_yyyymmdd, market="KOSPI"))
    kosdaq = set(stock.get_market_ticker_list(date_yyyymmdd, market="KOSDAQ"))
    kospi = set(str(x).zfill(6) for x in kospi)
    kosdaq = set(str(x).zfill(6) for x in kosdaq)
    return kospi, kosdaq

def get_mcap_eok(date_yyyymmdd: str, ticker: str) -> float:
    try:
        cap = stock.get_market_cap_by_date(date_yyyymmdd, date_yyyymmdd, ticker)
        return float(cap["ì‹œê°€ì´ì•¡"].iloc[0]) / 1e8
    except Exception:
        return np.nan

# ------------------------------- ë©”ì¸ ë¡œì§ -------------------------------
def main():
    log("ì „ì¢…ëª© ìˆ˜ì§‘ ì‹œì‘â€¦")

    # ê¸°ì¤€ì¼(ì˜ì—…ì¼) ê³ ì •: ì˜¤ëŠ˜ 17ì‹œ ì´í›„ë©´ ì˜¤ëŠ˜, ê·¸ ì „ì´ë©´ ì „ì˜ì—…ì¼ ì¶”ì •
    now = datetime.now(KST)
    end_dt = now
    # pykrxê°€ ê³µíœ´ì¼/ì£¼ë§ ì²˜ë¦¬í•´ ì£¼ì§€ë§Œ, ì•ˆì „í•˜ê²Œ ì „ì¼ì ë³´ì • ë¡œì§ (ê°„ë‹¨ ë²„ì „)
    end_s = end_dt.strftime("%Y%m%d")
    log(f"ğŸ“… ê±°ë˜ ê¸°ì¤€ì¼ í™•ì •: {end_s}")

    start_dt = end_dt - timedelta(days=LOOKBACK_DAYS)
    start_s = start_dt.strftime("%Y%m%d")

    log("ğŸ” ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¢…ëª© ì„ ì • ì¤‘â€¦")
    top_df = pick_top_by_trading_value(end_s, TOP_N)
    tickers = top_df["ì¢…ëª©ì½”ë“œ"].tolist()
    log(f"âœ… TOP {len(tickers)} ì¢…ëª© ì„ ì • ì™„ë£Œ")

    kospi_set, kosdaq_set = get_market_sets(end_s)

    rows = []
    for i, t in enumerate(tickers, 1):
        try:
            # OHLCV 60ì¼
            ohlcv = stock.get_market_ohlcv_by_date(start_s, end_s, t)
            if ohlcv is None or ohlcv.empty:
                continue
            ohlcv = ohlcv.reset_index().rename(columns={"index": "ë‚ ì§œ"})
            ohlcv["ë‚ ì§œ"] = pd.to_datetime(ohlcv["ë‚ ì§œ"])

            # ì§€í‘œ
            close = ohlcv["ì¢…ê°€"].astype(float)
            high  = ohlcv["ê³ ê°€"].astype(float)
            low   = ohlcv["ì €ê°€"].astype(float)
            vol   = ohlcv["ê±°ë˜ëŸ‰"].astype(float)

            ma20 = close.rolling(20).mean()
            ma60 = close.rolling(60).mean()
            atr14 = calc_atr(high, low, close, 14)
            rsi14 = calc_rsi(close, 14)

            ema12 = ema(close, 12)
            ema26 = ema(close, 26)
            macd_line = ema12 - ema26
            macd_sig  = ema(macd_line, 9)
            macd_hist = macd_line - macd_sig
            macd_slope = macd_hist.diff()

            vol_z = vol / (vol.rolling(20).mean())
            disp  = (close / ma20 - 1.0) * 100  # ä¹–é›¢%

            last = ohlcv.iloc[-1]
            c     = float(last["ì¢…ê°€"])
            v_z   = float(vol_z.iloc[-1])   if not np.isnan(vol_z.iloc[-1])   else np.nan
            rsi_v = float(rsi14.iloc[-1])   if not np.isnan(rsi14.iloc[-1])   else np.nan
            m_h   = float(macd_hist.iloc[-1]) if not np.isnan(macd_hist.iloc[-1]) else np.nan
            m_sl  = float(macd_slope.iloc[-1]) if not np.isnan(macd_slope.iloc[-1]) else np.nan
            m20   = float(ma20.iloc[-1])    if not np.isnan(ma20.iloc[-1])    else np.nan
            m60   = float(ma60.iloc[-1])    if not np.isnan(ma60.iloc[-1])    else np.nan
            atr   = float(atr14.iloc[-1])   if not np.isnan(atr14.iloc[-1])   else np.nan
            disp_v= float(disp.iloc[-1])    if not np.isnan(disp.iloc[-1])    else np.nan

            ret5  = (close.pct_change(5).iloc[-1]  * 100) if len(close) >= 6  else np.nan
            ret10 = (close.pct_change(10).iloc[-1] * 100) if len(close) >= 11 else np.nan

            # ì‹œì¥/ì‹œì´/ê±°ë˜ëŒ€ê¸ˆ
            mkt = "KOSPI" if t in kospi_set else ("KOSDAQ" if t in kosdaq_set else "ê¸°íƒ€")
            tv_eok   = float(top_df.loc[top_df["ì¢…ëª©ì½”ë“œ"] == t, "ê±°ë˜ëŒ€ê¸ˆ(ì›)"].values[0]) / 1e8
            mcap_eok = get_mcap_eok(end_s, t)

            # í•„í„° (ê°œì¡ì£¼ ì»·)
            if tv_eok < MIN_TURNOVER_EOK or (not np.isnan(mcap_eok) and mcap_eok < MIN_MCAP_EOK):
                continue

            # EBS ì ìˆ˜ (ê¸‰ë“± 'ì´ˆì…' ìŠ¤ì½”ì–´)
            score = 0
            reason = []
            if RSI_LOW <= rsi_v <= RSI_HIGH:
                score += 1; reason.append("RSI 45~65")
            if m_sl > 0:
                score += 1; reason.append("MACDâ†‘")
            if not np.isnan(disp_v) and -1.0 <= disp_v <= 4.0:
                score += 1; reason.append("MA20 ê·¼ì²˜")
            if v_z > 1.2:
                score += 1; reason.append("ê±°ë˜ëŸ‰â†‘")
            if not np.isnan(m20) and not np.isnan(m60) and m20 > m60:
                score += 1; reason.append("ìƒìŠ¹êµ¬ì¡°")
            if m_h > 0:
                score += 1; reason.append("MACD>sig")
            if not np.isnan(ret5) and ret5 < 10:
                score += 1; reason.append("ê³¼ì—´X")

            # ì¶”ì²œê°€(ë³´ìˆ˜ì  ê·œì¹™) â€” ë°ì´í„° ë¶€ì¡± ì‹œ ìŠ¤í‚µ
            if np.isnan(atr) or np.isnan(m20):
                continue
            buy  = min(c, m20 * 1.01)
            stop = buy - 1.5 * atr
            tgt1 = buy + (buy - stop) * 1.0   # R:R=1
            tgt2 = buy + (buy - stop) * 2.0   # R:R=2

            buy  = round_to_tick(buy)
            stop = max(round_to_tick(stop), round_to_tick(m20 * 0.97))
            tgt1 = round_to_tick(tgt1)
            tgt2 = round_to_tick(tgt2)

            rows.append({
                "ì‹œì¥": mkt,
                "ì¢…ëª©ì½”ë“œ": t,
                # ì¢…ëª©ëª…ì€ ë§ˆì§€ë§‰ì— krx_codes.csv ë³‘í•©ìœ¼ë¡œ í™•ì •
                "ì¢…ê°€": int(c),
                "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)": round(tv_eok, 2),
                "ì‹œê°€ì´ì•¡(ì–µì›)": None if np.isnan(mcap_eok) else round(mcap_eok, 1),
                "RSI14": None if np.isnan(rsi_v) else round(rsi_v, 1),
                "ä¹–é›¢%": None if np.isnan(disp_v) else round(disp_v, 2),
                "MACD_hist": None if np.isnan(m_h) else round(m_h, 4),
                "MACD_slope": None if np.isnan(m_sl) else round(m_sl, 5),
                "Vol_Z": None if np.isnan(v_z) else round(v_z, 2),
                "ret_5d_%": None if np.isnan(ret5) else round(ret5, 2),
                "ret_10d_%": None if np.isnan(ret10) else round(ret10, 2),
                "EBS": int(score),
                "í†µê³¼": "ğŸš€ì´ˆì…" if score >= PASS_SCORE else "",
                "ê·¼ê±°": ", ".join(reason),
                "ì¶”ì²œë§¤ìˆ˜ê°€": buy,
                "ì¶”ì²œë§¤ë„ê°€1": tgt1,
                "ì¶”ì²œë§¤ë„ê°€2": tgt2,
                "ì†ì ˆê°€": stop,
            })
        except Exception as e:
            log(f"âš ï¸ {t} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        time.sleep(SLEEP_SEC)

    if not rows:
        raise RuntimeError("ìˆ˜ì§‘ ê²°ê³¼ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")

    df_out = pd.DataFrame(rows)

    # ------------------- ì¢…ëª©ëª… ë§µ ìƒì„±/ë³‘í•© (ì´ë¦„ì—†ìŒ ë°©ì§€) -------------------
    build_name_map_and_save()  # í•­ìƒ ìƒì„± ì‹œë„
    try:
        nm = load_name_map()
        nm = nm[["ì¢…ëª©ì½”ë“œ", "ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
        df_out["ì¢…ëª©ì½”ë“œ"] = df_out["ì¢…ëª©ì½”ë“œ"].astype(str).str.zfill(6)
        df_out = df_out.merge(nm, on="ì¢…ëª©ì½”ë“œ", how="left")
        # í˜¹ì‹œ ì´ë¦„ì´ ë¹„ë©´ ì½”ë“œë¡œ ì±„ì›€
        df_out["ì¢…ëª©ëª…"] = df_out["ì¢…ëª©ëª…"].fillna(df_out["ì¢…ëª©ì½”ë“œ"])
    except Exception as e:
        log(f"ì´ë¦„ë§µ ë³‘í•© ìŠ¤í‚µ: {e}")
        if "ì¢…ëª©ëª…" not in df_out.columns:
            df_out["ì¢…ëª©ëª…"] = df_out["ì¢…ëª©ì½”ë“œ"]

    # ì •ë ¬ ê¸°ë³¸: EBS desc â†’ ê±°ë˜ëŒ€ê¸ˆ desc
    df_out = df_out.sort_values(["EBS", "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"], ascending=[False, False]).reset_index(drop=True)

    # ì €ì¥
    ensure_dir(OUT_DIR)
    today = end_dt.strftime("%Y%m%d")
    path_day = os.path.join(OUT_DIR, f"recommend_{today}.csv")
    path_latest = os.path.join(OUT_DIR, "recommend_latest.csv")
    df_out.to_csv(path_day, index=False, encoding="utf-8-sig")
    df_out.to_csv(path_latest, index=False, encoding="utf-8-sig")
    log(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {path_day} (+ {path_latest})")

if __name__ == "__main__":
    main()
