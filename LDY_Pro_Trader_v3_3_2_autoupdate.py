# -*- coding: utf-8 -*-
"""
LDY Pro Trader v3.3.4 (Auto Update + Robust Name Map + Number Format + ì¶”ê²© ì§„ìž… ëª¨ë“œ)
- ì¶”ì²œ CSV: data/recommend_latest.csv (remote ìš°ì„ )
- ì´ë¦„ë§µ:   data/krx_codes.csv (remote ìš°ì„ ) â†’ FDR â†’ pykrx ìˆœ í´ë°±
- collector CSV(ì™„ì œí’ˆ) ë˜ëŠ” ì›ì‹œ OHLCV ëª¨ë‘ ì§€ì›
- 'í’€ë°±' + 'ì¶”ê²©' 2ê°€ì§€ ì§„ìž… ëª¨ë“œ ì§€ì›
- ì§€ê¸ˆ ì§„ìž… ìœ íš¨(ëª©í‘œê°€1 â‰¥ ì¢…ê°€) í•„í„° & RR(ëª©í‘œ1/ì†ì ˆ) í•„í„° ì œê³µ
- í‘œ ìˆ«ìž(ê°€ê²©/ì–µì›)ì— ì²œë‹¨ìœ„ ì½¤ë§ˆ ì ìš© (Streamlit column_config)
"""

import os, io, math, requests, numpy as np, pandas as pd, streamlit as st
from datetime import datetime

# optional deps
try:
    from pykrx import stock
    PYKRX_OK = True
except Exception:
    PYKRX_OK = False

try:
    import FinanceDataReader as fdr
    FDR_OK = True
except Exception:
    FDR_OK = False

st.set_page_config(page_title="LDY Pro Trader v3.3.4 (Auto Update)", layout="wide")
st.title("ðŸ“ˆ LDY Pro Trader v3.3.4 (Auto Update)")
st.caption("ë§¤ì¼ ìž¥ë§ˆê° í›„ ìžë™ ì—…ë°ì´íŠ¸ë˜ëŠ” ìŠ¤ìœ™ ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ | Made by LDY")

RAW_URL   = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/recommend_latest.csv"
LOCAL_RAW = "data/recommend_latest.csv"
CODES_URL = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/krx_codes.csv"
LOCAL_MAP = "data/krx_codes.csv"
PASS_SCORE = 4

# ---------------- IO ----------------
@st.cache_data(ttl=300)
def load_csv_url(url: str) -> pd.DataFrame:
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    return pd.read_csv(io.BytesIO(r.content))

@st.cache_data(ttl=300)
def load_csv_path(path: str) -> pd.DataFrame:
    return pd.read_csv(path)

def log_src(df: pd.DataFrame, src: str, url_or_path: str):
    st.info(f"ìƒíƒœ âœ… ë°ì´í„° ë¡œë“œ: {src}\n\n{url_or_path}")
    st.success(f"ðŸ“… ì¶”ì²œ ê¸°ì¤€(í‘œì‹œ ì‹œê°): {pd.Timestamp.now(tz='Asia/Seoul').strftime('%Y-%m-%d %H:%M')} Â· ì›ì‹œ í–‰ìˆ˜: {len(df):,}")

# --------------- utils --------------
def z6(x) -> str:
    s = str(x)
    return s.zfill(6) if s.isdigit() else s

def ema(s: pd.Series, span: int):
    return s.ewm(span=span, adjust=False, min_periods=span).mean()

def rsi14(close: pd.Series, period=14):
    d = close.diff()
    up, dn = d.clip(lower=0), -d.clip(upper=0)
    au, ad = up.rolling(period).mean(), dn.rolling(period).mean()
    rs = au / ad.replace(0, np.nan)
    return 100 - 100/(1+rs)

def macd_feats(close: pd.Series):
    e12, e26 = ema(close,12), ema(close,26)
    macd = e12 - e26
    sig  = macd.ewm(span=9, adjust=False, min_periods=9).mean()
    hist = macd - sig
    return hist, hist.diff()

def atr14(h, l, c, period=14):
    prev = c.shift(1)
    tr = pd.concat([(h-l), (h-prev).abs(), (l-prev).abs()], axis=1).max(axis=1)
    return tr.rolling(period).mean()

def ensure_turnover(df: pd.DataFrame) -> pd.DataFrame:
    if "ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)" not in df.columns:
        base = None
        if "ê±°ëž˜ëŒ€ê¸ˆ(ì›)" in df.columns:
            base = pd.to_numeric(df["ê±°ëž˜ëŒ€ê¸ˆ(ì›)"], errors="coerce")
        elif all(x in df.columns for x in ["ê±°ëž˜ëŸ‰","ì¢…ê°€"]):
            base = pd.to_numeric(df["ê±°ëž˜ëŸ‰"], errors="coerce") * pd.to_numeric(df["ì¢…ê°€"], errors="coerce")
        if base is not None:
            df["ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)"] = (base/1e8).round(2)
    return df

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    cmap = {
        "Date":"ë‚ ì§œ","date":"ë‚ ì§œ",
        "Code":"ì¢…ëª©ì½”ë“œ","í‹°ì»¤":"ì¢…ëª©ì½”ë“œ","ticker":"ì¢…ëª©ì½”ë“œ",
        "Name":"ì¢…ëª©ëª…","name":"ì¢…ëª©ëª…",
        "Open":"ì‹œê°€","High":"ê³ ê°€","Low":"ì €ê°€","Close":"ì¢…ê°€","Volume":"ê±°ëž˜ëŸ‰",
        "ê±°ëž˜ëŒ€ê¸ˆ":"ê±°ëž˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡":"ì‹œê°€ì´ì•¡(ì›)"
    }
    for k,v in cmap.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k:v})

    if "ë‚ ì§œ" in df.columns:
        with pd.option_context('future.no_silent_downcasting', True):
            try: df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"])
            except: pass
    if "ì¢…ëª©ì½”ë“œ" in df.columns:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.replace(".0","", regex=False).map(z6)
    else:
        df["ì¢…ëª©ì½”ë“œ"] = None
    if "ì‹œìž¥" not in df.columns:
        df["ì‹œìž¥"] = "ALL"
    if "ì¢…ëª©ëª…" not in df.columns:
        df["ì¢…ëª©ëª…"] = None

    for c in ["ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€","ê±°ëž˜ëŸ‰","ê±°ëž˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡(ì›)"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    df = ensure_turnover(df)
    return df

def round_to_tick(price: float) -> int:
    # ë‹¨ìˆœ 10ì› í‹± ì ìš©(ê°„ì´)
    if pd.isna(price): return np.nan
    return int(round(float(price) / 10.0) * 10)

# --------- enrich from OHLCV ----------
@st.cache_data(ttl=300)
def enrich_from_ohlcv(raw: pd.DataFrame) -> pd.DataFrame:
    need = {"ì¢…ëª©ì½”ë“œ","ë‚ ì§œ","ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€"}
    if not need.issubset(set(raw.columns)):
        return raw
    raw = raw.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"])
    g = raw.groupby("ì¢…ëª©ì½”ë“œ", group_keys=False)

    def _feat(x: pd.DataFrame):
        x = x.copy()
        x["MA20"] = x["ì¢…ê°€"].rolling(20).mean()
        x["ATR14"] = atr14(x["ê³ ê°€"], x["ì €ê°€"], x["ì¢…ê°€"], 14)
        x["RSI14"] = rsi14(x["ì¢…ê°€"])
        hist, slope = macd_feats(x["ì¢…ê°€"]); x["MACD_hist"], x["MACD_slope"] = hist, slope
        x["Vol_Z"] = (x["ê±°ëž˜ëŸ‰"] - x["ê±°ëž˜ëŸ‰"].rolling(20).mean())/x["ê±°ëž˜ëŸ‰"].rolling(20).std()
        x["ä¹–é›¢%"] = (x["ì¢…ê°€"]/x["MA20"] - 1)*100
        x["ret_5d_%"]  = (x["ì¢…ê°€"]/x["ì¢…ê°€"].shift(5)  - 1)*100
        x["ret_10d_%"] = (x["ì¢…ê°€"]/x["ì¢…ê°€"].shift(10) - 1)*100

        last = x.iloc[-1:].copy()
        e, why = 0, []
        def nz(v): 
            return not (isinstance(v,float) and math.isnan(v))
        rsi = last["RSI14"].iloc[0];      c1 = nz(rsi) and 45<=rsi<=65;  e+=int(c1); why.append("RSI 45~65" if c1 else "")
        c2 = nz(last["MACD_slope"].iloc[0]) and last["MACD_slope"].iloc[0] > 0; e+=int(c2); why.append("MACDâ†‘" if c2 else "")
        close, ma20 = last["ì¢…ê°€"].iloc[0], last["MA20"].iloc[0]
        c3 = nz(ma20) and (0.99*ma20 <= close <= 1.04*ma20); e+=int(c3); why.append("MA20Â±4%" if c3 else "")
        c4 = nz(last["Vol_Z"].iloc[0]) and last["Vol_Z"].iloc[0] > 1.2; e+=int(c4); why.append("VolZ>1.2" if c4 else "")
        m20p = x["MA20"].iloc[-2] if len(x)>=2 else np.nan
        c5 = nz(m20p) and (last["MA20"].iloc[0] - m20p > 0); e+=int(c5); why.append("MA20â†‘" if c5 else "")
        c6 = nz(last["MACD_hist"].iloc[0]) and last["MACD_hist"].iloc[0] > 0; e+=int(c6); why.append("MACD>0" if c6 else "")
        r5 = last["ret_5d_%"].iloc[0];    c7 = nz(r5) and r5 < 10;        e+=int(c7); why.append("5d<10%" if c7 else "")
        last["EBS"] = e; last["ê·¼ê±°"] = " / ".join([w for w in why if w])

        atr = last["ATR14"].iloc[0]
        if any([not nz(atr), not nz(ma20), not nz(close)]) or atr <= 0:
            entry=t1=t2=stp=np.nan
        else:
            band_lo, band_hi = ma20-0.5*atr, ma20+0.5*atr
            entry = min(max(close, band_lo), band_hi)
            t1, t2, stp = entry+1.0*atr, entry+1.8*atr, entry-1.2*atr
        last["ì¶”ì²œë§¤ìˆ˜ê°€"] = round(entry,2) if not math.isnan(entry) else np.nan
        last["ì¶”ì²œë§¤ë„ê°€1"] = round(t1,2)   if not math.isnan(t1)    else np.nan
        last["ì¶”ì²œë§¤ë„ê°€2"] = round(t2,2)   if not math.isnan(t2)    else np.nan
        last["ì†ì ˆê°€"]     = round(stp,2)   if not math.isnan(stp)   else np.nan
        return last

    try:
        out = g.apply(_feat, include_groups=False).reset_index(drop=True)
    except TypeError:
        out = g.apply(_feat).reset_index(drop=True)

    # ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›) ìµœì‹ í–‰ ë³´ê°•
    tail = raw.groupby("ì¢…ëª©ì½”ë“œ").tail(1).copy()
    tail = ensure_turnover(tail)
    if "ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)" in tail.columns:
        out = out.merge(tail[["ì¢…ëª©ì½”ë“œ","ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)"]], on="ì¢…ëª©ì½”ë“œ", how="left")
    if "ì‹œê°€ì´ì•¡(ì–µì›)" not in out.columns:
        out["ì‹œê°€ì´ì•¡(ì–µì›)"] = np.nan
    if "ì‹œìž¥" not in out.columns:
        out["ì‹œìž¥"] = "ALL"
    return out

# -------- name map (robust) --------
@st.cache_data(ttl=6*60*60)
def load_name_map() -> pd.DataFrame | None:
    # 1) repoì˜ data/krx_codes.csv ìš°ì„ 
    try:
        m = load_csv_url(CODES_URL)
        if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
    except Exception:
        pass
    if os.path.exists(LOCAL_MAP):
        try:
            m = load_csv_path(LOCAL_MAP)
            if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
                m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
                return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass

    # 2) FDR í´ë°±
    if FDR_OK:
        try:
            lst = fdr.StockListing("KRX")
            m = lst.rename(columns={"Code":"ì¢…ëª©ì½”ë“œ","Name":"ì¢…ëª©ëª…"})[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]]
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m.drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass

    # 3) pykrx ê°œë³„ ì¡°íšŒ
    if PYKRX_OK:
        today = datetime.now().strftime("%Y%m%d")
        rows = []
        try:
            for mk in ["KOSPI","KOSDAQ","KONEX"]:
                try:
                    lst = stock.get_market_ticker_list(today, market=mk)
                except Exception:
                    lst = []
                for t in lst:
                    try:
                        nm = stock.get_market_ticker_name(t)
                    except Exception:
                        nm = None
                    rows.append({"ì¢…ëª©ì½”ë“œ": str(t).zfill(6), "ì¢…ëª©ëª…": nm})
            m = pd.DataFrame(rows).dropna().drop_duplicates("ì¢…ëª©ì½”ë“œ")
            return m if len(m) else None
        except Exception:
            return None
    return None

def apply_names(df: pd.DataFrame) -> pd.DataFrame:
    mp = load_name_map()
    if mp is not None:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
        if "ì¢…ëª©ëª…" not in df.columns: df["ì¢…ëª©ëª…"] = None
        df = df.merge(mp, on="ì¢…ëª©ì½”ë“œ", how="left", suffixes=("","_map"))
        df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna(df["ì¢…ëª©ëª…_map"])
        df = df.drop(columns=[c for c in df.columns if c.endswith("_map")], errors="ignore")
    df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna("(ì´ë¦„ì—†ìŒ)")
    return df

# -------- load raw --------
try:
    df_raw = load_csv_url(RAW_URL); log_src(df_raw, "remote", RAW_URL)
except Exception:
    if os.path.exists(LOCAL_RAW):
        df_raw = load_csv_path(LOCAL_RAW); log_src(df_raw, "local", LOCAL_RAW)
    else:
        st.error("âŒ CSVê°€ ì—†ìŠµë‹ˆë‹¤. Actionsì—ì„œ collectorê°€ data/recommend_latest.csvë¥¼ ì˜¬ë ¸ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

df_raw = normalize_cols(df_raw)

# ì´ë¯¸ ì™„ì œí’ˆì¸ì§€ ì²´í¬
has_ebs  = "EBS" in df_raw.columns and df_raw["EBS"].notna().any()
has_reco = all(c in df_raw.columns for c in ["ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]) and \
           df_raw[["ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]].notna().any().any()

if has_ebs and has_reco:
    df = df_raw.copy()
else:
    with st.status("ðŸ§® ì›ì‹œ OHLCV â†’ ì§€í‘œ/ì ìˆ˜/ì¶”ì²œê°€ ìƒì„± ì¤‘...", expanded=False):
        df = enrich_from_ohlcv(df_raw)

# ìµœì‹  í–‰ë§Œ
latest = df.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"]).groupby("ì¢…ëª©ì½”ë“œ").tail(1) if "ë‚ ì§œ" in df.columns else df.copy()

# ì´ë¦„ ë§¤í•‘ (ë ˆí¬/ FDR / pykrx)
with st.status("ðŸ·ï¸ ì¢…ëª©ëª… ë§¤í•‘ ì¤‘...", expanded=False):
    latest = apply_names(latest)

# ìˆ«ìž ìºìŠ¤íŒ… & ê±°ëž˜ëŒ€ê¸ˆ ë³´ê°•
latest = ensure_turnover(latest)
for c in ["ì¢…ê°€","ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","EBS","ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€","ATR14","MA20"]:
    if c in latest.columns:
        latest[c] = pd.to_numeric(latest[c], errors="coerce")

# ---------- ì¶”ê²© ëª¨ë“œ(í‘œì‹œìš©) ê³„ì‚° ----------
def infer_ma20_from_disp(c: float, disp_pct: float):
    if pd.isna(c) or pd.isna(disp_pct): return np.nan
    try:
        return float(c) / (1.0 + float(disp_pct)/100.0)
    except ZeroDivisionError:
        return np.nan

def infer_atr_proxy(row: pd.Series):
    # ìš°ì„  ATR14 ìžˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©
    if "ATR14" in row and pd.notna(row["ATR14"]) and row["ATR14"] > 0:
        return float(row["ATR14"])
    buy  = pd.to_numeric(row.get("ì¶”ì²œë§¤ìˆ˜ê°€"), errors="coerce")
    stop = pd.to_numeric(row.get("ì†ì ˆê°€"), errors="coerce")
    t1   = pd.to_numeric(row.get("ì¶”ì²œë§¤ë„ê°€1"), errors="coerce")
    t2   = pd.to_numeric(row.get("ì¶”ì²œë§¤ë„ê°€2"), errors="coerce")
    cand = []
    if pd.notna(buy) and pd.notna(stop) and buy > stop:
        cand.append((buy - stop) / 1.5)     # buy - stop = 1.5 * ATR
    if pd.notna(buy) and pd.notna(t1) and t1 > buy:
        cand.append((t1 - buy) / 1.5)       # t1 - buy = 1.5 * ATR
    if pd.notna(buy) and pd.notna(t2) and t2 > buy:
        cand.append((t2 - buy) / 3.0)       # t2 - buy = 3 * ATR
    if not cand:
        return np.nan
    return float(np.nanmedian(cand))

def compute_chase_set(dfv: pd.DataFrame) -> pd.DataFrame:
    out = dfv.copy()
    c   = pd.to_numeric(out.get("ì¢…ê°€"), errors="coerce")
    disp = pd.to_numeric(out.get("ä¹–é›¢%"), errors="coerce")
    ma20_est = pd.Series(np.nan, index=out.index)
    if "MA20" in out.columns and out["MA20"].notna().any():
        ma20_est = pd.to_numeric(out["MA20"], errors="coerce")
    else:
        ma20_est = c / (1.0 + disp/100.0)  # ä¹–é›¢%ë¡œ MA20 ì¶”ì •

    atr_proxy = out.apply(infer_atr_proxy, axis=1)
    # chase ê³„ì‚°
    buy_chase  = c
    stop_chase = np.maximum(c - 1.2*atr_proxy, ma20_est*0.97)
    t1_chase   = c + 1.0*atr_proxy
    t2_chase   = c + 1.8*atr_proxy

    # í‹± ë°˜ì˜¬ë¦¼
    out["ì¶”ì²œë§¤ìˆ˜ê°€(ì¶”ê²©)"]  = buy_chase.round(0).astype("Int64")
    out["ì†ì ˆê°€(ì¶”ê²©)"]      = pd.Series([round_to_tick(x) for x in stop_chase], index=out.index).astype("Int64")
    out["ì¶”ì²œë§¤ë„ê°€1(ì¶”ê²©)"] = pd.Series([round_to_tick(x) for x in t1_chase],   index=out.index).astype("Int64")
    out["ì¶”ì²œë§¤ë„ê°€2(ì¶”ê²©)"] = pd.Series([round_to_tick(x) for x in t2_chase],   index=out.index).astype("Int64")

    # RR(ëª©í‘œ1/ì†ì ˆ)
    # í’€ë°± RR
    pb_buy  = pd.to_numeric(out.get("ì¶”ì²œë§¤ìˆ˜ê°€"), errors="coerce")
    pb_stop = pd.to_numeric(out.get("ì†ì ˆê°€"), errors="coerce")
    pb_t1   = pd.to_numeric(out.get("ì¶”ì²œë§¤ë„ê°€1"), errors="coerce")
    out["RR(í’€ë°±)"] = np.where(
        (pb_buy.notna()) & (pb_stop.notna()) & (pb_t1.notna()) & (pb_buy > pb_stop),
        (pb_t1 - pb_buy) / (pb_buy - pb_stop),
        np.nan
    )
    # ì¶”ê²© RR
    ch_stop = pd.to_numeric(out["ì†ì ˆê°€(ì¶”ê²©)"], errors="coerce")
    ch_t1   = pd.to_numeric(out["ì¶”ì²œë§¤ë„ê°€1(ì¶”ê²©)"], errors="coerce")
    out["RR(ì¶”ê²©)"] = np.where(
        (c.notna()) & (ch_stop.notna()) & (ch_t1.notna()) & (c > ch_stop),
        (ch_t1 - c) / (c - ch_stop),
        np.nan
    )
    # ë³´ì¡°: ì¶”ì • MA20
    out["MA20(ì¶”ì •)"] = ma20_est
    return out

latest = compute_chase_set(latest)

# ------------- UI -------------
with st.expander("ðŸ” ë³´ê¸°/í•„í„°", expanded=True):
    c1,c2,c3,c4,c5 = st.columns([1,1,1,1,2])
    with c1:
        only_entry = st.checkbox("ðŸš€ ì´ˆìž… í›„ë³´ë§Œ (EBSâ‰¥4)", value=("EBS" in latest.columns))
    with c2:
        min_turn = st.slider("ìµœì†Œ ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)", 0, 5000, 50, step=10)
    with c3:
        sort_key = st.selectbox("ì •ë ¬", ["EBSâ–¼","ê±°ëž˜ëŒ€ê¸ˆâ–¼","ì‹œê°€ì´ì•¡â–¼","RSIâ–²","RSIâ–¼","ì¢…ê°€â–²","ì¢…ê°€â–¼"], index=0)
    with c4:
        topn = st.slider("í‘œì‹œ ìˆ˜(Top N)", 10, 500, 200, step=10)
    with c5:
        q_text = st.text_input("ðŸ”Ž ì¢…ëª©ëª…/ì½”ë“œ ê²€ìƒ‰", value="", placeholder="ì˜ˆ: ì‚¼ì„±ì „ìž ë˜ëŠ” 005930")

    c6, c7, c8 = st.columns([1,1,1])
    with c6:
        mode = st.radio("ì§„ìž… ê¸°ì¤€", ["í’€ë°±(ê¸°ë³¸)", "ì¶”ê²©"], horizontal=True)
    with c7:
        only_now = st.checkbox("ì§€ê¸ˆ ì§„ìž… ìœ íš¨(ëª©í‘œê°€1 â‰¥ ì¢…ê°€)", value=False)
    with c8:
        min_rr = st.slider("ìµœì†Œ RR(ëª©í‘œ1/ì†ì ˆ)", 0.0, 3.0, 0.0, step=0.1)

view = latest.copy()
if only_entry and "EBS" in view.columns:
    view = view[view["EBS"] >= PASS_SCORE]
if "ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)" in view.columns:
    view = view[view["ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)"] >= float(min_turn)]
if q_text:
    q = q_text.strip().lower()
    view = view[
        view["ì¢…ëª©ëª…"].fillna("").astype(str).str.lower().str.contains(q) |
        view["ì¢…ëª©ì½”ë“œ"].fillna("").astype(str).str.contains(q)
    ]

def safe_sort(dfv, key):
    try:
        if key=="EBSâ–¼" and "EBS" in dfv.columns:
            by = ["EBS"] + (["ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)"] if "ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)" in dfv.columns else [])
            return dfv.sort_values(by=by, ascending=[False]+[False]*(len(by)-1))
        if key=="ê±°ëž˜ëŒ€ê¸ˆâ–¼" and "ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)" in dfv.columns:
            return dfv.sort_values("ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)", ascending=False)
        if key=="ì‹œê°€ì´ì•¡â–¼" and "ì‹œê°€ì´ì•¡(ì–µì›)" in dfv.columns:
            return dfv.sort_values("ì‹œê°€ì´ì•¡(ì–µì›)", ascending=False, na_position="last")
        if key=="RSIâ–²" and "RSI14" in dfv.columns:
            return dfv.sort_values("RSI14", ascending=True, na_position="last")
        if key=="RSIâ–¼" and "RSI14" in dfv.columns:
            return dfv.sort_values("RSI14", ascending=False, na_position="last")
        if key=="ì¢…ê°€â–²" and "ì¢…ê°€" in dfv.columns:
            return dfv.sort_values("ì¢…ê°€", ascending=True, na_position="last")
        if key=="ì¢…ê°€â–¼" and "ì¢…ê°€" in dfv.columns:
            return dfv.sort_values("ì¢…ê°€", ascending=False, na_position="last")
    except Exception:
        pass
    for alt in ["EBS","ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","ì¢…ê°€"]:
        if alt in dfv.columns:
            return dfv.sort_values(alt, ascending=False, na_position="last")
    return dfv

# ì§€ê¸ˆ ì§„ìž… ìœ íš¨ / RR í•„í„°
if only_now:
    base_t1 = view["ì¶”ì²œë§¤ë„ê°€1(ì¶”ê²©)"] if (mode=="ì¶”ê²©" and "ì¶”ì²œë§¤ë„ê°€1(ì¶”ê²©)" in view.columns) else view["ì¶”ì²œë§¤ë„ê°€1"]
    view = view[ pd.to_numeric(base_t1, errors="coerce") >= pd.to_numeric(view["ì¢…ê°€"], errors="coerce") ]

if min_rr > 0:
    rr_col = "RR(ì¶”ê²©)" if mode=="ì¶”ê²©" else "RR(í’€ë°±)"
    if rr_col in view.columns:
        view = view[ pd.to_numeric(view[rr_col], errors="coerce") >= float(min_rr) ]

view = safe_sort(view, sort_key)

if "EBS" in view.columns:
    view["í†µê³¼"] = np.where(view["EBS"]>=PASS_SCORE, "ðŸš€", "")

# í‘œì‹œ ì»¬ëŸ¼
base_cols = [
    "í†µê³¼","ì‹œìž¥","ì¢…ëª©ëª…","ì¢…ëª©ì½”ë“œ",
    "ì¢…ê°€","ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)",
    "EBS","ê·¼ê±°","RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%"
]
pullback_cols = ["ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","RR(í’€ë°±)"]
chase_cols    = ["ì¶”ì²œë§¤ìˆ˜ê°€(ì¶”ê²©)","ì†ì ˆê°€(ì¶”ê²©)","ì¶”ì²œë§¤ë„ê°€1(ì¶”ê²©)","ì¶”ì²œë§¤ë„ê°€2(ì¶”ê²©)","RR(ì¶”ê²©)"]

cols = base_cols + pullback_cols + [c for c in chase_cols if c in view.columns]

for c in cols:
    if c not in view.columns:
        view[c] = np.nan

st.write(f"ðŸ“‹ ì´ {len(latest):,}ê°œ / í‘œì‹œ {min(len(view), int(topn)):,}ê°œ")

# â”€â”€ ìˆ«ìž í¬ë§·(ì½¤ë§ˆ) ì ìš©ì„ ìœ„í•œ ìºìŠ¤íŒ… â”€â”€
view_fmt = view[cols].head(int(topn)).copy()

# ê°€ê²©/ì •ìˆ˜ë¥˜ â†’ Int64 (NaN í—ˆìš© ì •ìˆ˜)
int_like_cols = [
    "ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2",
    "ì¶”ì²œë§¤ìˆ˜ê°€(ì¶”ê²©)","ì†ì ˆê°€(ì¶”ê²©)","ì¶”ì²œë§¤ë„ê°€1(ì¶”ê²©)","ì¶”ì²œë§¤ë„ê°€2(ì¶”ê²©)","EBS"
]
for c in int_like_cols:
    if c in view_fmt.columns:
        view_fmt[c] = pd.to_numeric(view_fmt[c], errors="coerce").round(0).astype("Int64")

# ì–µì›/ì§€í‘œë¥˜ â†’ float
float_cols = ["ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","RR(í’€ë°±)","RR(ì¶”ê²©)"]
for c in float_cols:
    if c in view_fmt.columns:
        view_fmt[c] = pd.to_numeric(view_fmt[c], errors="coerce")

st.data_editor(
    view_fmt,
    width="stretch",
    height=640,
    hide_index=True,
    disabled=True,          # ì½ê¸° ì „ìš© í‘œ
    num_rows="fixed",
    column_config={
        # í…ìŠ¤íŠ¸
        "í†µê³¼":         st.column_config.TextColumn(" "),
        "ì‹œìž¥":         st.column_config.TextColumn("ì‹œìž¥"),
        "ì¢…ëª©ëª…":       st.column_config.TextColumn("ì¢…ëª©ëª…"),
        "ì¢…ëª©ì½”ë“œ":     st.column_config.TextColumn("ì¢…ëª©ì½”ë“œ"),
        "ê·¼ê±°":         st.column_config.TextColumn("ê·¼ê±°"),
        # ê°€ê²©/ì •ìˆ˜(ì½¤ë§ˆ)
        "ì¢…ê°€":          st.column_config.NumberColumn("ì¢…ê°€",           format="%,d"),
        "ì¶”ì²œë§¤ìˆ˜ê°€":    st.column_config.NumberColumn("ì¶”ì²œë§¤ìˆ˜ê°€(í’€ë°±)",format="%,d"),
        "ì†ì ˆê°€":        st.column_config.NumberColumn("ì†ì ˆê°€(í’€ë°±)",    format="%,d"),
        "ì¶”ì²œë§¤ë„ê°€1":   st.column_config.NumberColumn("ëª©í‘œê°€1(í’€ë°±)",   format="%,d"),
        "ì¶”ì²œë§¤ë„ê°€2":   st.column_config.NumberColumn("ëª©í‘œê°€2(í’€ë°±)",   format="%,d"),
        "EBS":          st.column_config.NumberColumn("EBS",            format="%d"),
        # ì–µì›/ì§€í‘œ (ì½¤ë§ˆÂ·ì†Œìˆ˜)
        "ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)": st.column_config.NumberColumn("ê±°ëž˜ëŒ€ê¸ˆ(ì–µì›)",  format="%,.0f"),
        "ì‹œê°€ì´ì•¡(ì–µì›)": st.column_config.NumberColumn("ì‹œê°€ì´ì•¡(ì–µì›)",  format="%,.0f"),
        "RSI14":        st.column_config.NumberColumn("RSI14",          format="%.1f"),
        "ä¹–é›¢%":         st.column_config.NumberColumn("ä¹–é›¢%",           format="%.2f"),
        "MACD_hist":    st.column_config.NumberColumn("MACD_hist",      format="%.4f"),
        "MACD_slope":   st.column_config.NumberColumn("MACD_slope",     format="%.5f"),
        "Vol_Z":        st.column_config.NumberColumn("Vol_Z",          format="%.2f"),
        "ret_5d_%":     st.column_config.NumberColumn("ret_5d_%",       format="%.2f"),
        "ret_10d_%":    st.column_config.NumberColumn("ret_10d_%",      format="%.2f"),
        # ì¶”ê²© ì„¸íŠ¸(ì½¤ë§ˆ)
        "ì¶”ì²œë§¤ìˆ˜ê°€(ì¶”ê²©)":  st.column_config.NumberColumn("ì¶”ì²œë§¤ìˆ˜ê°€(ì¶”ê²©)",  format="%,d"),
        "ì†ì ˆê°€(ì¶”ê²©)":      st.column_config.NumberColumn("ì†ì ˆê°€(ì¶”ê²©)",      format="%,d"),
        "ì¶”ì²œë§¤ë„ê°€1(ì¶”ê²©)": st.column_config.NumberColumn("ëª©í‘œê°€1(ì¶”ê²©)",     format="%,d"),
        "ì¶”ì²œë§¤ë„ê°€2(ì¶”ê²©)": st.column_config.NumberColumn("ëª©í‘œê°€2(ì¶”ê²©)",     format="%,d"),
        # RR
        "RR(í’€ë°±)":     st.column_config.NumberColumn("RR(í’€ë°±: ëª©í‘œ1/ì†ì ˆ)",   format="%.2f"),
        "RR(ì¶”ê²©)":     st.column_config.NumberColumn("RR(ì¶”ê²©: ëª©í‘œ1/ì†ì ˆ)",   format="%.2f"),
    },
)

st.download_button(
    "ðŸ“¥ í˜„ìž¬ ë³´ê¸° ë‹¤ìš´ë¡œë“œ (CSV)",
    data=view_fmt.to_csv(index=False, encoding="utf-8-sig"),
    file_name="ldy_entry_candidates.csv",
    mime="text/csv"
)

with st.expander("â„¹ï¸ EBS & ì§„ìž… ë¡œì§", expanded=False):
    st.markdown("""
**EBS(0~7)**: RSI 45~65 / MACDâ†‘ / MA20Â±4% / VolZ>1.2 / MA20â†‘ / MACD>0 / 5d<10%  
**í†µê³¼ ê¸°ì¤€**: EBS â‰¥ 4  

**í’€ë°± ì§„ìž…**: MA20Â±0.5ATR ë¶€ê·¼ ì§„ìž…, T1=+1.0ATR, T2=+1.8ATR, ì†ì ˆ=âˆ’1.2ATR  
**ì¶”ê²© ì§„ìž…(í‘œì‹œìš©)**: í˜„ìž¬ê°€ ê¸°ì¤€ T1=+1.0Ã—ATR(ì¶”ì •), T2=+1.8Ã—ATR(ì¶”ì •), ì†ì ˆ=max(í˜„ìž¬ê°€âˆ’1.2Ã—ATR, MA20Ã—0.97)  
- ATRì´ CSVì— ì—†ìœ¼ë©´, `ì¶”ì²œê°€/ì†ì ˆ/ëª©í‘œê°€` ê´€ê³„ì‹ìœ¼ë¡œ ATRì„ **ì¶”ì •**í•˜ê³ ,  
- MA20ì´ ì—†ìœ¼ë©´ ä¹–é›¢%ë¡œ MA20ì„ **ì—­ì‚°**í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤.  

**í•„í„°**  
- â€œì§€ê¸ˆ ì§„ìž… ìœ íš¨â€: (ì„ íƒí•œ ì§„ìž… ëª¨ë“œì˜) `ëª©í‘œê°€1 â‰¥ ì¢…ê°€`  
- â€œìµœì†Œ RRâ€: (ëª©í‘œ1âˆ’ì§„ìž…) / (ì§„ìž…âˆ’ì†ì ˆ) â‰¥ ì„¤ì •ê°’
""")
