# -*- coding: utf-8 -*-
"""
LDY Pro Trader v4.4 â€” Global Rank (Single Composite Score + Router + Explain + P_hit)
- í•œ í™”ë©´: 'ì˜¤ëŠ˜ì˜ GLOBAL TOP 10'ë§Œ ê³ ì • ë…¸ì¶œ (ê°€ì¤‘ì¹˜/ìŠ¬ë¼ì´ë” ì—†ìŒ)
- ëª¨ë“  ì§€í‘œ â†’ ë‹¨ì¼ ì ìˆ˜ LDY_SCORE(0~100), LDY_RANK = ë‚´ë¦¼ì°¨ìˆœ
- ì „ëµ ë°°ì§€(ROUTE): BRK(ëŒíŒŒ)/PULL(ëˆŒë¦¼)/TREND(ì¶”ì„¸)/MR(ë˜ëŒë¦¼) ê°„ë‹¨ ë¼ìš°íŒ…
- ì„¤ëª…ë ¥: ì»´í¬ë„ŒíŠ¸ë³„ ê¸°ì—¬ë„(ì ìˆ˜)+íŒ¨ë„í‹°, WHY ë¬¸ìì—´, P_hit(íƒ€ê²© í™•ë¥  ì¶”ì •) í‘œì‹œ
- ìœ ë™ì„± í•˜ë“œì»·: KOSPIâ‰¥200ì–µ, KOSDAQâ‰¥100ì–µ (í›„ë³´ ë¶€ì¡± ì‹œ ìë™ ì™„í™”)
- ì„ íƒ ë¡œê·¸ í•™ìŠµ(ì—†ìœ¼ë©´ ìë™ ë¬´ì‹œ): data/trade_logs.csv(ì»¬ëŸ¼: code, hit(0/1), score(float))
"""

import os, io, math, json, requests, numpy as np, pandas as pd, streamlit as st
from datetime import datetime

# -------- Optional deps (ì´ë¦„ ë§µ í´ë°±ìš©) --------
try:
    from pykrx import stock
    PYKRX_OK = True
except Exception:
    PYKRX_OK = False

try:
    import FinanceDataReader as fdr
    FDR_OK = True
except Exception:
    FDR_OK = False

# -------- Page --------
st.set_page_config(page_title="LDY Pro Trader v4.4 â€” Global Rank", layout="wide")
st.title("ğŸ† LDY Pro Trader v4.4 â€” Global Rank")
st.caption("ëª¨ë“  ì§€í‘œë¥¼ ë‹¨ì¼ ì ìˆ˜ë¡œ ì¢…í•© â†’ 1ìœ„ê°€ ê°€ì¥ ìœ ë§í•œ ì¢…ëª© (ê³ ì • Top 10, ê°€ì¤‘ì¹˜ UI ì—†ìŒ)")

# -------- Constants --------
RAW_URL   = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/recommend_latest.csv"
LOCAL_RAW = "data/recommend_latest.csv"
CODES_URL = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/krx_codes.csv"
LOCAL_MAP = "data/krx_codes.csv"

PASS_EBS = 4                 # í’ˆì§ˆ ê²Œì´íŠ¸
MIN_TURN_KOSPI = 200.0       # ìœ ë™ì„± í•˜ë“œì»·
MIN_TURN_KOSDAQ = 100.0
MIN_TURN_DEFAULT = 100.0

# ê³ ì • ê°€ì¤‘ì¹˜(í•©=1.0) â€” UI ì¡°ì • ì—†ìŒ
W_RR   = 0.25  # ë³´ìƒëŒ€ë¹„ìœ„í—˜ (RR1)
W_T1   = 0.18  # ëª©í‘œ1 ì—¬ìœ 
W_SL   = 0.12  # ì†ì ˆ ì—¬ìœ 
W_NEAR = 0.12  # í˜„ì¬ê°€-ì¶”ì²œê°€ ê·¼ì ‘
W_MOM  = 0.10  # ëª¨ë©˜í…€(ERS+MACD_slope+RSI ì¤‘ì‹¬)
W_LIQ  = 0.13  # ìœ ë™ì„±(ê±°ë˜ëŒ€ê¸ˆ í¼ì„¼íƒ€ì¼)
W_TEC  = 0.10  # ê¸°ìˆ ê· í˜•(VolZ ìŠ¤ìœ—ìŠ¤íŒŸ +ä¹–é›¢ ì•ˆì •)

# í˜ë„í‹°(ì ìˆ˜ì—ì„œ ì§ì ‘ ì°¨ê°)
P_OVERHEAT_5D = 6.0   # 5ì¼ ê³¼ì—´
P_OVERHEAT_10D= 6.0   # 10ì¼ ê³¼ì—´
P_RSI_OUT     = 4.0   # RSI 45~65 ì´íƒˆ
P_MACD_NEG    = 4.0   # MACD ê¸°ìš¸ê¸° ìŒìˆ˜
P_NEAR_FAR    = 4.0   # ì—”íŠ¸ë¦¬ ê´´ë¦¬ ê³¼ë‹¤
P_LIQ_LOW     = 4.0   # ìœ ë™ì„± í•˜ìœ„ê¶Œ
P_VOL_SPIKE   = 2.0   # VolZ ìŠ¤íŒŒì´í¬

# -------- IO helpers --------
@st.cache_data(ttl=300)
def load_csv_url(url: str) -> pd.DataFrame:
    r = requests.get(url, timeout=30); r.raise_for_status()
    return pd.read_csv(io.BytesIO(r.content))

@st.cache_data(ttl=300)
def load_csv_path(path: str) -> pd.DataFrame:
    return pd.read_csv(path, encoding="utf-8")

def log_src(df: pd.DataFrame, src: str, url_or_path: str):
    st.info(f"ìƒíƒœ âœ… ë°ì´í„° ë¡œë“œ: {src}\n\n{url_or_path}")
    st.success(f"ğŸ“… í‘œì‹œì‹œê°: {pd.Timestamp.now(tz='Asia/Seoul').strftime('%Y-%m-%d %H:%M')} Â· í–‰ìˆ˜: {len(df):,}")

# -------- Utils --------
def z6(x) -> str:
    s = str(x)
    return s.zfill(6) if s.isdigit() else s

def nz_num(s: pd.Series):
    return pd.to_numeric(s, errors="coerce")

def ensure_turnover(df: pd.DataFrame) -> pd.DataFrame:
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" not in df.columns:
        base = None
        if "ê±°ë˜ëŒ€ê¸ˆ(ì›)" in df.columns:
            base = nz_num(df["ê±°ë˜ëŒ€ê¸ˆ(ì›)"])
        elif all(c in df.columns for c in ["ê±°ë˜ëŸ‰","ì¢…ê°€"]):
            base = nz_num(df["ê±°ë˜ëŸ‰"]) * nz_num(df["ì¢…ê°€"])
        if base is not None:
            df["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] = (base/1e8).round(2)
    return df

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    cmap = {
        "Date":"ë‚ ì§œ","date":"ë‚ ì§œ",
        "Code":"ì¢…ëª©ì½”ë“œ","í‹°ì»¤":"ì¢…ëª©ì½”ë“œ","ticker":"ì¢…ëª©ì½”ë“œ",
        "Name":"ì¢…ëª©ëª…","name":"ì¢…ëª©ëª…",
        "Open":"ì‹œê°€","High":"ê³ ê°€","Low":"ì €ê°€","Close":"ì¢…ê°€","Volume":"ê±°ë˜ëŸ‰",
        "ê±°ë˜ëŒ€ê¸ˆ":"ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡":"ì‹œê°€ì´ì•¡(ì›)"
    }
    for k,v in cmap.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k:v})
    if "ë‚ ì§œ" in df.columns:
        try: df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"])
        except: pass
    if "ì¢…ëª©ì½”ë“œ" in df.columns:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.replace(".0","", regex=False).map(z6)
    else:
        df["ì¢…ëª©ì½”ë“œ"] = None
    if "ì‹œì¥" not in df.columns:
        df["ì‹œì¥"] = "ALL"
    if "ì¢…ëª©ëª…" not in df.columns:
        df["ì¢…ëª©ëª…"] = None
    # ìˆ«ì ìºìŠ¤íŒ…
    for c in ["ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€","ê±°ë˜ëŸ‰","ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡(ì›)","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)",
              "RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","EBS",
              "ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]:
        if c in df.columns:
            df[c] = nz_num(df[c])
    return ensure_turnover(df)

# -------- ì´ë¦„ë§µ --------
@st.cache_data(ttl=6*60*60)
def load_name_map() -> pd.DataFrame | None:
    try:
        m = load_csv_url(CODES_URL)
        if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
    except Exception:
        pass
    if os.path.exists(LOCAL_MAP):
        try:
            m = load_csv_path(LOCAL_MAP)
            if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
                m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
                return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass
    if FDR_OK:
        try:
            lst = fdr.StockListing("KRX")
            m = lst.rename(columns={"Code":"ì¢…ëª©ì½”ë“œ","Name":"ì¢…ëª©ëª…"})[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]]
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m.drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass
    if PYKRX_OK:
        today = datetime.now().strftime("%Y%m%d")
        rows = []
        try:
            for mk in ["KOSPI","KOSDAQ","KONEX"]:
                lst = stock.get_market_ticker_list(today, market=mk) or []
                for t in lst:
                    try: nm = stock.get_market_ticker_name(t)
                    except Exception: nm = None
                    rows.append({"ì¢…ëª©ì½”ë“œ": str(t).zfill(6), "ì¢…ëª©ëª…": nm})
            m = pd.DataFrame(rows).dropna().drop_duplicates("ì¢…ëª©ì½”ë“œ")
            return m if len(m) else None
        except Exception:
            return None
    return None

def apply_names(df: pd.DataFrame) -> pd.DataFrame:
    mp = load_name_map()
    if mp is not None:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
        if "ì¢…ëª©ëª…" not in df.columns: df["ì¢…ëª©ëª…"] = None
        df = df.merge(mp, on="ì¢…ëª©ì½”ë“œ", how="left", suffixes=("","_map"))
        df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna(df["ì¢…ëª©ëª…_map"])
        df = df.drop(columns=[c for c in df.columns if c.endswith("_map")], errors="ignore")
    df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna("(ì´ë¦„ì—†ìŒ)")
    return df

# -------- ë¡œë“œ --------
try:
    df_raw = load_csv_url(RAW_URL); log_src(df_raw, "remote", RAW_URL)
except Exception:
    if os.path.exists(LOCAL_RAW):
        df_raw = load_csv_path(LOCAL_RAW); log_src(df_raw, "local", LOCAL_RAW)
    else:
        st.error("âŒ CSVê°€ ì—†ìŠµë‹ˆë‹¤. Actions ìˆ˜ì§‘ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

df = normalize_cols(df_raw)
df = apply_names(df)
latest = df.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"]).groupby("ì¢…ëª©ì½”ë“œ").tail(1) if "ë‚ ì§œ" in df.columns else df.copy()

# -------- í•˜ë“œ ìœ ë™ì„± ì»· --------
def liquidity_gate(x_turn: pd.Series, market: pd.Series) -> pd.Series:
    min_map = {"KOSPI": MIN_TURN_KOSPI, "KOSDAQ": MIN_TURN_KOSDAQ}
    mins = market.map(min_map).fillna(MIN_TURN_DEFAULT)
    return nz_num(x_turn) >= mins

# -------- ì •ê·œí™” ìœ í‹¸ --------
def cap_q(s: pd.Series, q=90, floor=1.0):
    s = nz_num(s)
    if s.notna().sum()==0: return floor
    c = np.nanpercentile(s, q)
    if not np.isfinite(c) or c<=0: c=floor
    return float(max(c, floor))

def pct_norm_pos(s: pd.Series, q=90, floor=1.0):
    s = nz_num(s).clip(lower=0)
    cap = cap_q(s, q=q, floor=floor)
    return np.clip(s / cap, 0, 1)

def inv_dist_norm(dist: pd.Series, cap):
    d = nz_num(dist)
    return np.clip(1 - (d / cap), 0, 1)

# -------- ì „ëµ ë¼ìš°í„°(ê°„ì´) --------
def route_tag(row) -> str:
    rsi = row.get("RSI14", np.nan)
    slope = row.get("MACD_slope", np.nan)
    kairi = row.get("ä¹–é›¢%", np.nan)
    r5 = row.get("ret_5d_%", np.nan)
    near = row.get("Now%", np.nan)

    # ê¸°ì¤€: ëŒíŒŒ(BRK) / ëˆŒë¦¼(PULL) / ì¶”ì„¸(TREND) / ë˜ëŒë¦¼(MR)
    if pd.notna(r5) and pd.notna(near) and pd.notna(slope):
        if (r5 >= 3) and (near <= 0.7) and (slope > 0) and (abs(kairi) <= 6):
            return "ğŸ”¼ BRK"
    if pd.notna(rsi) and pd.notna(near):
        if (45 <= rsi <= 60) and (near <= 1.0) and (abs(kairi) <= 5):
            return "â†©ï¸ PULL"
    if pd.notna(slope) and slope > 0 and pd.notna(r5) and r5 > 0 and abs(kairi) <= 7:
        return "ğŸ“ˆ TREND"
    if pd.notna(rsi) and (rsi >= 67 or rsi <= 40):
        return "ğŸ” MR"
    return "â€”"

# -------- P_hit êµì •(ë¡œê·¸ ìˆìœ¼ë©´ ì´ìš©) --------
@st.cache_data(ttl=300)
def load_trade_logs(path="data/trade_logs.csv"):
    if os.path.exists(path):
        try:
            d = pd.read_csv(path)
            # ê¸°ëŒ€ ì»¬ëŸ¼: code, hit(0/1), score(float)
            if {"code","hit","score"}.issubset(d.columns):
                d["hit"] = nz_num(d["hit"]).clip(0,1)
                d["score"] = nz_num(d["score"])
                return d.dropna(subset=["score","hit"])
        except Exception:
            return None
    return None

def calibrate_p_hit(raw_score: pd.Series, ers_norm: pd.Series) -> pd.Series:
    # ë² ì´ìŠ¤: 0~100 ì ìˆ˜ â†’ 0~1 ë¡œì§“í˜• ë§¤í•‘(ì™„ë§Œ)
    x = nz_num(raw_score).fillna(0)/100.0
    base = 1/(1 + np.exp(-4*(x-0.55)))   # ì¤‘ì‹¬ 55ì  ë¶€ê·¼
    # ERS ë³´ì •(í’ˆì§ˆ ì‹œê·¸ë„)
    e = np.clip(nz_num(ers_norm), 0, 1).fillna(0)
    base = np.clip(0.85*base + 0.15*e, 0, 1)

    logs = load_trade_logs()
    if logs is None or logs.empty:
        return base

    # ë‹¨ìˆœ í”Œë«-ë¹ˆ êµì •: ì ìˆ˜ 10ë¶„ìœ„ â†’ ì‹¤ì¸¡ hit ë¹„ìœ¨ë¡œ ì¬ë§¤í•‘
    df = pd.DataFrame({"score": x, "base": base})
    # ë¡œê·¸ë¥¼ 10ë¶„ìœ„ë¡œ ì§‘ê³„
    logs = logs.copy()
    logs["bin"] = pd.qcut(logs["score"], q=10, duplicates="drop")
    by = logs.groupby("bin", as_index=False)["hit"].mean().rename(columns={"hit":"obs"})
    # í˜„ì¬ xë„ ê°™ì€ ë°©ì‹ìœ¼ë¡œ êµ¬ê°„í™”
    try:
        ref = pd.qcut(x, q=len(by), duplicates="drop")
        ref = pd.DataFrame({"bin": ref})
        ref = ref.merge(by, on="bin", how="left")
        cal = ref["obs"].fillna(base)
        return cal.clip(0,1)
    except Exception:
        return base

# -------- Composite Score --------
def build_global_score(lat: pd.DataFrame) -> pd.DataFrame:
    x = lat.copy()

    # í•„ìˆ˜ ìˆ˜ì¹˜
    for c in ["ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","MACD_slope",
              "Vol_Z","ä¹–é›¢%","ret_5d_%","ret_10d_%","EBS","MACD_hist"]:
        if c not in x.columns: x[c]=np.nan

    close = nz_num(x["ì¢…ê°€"])
    entry = nz_num(x["ì¶”ì²œë§¤ìˆ˜ê°€"])
    stop  = nz_num(x["ì†ì ˆê°€"])
    t1    = nz_num(x["ì¶”ì²œë§¤ë„ê°€1"])
    turn  = nz_num(x["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"])
    rsi   = nz_num(x["RSI14"])
    slope = nz_num(x["MACD_slope"])
    volz  = nz_num(x["Vol_Z"])
    kairi = nz_num(x["ä¹–é›¢%"])
    r5    = nz_num(x["ret_5d_%"])
    r10   = nz_num(x["ret_10d_%"])
    ebs   = nz_num(x["EBS"]).fillna(0)

    # RR1, ì—¬ìœ , ê·¼ì ‘
    rr_den = (entry - stop)
    rr1 = (t1 - entry) / rr_den.replace(0, np.nan)
    rr1 = rr1.mask(entry.isna() | stop.isna() | t1.isna())
    now_gap = (close - entry).abs() / entry * 100
    t1_room = (t1 - close) / close * 100
    sl_room = (close - stop) / close * 100

    # ì •ê·œí™”
    rr_norm   = pct_norm_pos(rr1, q=90, floor=1.0)
    t1_norm   = np.clip(t1_room / cap_q(t1_room, q=90, floor=5.0), 0, 1)
    sl_norm   = np.clip(sl_room / cap_q(sl_room, q=90, floor=3.0), 0, 1)
    near_norm = inv_dist_norm(now_gap, cap=cap_q(now_gap, q=75, floor=1.0))
    ers_bits = (ebs>=PASS_EBS).astype(int) + (slope>0).astype(int) + ((rsi>=45)&(rsi<=65)).astype(int)
    ers_norm = np.clip(ers_bits/3.0, 0, 1)
    slope_pos_norm = pct_norm_pos(slope, q=90, floor=1.0)
    rsi_center = 1 - np.minimum((rsi-55).abs()/10, 1)           # 55ì— ê°€ê¹Œìš¸ìˆ˜ë¡ 1 (Â±10)
    rsi_center = rsi_center.clip(0,1).fillna(0)
    mom_norm = np.clip(0.5*ers_norm + 0.3*slope_pos_norm + 0.2*rsi_center, 0, 1)

    # ìœ ë™ì„±: ê±°ë˜ëŒ€ê¸ˆ í¼ì„¼íƒ€ì¼ ìŠ¤ì¼€ì¼
    if turn.notna().any():
        lo = np.nanpercentile(turn, 30) if np.isfinite(np.nanpercentile(turn.dropna(), 30)) else np.nanmin(turn)
        hi = np.nanpercentile(turn, 90) if np.isfinite(np.nanpercentile(turn.dropna(), 90)) else np.nanmax(turn)
        span = max(hi - lo, 1e-9)
        liq_norm = np.clip((turn - lo) / span, 0, 1)
    else:
        liq_norm = pd.Series(0.0, index=x.index)

    # ê¸°ìˆ  ê· í˜•: VolZâ‰ˆ1 + |ä¹–é›¢| ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ
    vol_sweet = 1 - np.minimum((volz - 1).abs()/3, 1)
    vol_sweet = vol_sweet.clip(0,1).fillna(0)
    kairi_norm = 1 - np.minimum(kairi.abs()/cap_q(kairi.abs(), q=80, floor=3.0), 1)
    kairi_norm = kairi_norm.clip(0,1).fillna(0)
    tec_norm = np.clip(0.6*vol_sweet + 0.4*kairi_norm, 0, 1)

    # ê°€ì¤‘í•©(0~100)
    c_rr   = 100*(W_RR*rr_norm)
    c_t1   = 100*(W_T1*t1_norm)
    c_sl   = 100*(W_SL*sl_norm)
    c_near = 100*(W_NEAR*near_norm)
    c_mom  = 100*(W_MOM*mom_norm)
    c_liq  = 100*(W_LIQ*liq_norm)
    c_tec  = 100*(W_TEC*tec_norm)
    base_score = c_rr + c_t1 + c_sl + c_near + c_mom + c_liq + c_tec

    # í˜ë„í‹°
    pen = pd.Series(0.0, index=x.index)
    pen += P_OVERHEAT_5D * np.clip((r5 - 10)/10, 0, 1)
    pen += P_OVERHEAT_10D* np.clip((r10 - 20)/20, 0, 1)
    pen += P_RSI_OUT * ((rsi < 45) | (rsi > 65)).astype(float)
    pen += P_MACD_NEG * (slope < 0).astype(float)
    near_cap = cap_q(now_gap, q=75, floor=1.0)
    pen += P_NEAR_FAR * np.clip((now_gap - near_cap)/near_cap, 0, 1)
    if turn.notna().any():
        p20 = np.nanpercentile(turn.dropna(), 20) if turn.dropna().size else -np.inf
        pen += P_LIQ_LOW * (turn < p20).astype(float)
    pen += P_VOL_SPIKE * (volz > 3).astype(float)

    score = np.clip(base_score - pen, 0, 100)

    # ê²°ê³¼ í•©ì¹˜ê¸°
    x["RR1"]        = rr1
    x["Now%"]       = now_gap
    x["T1ì—¬ìœ %"]     = t1_room
    x["SLì—¬ìœ %"]     = sl_room
    x["ERS"]        = ers_bits.astype(float)
    x["LDY_SCORE"]  = score.round(1)
    x["_cRR"] = c_rr.round(1); x["_cT1"] = c_t1.round(1); x["_cSL"] = c_sl.round(1)
    x["_cNEAR"] = c_near.round(1); x["_cMOM"] = c_mom.round(1); x["_cLIQ"] = c_liq.round(1); x["_cTEC"] = c_tec.round(1)
    x["_PEN"] = pen.round(1)

    # ë¼ìš°í„°
    # Now% ë“±ì€ ë°©ê¸ˆ ë§Œë“  ì»¬ëŸ¼ ì‚¬ìš©
    x["ROUTE"] = (x.apply(route_tag, axis=1) if len(x) else "â€”")

    # ìœ ë™ì„± ê²Œì´íŠ¸
    x["_GATE_OK"] = liquidity_gate(x["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"], x["ì‹œì¥"]).fillna(False)

    # ë­í¬
    x = x.sort_values("LDY_SCORE", ascending=False, na_position="last")
    x["LDY_RANK"] = range(1, len(x)+1)

    # WHY ë¬¸ìì—´(ìš”ì•½)
    x["WHY"] = (
        "RR+" + x["_cRR"].fillna(0).astype(str) + ", "
        "T1+" + x["_cT1"].fillna(0).astype(str) + ", "
        "SL+" + x["_cSL"].fillna(0).astype(str) + ", "
        "NEAR+" + x["_cNEAR"].fillna(0).astype(str) + ", "
        "MOM+" + x["_cMOM"].fillna(0).astype(str) + ", "
        "LIQ+" + x["_cLIQ"].fillna(0).astype(str) + ", "
        "TEC+" + x["_cTEC"].fillna(0).astype(str) + ", "
        "PENâˆ’" + x["_PEN"].fillna(0).astype(str)
    )
    return x

scored = build_global_score(latest)

# ë­í‚¹ í¬í•¨ ì¡°ê±´: ì¶”ì²œ/ì†ì ˆ/ëª©í‘œ1/ì¢…ê°€ ìˆì–´ì•¼
scored = scored.dropna(subset=["ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¢…ê°€"])

# í’ˆì§ˆê²Œì´íŠ¸ & ìœ ë™ì„±
base = scored[(nz_num(scored.get("EBS")) >= PASS_EBS) & (scored["_GATE_OK"])].copy()

# í›„ë³´ ë¶€ì¡± ì‹œ ìë™ ì™„í™”
if len(base) < 10:
    fb = scored[nz_num(scored.get("EBS")) >= (PASS_EBS-1)].copy()
    MIN_KOSPI_F, MIN_KOSDAQ_F = 150.0, 80.0
    mm = {"KOSPI": MIN_KOSPI_F, "KOSDAQ": MIN_KOSDAQ_F}
    fb["_min_turn"] = fb["ì‹œì¥"].map(mm).fillna(MIN_TURN_DEFAULT)
    fb = fb[ nz_num(fb["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"]) >= fb["_min_turn"] ]
    base_codes = set(base["ì¢…ëª©ì½”ë“œ"])
    fill = fb[~fb["ì¢…ëª©ì½”ë“œ"].isin(base_codes)]
    base = pd.concat([base, fill]).sort_values("LDY_SCORE", ascending=False).head(50)

# ìµœì¢… Top10
top10 = base.sort_values("LDY_SCORE", ascending=False, na_position="last").head(10).copy()
top10["í†µê³¼"] = np.where(nz_num(top10.get("EBS")) >= PASS_EBS, "ğŸš€", "")

# P_hit(íƒ€ê²©í™•ë¥ ) ì¶”ì •
ers_norm_tmp = np.clip(nz_num(top10["ERS"])/3.0, 0, 1)
top10["P_hit"] = (calibrate_p_hit(top10["LDY_SCORE"], ers_norm_tmp) * 100).round(1)

# -------- Render --------
def colcfg(df):
    cfg={}
    def add(k, col):
        if k in df.columns: cfg[k]=col
    add("LDY_RANK",  st.column_config.NumberColumn("RANK", format="%d"))
    add("í†µê³¼",       st.column_config.TextColumn(" "))
    add("ROUTE",     st.column_config.TextColumn("ROUTE"))
    add("ì‹œì¥",       st.column_config.TextColumn("ì‹œì¥"))
    add("ì¢…ëª©ëª…",     st.column_config.TextColumn("ì¢…ëª©ëª…"))
    add("ì¢…ëª©ì½”ë“œ",   st.column_config.TextColumn("ì¢…ëª©ì½”ë“œ"))
    add("LDY_SCORE", st.column_config.NumberColumn("LDY_SCORE", format="%.1f"))
    add("P_hit",     st.column_config.NumberColumn("P_hit(%)", format="%.1f"))
    add("ì¢…ê°€",        st.column_config.NumberColumn("ì¢…ê°€", format="%,d"))
    add("ì¶”ì²œë§¤ìˆ˜ê°€",  st.column_config.NumberColumn("ì¶”ì²œë§¤ìˆ˜ê°€", format="%,d"))
    add("ì†ì ˆê°€",      st.column_config.NumberColumn("ì†ì ˆê°€", format="%,d"))
    add("ì¶”ì²œë§¤ë„ê°€1", st.column_config.NumberColumn("ëª©í‘œ1", format="%,d"))
    add("ì¶”ì²œë§¤ë„ê°€2", st.column_config.NumberColumn("ëª©í‘œ2", format="%,d"))
    add("RR1",       st.column_config.NumberColumn("RR1", format="%.2f"))
    add("Now%",      st.column_config.NumberColumn("ì—”íŠ¸ë¦¬ê·¼ì ‘(%)", format="%.2f"))
    add("T1ì—¬ìœ %",    st.column_config.NumberColumn("ëª©í‘œ1ì—¬ìœ (%)", format="%.2f"))
    add("SLì—¬ìœ %",    st.column_config.NumberColumn("ì†ì ˆì—¬ìœ (%)", format="%.2f"))
    add("ERS",       st.column_config.NumberColumn("ERS", format="%.0f"))
    add("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", st.column_config.NumberColumn("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", format="%,.0f"))
    add("ì‹œê°€ì´ì•¡(ì–µì›)", st.column_config.NumberColumn("ì‹œê°€ì´ì•¡(ì–µì›)", format="%,.0f"))
    add("RSI14",     st.column_config.NumberColumn("RSI14", format="%.1f"))
    add("ä¹–é›¢%",      st.column_config.NumberColumn("ä¹–é›¢%", format="%.2f"))
    add("MACD_slope",st.column_config.NumberColumn("MACD_slope", format="%.5f"))
    add("Vol_Z",     st.column_config.NumberColumn("Vol_Z", format="%.2f"))
    add("ret_5d_%",  st.column_config.NumberColumn("5ì¼ìˆ˜ìµ%", format="%.2f"))
    add("ret_10d_%", st.column_config.NumberColumn("10ì¼ìˆ˜ìµ%", format="%.2f"))
    add("EBS",       st.column_config.NumberColumn("EBS", format="%d"))
    add("WHY",       st.column_config.TextColumn("WHY(ê¸°ì—¬ë„ ìš”ì•½)"))
    # ë‚´ë¶€ ê¸°ì—¬ë„ ì—´ì€ ë‹¤ìš´ë¡œë“œì—ë§Œ í¬í•¨(í…Œì´ë¸”ì€ ê°„ê²°í•˜ê²Œ)
    return cfg

st.subheader("ì˜¤ëŠ˜ì˜ GLOBAL TOP 10", anchor=False)

cols_show = [
    "LDY_RANK","í†µê³¼","ROUTE","ì‹œì¥","ì¢…ëª©ëª…","ì¢…ëª©ì½”ë“œ",
    "LDY_SCORE","P_hit",
    "ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2",
    "RR1","Now%","T1ì—¬ìœ %","SLì—¬ìœ %","ERS",
    "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)",
    "RSI14","ä¹–é›¢%","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","EBS",
    "WHY"
]
for c in cols_show:
    if c not in top10.columns: top10[c]=np.nan

# í˜•ì‹ ì•ˆì •í™”
fmt = top10.copy()
int_cols = ["LDY_RANK","ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","EBS"]
for c in int_cols:
    if c in fmt.columns:
        fmt[c] = nz_num(fmt[c]).round(0).astype("Int64")
float_cols = ["LDY_SCORE","P_hit","RR1","Now%","T1ì—¬ìœ %","SLì—¬ìœ %","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)",
              "RSI14","ä¹–é›¢%","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%"]
for c in float_cols:
    if c in fmt.columns:
        fmt[c] = nz_num(fmt[c])

st.data_editor(
    fmt[cols_show],
    key="tbl_global_top10_v44",
    width="stretch", height=560,
    hide_index=True, disabled=True, num_rows="fixed",
    column_config=colcfg(fmt),
)

# ë‹¤ìš´ë¡œë“œ (ì„¤ëª…ìš© ë‚´ë¶€ ê¸°ì—¬ë„ í¬í•¨)
cols_download = cols_show + ["_cRR","_cT1","_cSL","_cNEAR","_cMOM","_cLIQ","_cTEC","_PEN"]
for c in cols_download:
    if c not in top10.columns: top10[c] = np.nan

st.download_button(
    "ğŸ“¥ GLOBAL TOP 10 (CSV)",
    data=top10[cols_download].to_csv(index=False, encoding="utf-8-sig"),
    file_name="ldy_global_top10.csv",
    mime="text/csv",
    key="dl_global_top10_v44",
)

# ===== [FIX] ì „ì²´ ë­í‚¹ CSV: ëˆ„ë½ ì»¬ëŸ¼ ìë™ ë³´ê°• í›„ ë‚´ë³´ë‚´ê¸° =====
def ensure_all_columns(df: pd.DataFrame, wanted: list[str]) -> pd.DataFrame:
    out = df.copy()
    missing = [c for c in wanted if c not in out.columns]
    # ë””ë²„ê·¸ ê²¸ í™”ë©´ì— ê²½ê³ 
    if missing:
        st.warning("âš ï¸ ë‚´ë³´ë‚´ê¸° ëˆ„ë½ ì»¬ëŸ¼ ìë™ ë³´ê°•: " + ", ".join(missing))
    for c in missing:
        out[c] = np.nan
    # ì •ë ¬ëœ ê³ ì • ì»¬ëŸ¼ ìˆœì„œë¡œ ë°˜í™˜
    return out[wanted]

# Top10ì—ì„œ ì“°ë˜ ê³ ì • í‘œì‹œ ì»¬ëŸ¼(ìˆœì„œ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©)
full_cols = [
    "LDY_RANK","í†µê³¼","ì‹œì¥","ì¢…ëª©ëª…","ì¢…ëª©ì½”ë“œ","LDY_SCORE",
    "ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2",
    "RR1","Now%","T1ì—¬ìœ %","SLì—¬ìœ %","ERS",
    "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_slope",
    "Vol_Z","ret_5d_%","ret_10d_%","EBS","ê·¼ê±°"
]

# ì „ì²´ ë­í‚¹ ë°ì´íƒ€ ì¤€ë¹„
export_df = scored.sort_values("LDY_SCORE", ascending=False, na_position="last").copy()

# 'í†µê³¼' ì¹¼ëŸ¼ì´ ì—†ëŠ” ê²½ìš°(Top10ì—ì„œë§Œ ë§Œë“¤ì—ˆì„ ìˆ˜ ìˆìŒ) â†’ ì „ì²´ì—ë„ ìƒì„±
if "í†µê³¼" not in export_df.columns:
    export_df["í†µê³¼"] = np.where(
        pd.to_numeric(export_df.get("EBS"), errors="coerce") >= PASS_EBS, "ğŸš€", ""
    )

# ì»¬ëŸ¼ ìë™ ë³´ê°• í›„, ìƒìœ„ Ní–‰ë§Œ ë‚´ë³´ë‚´ê¸°
export_ready = ensure_all_columns(export_df, full_cols).head(2000)

st.download_button(
    "ğŸ“¥ ì „ì²´ ë­í‚¹ (CSV, ìµœëŒ€ 2,000í–‰)",
    data=export_ready.to_csv(index=False, encoding="utf-8-sig"),
    file_name="ldy_global_rank_full.csv",
    mime="text/csv",
    key="dl_global_full",
)
# ===============================================================

