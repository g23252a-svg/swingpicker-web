# -*- coding: utf-8 -*-
"""
LDY Pro Trader v4.0 â€” Global Rank (Single Composite Score)
- í•œ í™”ë©´: 'ì˜¤ëŠ˜ì˜ GLOBAL TOP 10'ë§Œ ê³ ì • ë…¸ì¶œ (ê°€ì¤‘ì¹˜/ìŠ¬ë¼ì´ë” ì—†ìŒ)
- ëª¨ë“  ì§€í‘œ(ë¦¬ìŠ¤í¬Â·ë³´ìƒÂ·ìœ ë™ì„±Â·ëª¨ë©˜í…€Â·ê³¼ì—´/ê³¼ë§¤ìˆ˜Â·ê·¼ì ‘ë„ ë“±) â†’ ë‹¨ì¼ ì ìˆ˜ LDY_SCORE(0~100)
- LDY_RANK = LDY_SCORE ë‚´ë¦¼ì°¨ìˆœ ìˆœìœ„ (1ìœ„ê°€ ê°€ì¥ ìœ ë§)
- ìœ ë™ì„± í•˜ë“œì»·: KOSPIâ‰¥200ì–µ, KOSDAQâ‰¥100ì–µ (ë¹„ë©´ ìë™ ì™„í™”)
"""

import os, io, math, requests, numpy as np, pandas as pd, streamlit as st
from datetime import datetime

# -------- Optional deps (ì´ë¦„ ë§µ í´ë°±ìš©) --------
try:
    from pykrx import stock
    PYKRX_OK = True
except Exception:
    PYKRX_OK = False

try:
    import FinanceDataReader as fdr
    FDR_OK = True
except Exception:
    FDR_OK = False

# -------- Page --------
st.set_page_config(page_title="LDY Pro Trader v4.0 â€” Global Rank", layout="wide")
st.title("ğŸ† LDY Pro Trader v4.0 â€” Global Rank")
st.caption("ëª¨ë“  ì§€í‘œë¥¼ ë‹¨ì¼ ì ìˆ˜ë¡œ ì¢…í•© â†’ 1ìœ„ê°€ ê°€ì¥ ìœ ë§í•œ ì¢…ëª©")

# -------- Constants --------
RAW_URL   = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/recommend_latest.csv"
LOCAL_RAW = "data/recommend_latest.csv"
CODES_URL = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/krx_codes.csv"
LOCAL_MAP = "data/krx_codes.csv"

PASS_EBS = 4                 # í’ˆì§ˆ ê²Œì´íŠ¸
MIN_TURN_KOSPI = 200.0       # ìœ ë™ì„± í•˜ë“œì»·
MIN_TURN_KOSDAQ = 100.0
MIN_TURN_DEFAULT = 100.0

# ê³ ì • ê°€ì¤‘ì¹˜(í•©=1.0) â€” ì¡°ì • UI ì—†ìŒ
W_RR   = 0.25  # ë³´ìƒëŒ€ë¹„ìœ„í—˜ (RR1)
W_T1   = 0.18  # ëª©í‘œ1 ì—¬ìœ 
W_SL   = 0.12  # ì†ì ˆ ì—¬ìœ 
W_NEAR = 0.12  # í˜„ì¬ê°€-ì¶”ì²œê°€ ê·¼ì ‘
W_MOM  = 0.10  # ëª¨ë©˜í…€(ERS+MACD_slope+RSIì¤‘ì‹¬ ë³´ë„ˆìŠ¤)
W_LIQ  = 0.13  # ìœ ë™ì„±(ê±°ë˜ëŒ€ê¸ˆ í¼ì„¼íƒ€ì¼)
W_TEC  = 0.10  # ê¸°ìˆ ê· í˜•(VolZ ìŠ¤ìœ—ìŠ¤íŒŸ +ä¹–é›¢ ì•ˆì •)

# í˜ë„í‹°(ì ìˆ˜ì—ì„œ ì§ì ‘ ì°¨ê°, 0~30 ë²”ìœ„ ê°€ì •)
P_OVERHEAT_5D = 6.0   # ë‹¨ê¸° ê³¼ì—´(ret_5d_%) ê³¼ë„ ì‹œ
P_OVERHEAT_10D= 6.0   # ì¤‘ê¸° ê³¼ì—´(ret_10d_%)
P_RSI_OUT     = 4.0   # RSI 45~65 ë²—ì–´ë‚¨
P_MACD_NEG    = 4.0   # MACD ê¸°ìš¸ê¸° ìŒìˆ˜
P_NEAR_FAR    = 4.0   # ì—”íŠ¸ë¦¬ì—ì„œ ë„ˆë¬´ ë©€ì–´ì§
P_LIQ_LOW     = 4.0   # ìœ ë™ì„± í•˜ìœ„ê¶Œ
P_VOL_SPIKE   = 2.0   # ë³€ë™ì„± ê³¼ë„ ìŠ¤íŒŒì´í¬(VolZâ‰«)

# -------- IO helpers --------
@st.cache_data(ttl=300)
def load_csv_url(url: str) -> pd.DataFrame:
    r = requests.get(url, timeout=30); r.raise_for_status()
    return pd.read_csv(io.BytesIO(r.content))

@st.cache_data(ttl=300)
def load_csv_path(path: str) -> pd.DataFrame:
    return pd.read_csv(path, encoding="utf-8")

def log_src(df: pd.DataFrame, src: str, url_or_path: str):
    st.info(f"ìƒíƒœ âœ… ë°ì´í„° ë¡œë“œ: {src}\n\n{url_or_path}")
    st.success(f"ğŸ“… í‘œì‹œì‹œê°: {pd.Timestamp.now(tz='Asia/Seoul').strftime('%Y-%m-%d %H:%M')} Â· í–‰ìˆ˜: {len(df):,}")

# -------- Utils --------
def z6(x) -> str:
    s = str(x)
    return s.zfill(6) if s.isdigit() else s

def ensure_turnover(df: pd.DataFrame) -> pd.DataFrame:
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" not in df.columns:
        base = None
        if "ê±°ë˜ëŒ€ê¸ˆ(ì›)" in df.columns:
            base = pd.to_numeric(df["ê±°ë˜ëŒ€ê¸ˆ(ì›)"], errors="coerce")
        elif all(c in df.columns for c in ["ê±°ë˜ëŸ‰","ì¢…ê°€"]):
            base = pd.to_numeric(df["ê±°ë˜ëŸ‰"], errors="coerce") * pd.to_numeric(df["ì¢…ê°€"], errors="coerce")
        if base is not None:
            df["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] = (base/1e8).round(2)
    return df

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    cmap = {
        "Date":"ë‚ ì§œ","date":"ë‚ ì§œ",
        "Code":"ì¢…ëª©à¤•à¥‹ë“œ","í‹°ì»¤":"ì¢…ëª©ì½”ë“œ","ticker":"ì¢…ëª©ì½”ë“œ",
        "Name":"ì¢…ëª©ëª…","name":"ì¢…ëª©ëª…",
        "Open":"ì‹œê°€","High":"ê³ ê°€","Low":"ì €ê°€","Close":"ì¢…ê°€","Volume":"ê±°ë˜ëŸ‰",
        "ê±°ë˜ëŒ€ê¸ˆ":"ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡":"ì‹œê°€ì´ì•¡(ì›)"
    }
    for k,v in cmap.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k:v})
    if "ë‚ ì§œ" in df.columns:
        try: df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"])
        except: pass
    if "ì¢…ëª©ì½”ë“œ" in df.columns:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.replace(".0","", regex=False).map(z6)
    else:
        df["ì¢…ëª©ì½”ë“œ"] = None
    if "ì‹œì¥" not in df.columns:
        df["ì‹œì¥"] = "ALL"
    if "ì¢…ëª©ëª…" not in df.columns:
        df["ì¢…ëª©ëª…"] = None
    for c in ["ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€","ê±°ë˜ëŸ‰","ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡(ì›)","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)",
              "RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","EBS",
              "ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return ensure_turnover(df)

# -------- ì´ë¦„ë§µ --------
@st.cache_data(ttl=6*60*60)
def load_name_map() -> pd.DataFrame | None:
    try:
        m = load_csv_url(CODES_URL)
        if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
    except Exception:
        pass
    if os.path.exists(LOCAL_MAP):
        try:
            m = load_csv_path(LOCAL_MAP)
            if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
                m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
                return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass
    if FDR_OK:
        try:
            lst = fdr.StockListing("KRX")
            m = lst.rename(columns={"Code":"ì¢…ëª©ì½”ë“œ","Name":"ì¢…ëª©ëª…"})[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]]
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m.drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass
    if PYKRX_OK:
        today = datetime.now().strftime("%Y%m%d")
        rows = []
        try:
            for mk in ["KOSPI","KOSDAQ","KONEX"]:
                lst = stock.get_market_ticker_list(today, market=mk) or []
                for t in lst:
                    nm = None
                    try: nm = stock.get_market_ticker_name(t)
                    except Exception: pass
                    rows.append({"ì¢…ëª©ì½”ë“œ": str(t).zfill(6), "ì¢…ëª©ëª…": nm})
            m = pd.DataFrame(rows).dropna().drop_duplicates("ì¢…ëª©ì½”ë“œ")
            return m if len(m) else None
        except Exception:
            return None
    return None

def apply_names(df: pd.DataFrame) -> pd.DataFrame:
    mp = load_name_map()
    if mp is not None:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
        if "ì¢…ëª©ëª…" not in df.columns: df["ì¢…ëª©ëª…"] = None
        df = df.merge(mp, on="ì¢…ëª©ì½”ë“œ", how="left", suffixes=("","_map"))
        df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna(df["ì¢…ëª©ëª…_map"])
        df = df.drop(columns=[c for c in df.columns if c.endswith("_map")], errors="ignore")
    df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna("(ì´ë¦„ì—†ìŒ)")
    return df

# -------- Load --------
try:
    df_raw = load_csv_url(RAW_URL); log_src(df_raw, "remote", RAW_URL)
except Exception:
    if os.path.exists(LOCAL_RAW):
        df_raw = load_csv_path(LOCAL_RAW); log_src(df_raw, "local", LOCAL_RAW)
    else:
        st.error("âŒ CSVê°€ ì—†ìŠµë‹ˆë‹¤. Actions ìˆ˜ì§‘ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

df = normalize_cols(df_raw)
df = apply_names(df)

# ìµœì‹ í–‰ë§Œ ì‚¬ìš©
latest = df.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"]).groupby("ì¢…ëª©ì½”ë“œ").tail(1) if "ë‚ ì§œ" in df.columns else df.copy()

# -------- í•˜ë“œ ìœ ë™ì„± ì»· --------
def liquidity_gate(x: pd.Series, market: pd.Series) -> pd.Series:
    min_map = {"KOSPI": MIN_TURN_KOSPI, "KOSDAQ": MIN_TURN_KOSDAQ}
    mins = market.map(min_map).fillna(MIN_TURN_DEFAULT)
    return x >= mins

# -------- ì •ê·œí™” ìœ í‹¸ --------
def cap_q(s: pd.Series, q=90, floor=1.0):
    s = pd.to_numeric(s, errors="coerce")
    if s.notna().sum()==0: return floor
    c = np.nanpercentile(s, q)
    if not np.isfinite(c) or c<=0: c=floor
    return max(float(c), floor)

def pct_norm_pos(s: pd.Series, q=90, floor=1.0):
    # ì–‘ìˆ˜ë§Œ ì¸ì •(ìŒìˆ˜â†’0), q-ìº¡ìœ¼ë¡œ 0~1 ìŠ¤ì¼€ì¼
    s = pd.to_numeric(s, errors="coerce").clip(lower=0)
    cap = cap_q(s, q=q, floor=floor)
    return np.clip(s / cap, 0, 1)

def inv_dist_norm(dist: pd.Series, cap):
    # 0ì¼ìˆ˜ë¡ 1, cap ë„˜ìœ¼ë©´ 0
    d = pd.to_numeric(dist, errors="coerce")
    return np.clip(1 - (d / cap), 0, 1)

# -------- Composite Score --------
def build_global_score(lat: pd.DataFrame) -> pd.DataFrame:
    x = lat.copy()

    # í•„ìˆ˜ ìˆ˜ì¹˜
    for c in ["ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","RSI14","MACD_slope","Vol_Z","ä¹–é›¢%","ret_5d_%","ret_10d_%","EBS"]:
        if c not in x.columns: x[c]=np.nan

    close = pd.to_numeric(x["ì¢…ê°€"], errors="coerce")
    entry = pd.to_numeric(x["ì¶”ì²œë§¤ìˆ˜ê°€"], errors="coerce")
    stop  = pd.to_numeric(x["ì†ì ˆê°€"], errors="coerce")
    t1    = pd.to_numeric(x["ì¶”ì²œë§¤ë„ê°€1"], errors="coerce")
    turn  = pd.to_numeric(x["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"], errors="coerce")
    rsi   = pd.to_numeric(x["RSI14"], errors="coerce")
    slope = pd.to_numeric(x["MACD_slope"], errors="coerce")
    volz  = pd.to_numeric(x["Vol_Z"], errors="coerce")
    kairi = pd.to_numeric(x["ä¹–é›¢%"], errors="coerce")
    r5    = pd.to_numeric(x["ret_5d_%"], errors="coerce")
    r10   = pd.to_numeric(x["ret_10d_%"], errors="coerce")
    ebs   = pd.to_numeric(x["EBS"], errors="coerce").fillna(0)

    # RR1, ì—¬ìœ , ê·¼ì ‘
    rr_den = (entry - stop)
    rr1 = (t1 - entry) / rr_den.replace(0, np.nan)
    rr1 = rr1.mask(entry.isna() | stop.isna() | t1.isna())
    now_gap = (close - entry).abs() / entry * 100
    t1_room = (t1 - close) / close * 100
    sl_room = (close - stop) / close * 100

    # ì •ê·œí™”(ìƒí•œ=ë¶„í¬ ê¸°ë°˜, ê³¼í•œ outlier ë°©ì§€)
    rr_norm   = pct_norm_pos(rr1, q=90, floor=1.0)
    t1_norm   = np.clip(t1_room / cap_q(t1_room, q=90, floor=5.0), 0, 1)
    sl_norm   = np.clip(sl_room / cap_q(sl_room, q=90, floor=3.0), 0, 1)
    near_norm = inv_dist_norm(now_gap, cap=cap_q(now_gap, q=75, floor=1.0))
    # ëª¨ë©˜í…€ ë¬¶ìŒ: ERS(=EBSâ‰¥4 + slope>0 + RSI in-band) + slope(ì–‘ìˆ˜ë¶€ë¶„) + RSI ì¤‘ì‹¬ë³´ë„ˆìŠ¤
    ers_bits = (ebs>=PASS_EBS).astype(int) + (slope>0).astype(int) + ((rsi>=45)&(rsi<=65)).astype(int)
    ers_norm = np.clip(ers_bits/3.0, 0, 1)
    slope_pos_norm = pct_norm_pos(slope, q=90, floor=1.0)
    rsi_center = 1 - np.minimum((rsi-55).abs()/10, 1)           # 55ì— ê°€ê¹Œìš¸ìˆ˜ë¡ 1 (Â±10 ë²”ìœ„)
    rsi_center = rsi_center.clip(lower=0, upper=1).fillna(0)
    mom_norm = np.clip(0.5*ers_norm + 0.3*slope_pos_norm + 0.2*rsi_center, 0, 1)

    # ìœ ë™ì„±: ê±°ë˜ëŒ€ê¸ˆ í¼ì„¼íƒ€ì¼ ìŠ¤ì¼€ì¼
    if turn.notna().any():
        lo = np.nanpercentile(turn, 30)
        hi = np.nanpercentile(turn, 90)
        span = max(hi - lo, 1e-9)
        liq_norm = np.clip((turn - lo) / span, 0, 1)
    else:
        liq_norm = pd.Series(0.0, index=x.index)

    # ê¸°ìˆ  ê· í˜•: VolZ ìŠ¤ìœ—ìŠ¤íŒŸ(â‰ˆ1) +ä¹–é›¢ ì•ˆì •(ì ˆëŒ€ä¹–é›¢ ë‚®ì„ìˆ˜ë¡)
    vol_sweet = 1 - np.minimum((volz - 1).abs()/3, 1)           # 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ
    vol_sweet = vol_sweet.clip(0,1).fillna(0)
    kairi_norm = 1 - np.minimum(kairi.abs()/cap_q(kairi.abs(), q=80, floor=3.0), 1)
    kairi_norm = kairi_norm.clip(0,1).fillna(0)
    tec_norm = np.clip(0.6*vol_sweet + 0.4*kairi_norm, 0, 1)

    # ê°€ì¤‘í•© (0~100)
    base_score = 100*(W_RR*rr_norm + W_T1*t1_norm + W_SL*sl_norm + W_NEAR*near_norm + W_MOM*mom_norm + W_LIQ*liq_norm + W_TEC*tec_norm)

    # í˜ë„í‹° (ì ìˆ˜ ì°¨ê°)
    pen = pd.Series(0.0, index=x.index)

    # ë‹¨ê¸°/ì¤‘ê¸° ê³¼ì—´
    pen += P_OVERHEAT_5D * np.clip((r5 - 10)/10, 0, 1)      # 5ì¼ +10% ì´ˆê³¼ë¶€í„° ìµœëŒ€ íŒ¨ë„í‹°
    pen += P_OVERHEAT_10D* np.clip((r10 - 20)/20, 0, 1)     # 10ì¼ +20% ì´ˆê³¼ë¶€í„°

    # RSI ë°´ë“œ ì´íƒˆ(45~65)
    rsi_out = (rsi < 45) | (rsi > 65)
    pen += P_RSI_OUT * rsi_out.astype(float)

    # MACD ê¸°ìš¸ê¸° ìŒìˆ˜
    pen += P_MACD_NEG * (slope < 0).astype(float)

    # ì—”íŠ¸ë¦¬ì™€ ê´´ë¦¬ ê³¼ë‹¤
    near_cap = cap_q(now_gap, q=75, floor=1.0)
    pen += P_NEAR_FAR * np.clip((now_gap - near_cap)/near_cap, 0, 1)

    # ìœ ë™ì„± í•˜ìœ„ê¶Œ (í•˜ìœ„ 20%)
    if turn.notna().any():
        p20 = np.nanpercentile(turn, 20)
        pen += P_LIQ_LOW * (turn < p20).astype(float)

    # ë³€ë™ì„± ìŠ¤íŒŒì´í¬ (VolZ > 3)
    pen += P_VOL_SPIKE * (volz > 3).astype(float)

    score = np.clip(base_score - pen, 0, 100)
    x["RR1"]      = rr1
    x["Now%"]     = now_gap
    x["T1ì—¬ìœ %"]   = t1_room
    x["SLì—¬ìœ %"]   = sl_room
    x["ERS"]      = ers_bits.astype(float)
    x["LDY_SCORE"]= score.round(1)

    # í•˜ë“œ ìœ ë™ì„± ì»·(ê¸°ë³¸), ë¹„ë©´ ì™„í™”ìš© í”Œë˜ê·¸
    gate_ok = liquidity_gate(x["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"], x["ì‹œì¥"])
    x["_GATE_OK"] = gate_ok.fillna(False)

    # ë­í¬(ë‚´ë¦¼ì°¨ìˆœ)
    x = x.sort_values("LDY_SCORE", ascending=False, na_position="last")
    x["LDY_RANK"] = range(1, len(x)+1)
    return x

scored = build_global_score(latest)

# ê¸°ë³¸ í•„í„°: ì¶”ì²œê°€/ì†ì ˆ/ëª©í‘œ1 ëª¨ë‘ ìˆì–´ì•¼ ë­í‚¹ í¬í•¨
scored = scored.dropna(subset=["ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¢…ê°€"])

# í’ˆì§ˆê²Œì´íŠ¸(EBS) & ìœ ë™ì„± í•˜ë“œì»·
base = scored[ (pd.to_numeric(scored.get("EBS"), errors="coerce") >= PASS_EBS) & (scored["_GATE_OK"]) ].copy()

# ë¹„ê±°ë‚˜ Top10 ë¯¸ë§Œì´ë©´ ìë™ ì™„í™”(EBSâ‰¥3 + ìœ ë™ì„± ì™„í™”: KOSPI150/KOSDAQ80)
if len(base) < 10:
    fb = scored[ pd.to_numeric(scored.get("EBS"), errors="coerce") >= (PASS_EBS-1) ].copy()
    # ì™„í™” ì»·
    MIN_KOSPI_F, MIN_KOSDAQ_F = 150.0, 80.0
    mm = {"KOSPI": MIN_KOSPI_F, "KOSDAQ": MIN_KOSDAQ_F}
    fb["_min_turn"] = fb["ì‹œì¥"].map(mm).fillna(MIN_TURN_DEFAULT)
    fb = fb[ fb["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] >= fb["_min_turn"] ]
    base_codes = set(base["ì¢…ëª©ì½”ë“œ"])
    fill = fb[~fb["ì¢…ëª©ì½”ë“œ"].isin(base_codes)]
    base = pd.concat([base, fill]).sort_values("LDY_SCORE", ascending=False).head(50)

# ìµœì¢… Top 10
top10 = base.sort_values("LDY_SCORE", ascending=False, na_position="last").head(10).copy()
top10["í†µê³¼"] = np.where(pd.to_numeric(top10.get("EBS"), errors="coerce") >= PASS_EBS, "ğŸš€", "")

# -------- Render --------
def colcfg(df):
    cfg={}
    def add(k, col):
        if k in df.columns: cfg[k]=col
    add("LDY_RANK",  st.column_config.NumberColumn("RANK", format="%d"))
    add("í†µê³¼",       st.column_config.TextColumn(" "))
    add("ì‹œì¥",       st.column_config.TextColumn("ì‹œì¥"))
    add("ì¢…ëª©ëª…",     st.column_config.TextColumn("ì¢…ëª©ëª…"))
    add("ì¢…ëª©ì½”ë“œ",   st.column_config.TextColumn("ì¢…ëª©ì½”ë“œ"))
    add("LDY_SCORE", st.column_config.NumberColumn("LDY_SCORE", format="%.1f"))
    add("ì¢…ê°€",        st.column_config.NumberColumn("ì¢…ê°€", format="%,d"))
    add("ì¶”ì²œë§¤ìˆ˜ê°€",  st.column_config.NumberColumn("ì¶”ì²œë§¤ìˆ˜ê°€", format="%,d"))
    add("ì†ì ˆê°€",      st.column_config.NumberColumn("ì†ì ˆê°€", format="%,d"))
    add("ì¶”ì²œë§¤ë„ê°€1", st.column_config.NumberColumn("ëª©í‘œ1", format="%,d"))
    add("ì¶”ì²œë§¤ë„ê°€2", st.column_config.NumberColumn("ëª©í‘œ2", format="%,d"))
    add("RR1",       st.column_config.NumberColumn("RR1", format="%.2f"))
    add("Now%",      st.column_config.NumberColumn("ì—”íŠ¸ë¦¬ê·¼ì ‘(%)", format="%.2f"))
    add("T1ì—¬ìœ %",    st.column_config.NumberColumn("ëª©í‘œ1ì—¬ìœ (%)", format="%.2f"))
    add("SLì—¬ìœ %",    st.column_config.NumberColumn("ì†ì ˆì—¬ìœ (%)", format="%.2f"))
    add("ERS",       st.column_config.NumberColumn("ERS", format="%.0f"))
    add("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", st.column_config.NumberColumn("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", format="%,.0f"))
    add("ì‹œê°€ì´ì•¡(ì–µì›)", st.column_config.NumberColumn("ì‹œê°€ì´ì•¡(ì–µì›)", format="%,.0f"))
    add("RSI14",     st.column_config.NumberColumn("RSI14", format="%.1f"))
    add("ä¹–é›¢%",      st.column_config.NumberColumn("ä¹–é›¢%", format="%.2f"))
    add("MACD_slope",st.column_config.NumberColumn("MACD_slope", format="%.5f"))
    add("Vol_Z",     st.column_config.NumberColumn("Vol_Z", format="%.2f"))
    add("ret_5d_%",  st.column_config.NumberColumn("5ì¼ìˆ˜ìµ%", format="%.2f"))
    add("ret_10d_%", st.column_config.NumberColumn("10ì¼ìˆ˜ìµ%", format="%.2f"))
    add("EBS",       st.column_config.NumberColumn("EBS", format="%d"))
    add("ê·¼ê±°",       st.column_config.TextColumn("ê·¼ê±°"))
    return cfg

st.subheader("ì˜¤ëŠ˜ì˜ GLOBAL TOP 10", anchor=False)
cols = ["LDY_RANK","í†µê³¼","ì‹œì¥","ì¢…ëª©ëª…","ì¢…ëª©ì½”ë“œ","LDY_SCORE",
        "ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2",
        "RR1","Now%","T1ì—¬ìœ %","SLì—¬ìœ %","ERS",
        "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","EBS","ê·¼ê±°"]
for c in cols:
    if c not in top10.columns: top10[c]=np.nan

# í˜•ì‹ ì•ˆì •í™”
fmt = top10.copy()
int_cols = ["LDY_RANK","ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","EBS"]
for c in int_cols:
    if c in fmt.columns:
        fmt[c] = pd.to_numeric(fmt[c], errors="coerce").round(0).astype("Int64")
float_cols = ["LDY_SCORE","RR1","Now%","T1ì—¬ìœ %","SLì—¬ìœ %","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)",
              "RSI14","ä¹–é›¢%","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%"]
for c in float_cols:
    if c in fmt.columns:
        fmt[c] = pd.to_numeric(fmt[c], errors="coerce")

st.data_editor(
    fmt[cols],
    key="tbl_global_top10",
    width="stretch", height=520,
    hide_index=True, disabled=True, num_rows="fixed",
    column_config=colcfg(fmt),
)

st.download_button(
    "ğŸ“¥ GLOBAL TOP 10 (CSV)",
    data=top10[cols].to_csv(index=False, encoding="utf-8-sig"),
    file_name="ldy_global_top10.csv",
    mime="text/csv",
    key="dl_global_top10",
)

# ì „ì²´ ë­í‚¹ CSV ë‹¤ìš´ë§Œ ì œê³µ(í™”ë©´í‘œì‹œëŠ” Top10ë§Œ)
st.download_button(
    "ğŸ“¥ ì „ì²´ ë­í‚¹ (CSV, ìµœëŒ€ 2,000í–‰)",
    data=scored.sort_values("LDY_SCORE", ascending=False).head(2000)[cols].to_csv(index=False, encoding="utf-8-sig"),
    file_name="ldy_global_rank_full.csv",
    mime="text/csv",
    key="dl_global_full",
)

st.caption("â€» í’ˆì§ˆê²Œì´íŠ¸: EBSâ‰¥4 + ìœ ë™ì„± í•˜ë“œì»· ê¸°ë³¸ / í›„ë³´ê°€ ë¶€ì¡±í•˜ë©´ ìë™ ì™„í™”(EBSâ‰¥3, ì™„í™” ìœ ë™ì„±)")
