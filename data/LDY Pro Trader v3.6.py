# -*- coding: utf-8 -*-
"""
LDY Pro Trader v3.5 â€” MOMO Top10 (No Sliders)
- ë§¤ì¼ ì¥ë§ˆê° í›„ ì—…ë°ì´íŠ¸ëœ CSV(recommend_latest.csv)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
  EV_SCORE + MOMO_SCOREë¥¼ ê²°í•©í•œ GLOBAL_SCOREë¡œ ë‹¨ì¼ Top10 ì¶œë ¥
- ê¸‰ë“± ì§ì „/ì§í›„ 'í­ë°œ(momentum burst)' ì‹ í˜¸ë¥¼ ê°•í•˜ê²Œ ë°˜ì˜
- ìŠ¬ë¼ì´ë”/ê°€ì¤‘ì¹˜ UI ì œê±°, ê³ ì • ì»·(ê±°ë˜ëŒ€ê¸ˆ, EBS)ë§Œ ì ìš©
"""

import os, io, math, requests, numpy as np, pandas as pd, streamlit as st
from datetime import datetime

# ---------- Optional deps (fallbackìš©) ----------
try:
    from pykrx import stock
    PYKRX_OK = True
except Exception:
    PYKRX_OK = False

try:
    import FinanceDataReader as fdr
    FDR_OK = True
except Exception:
    FDR_OK = False

# ---------- Page ----------
st.set_page_config(page_title="LDY Pro Trader v3.5 â€” MOMO Top10", layout="wide")
st.title("ğŸ“ˆ LDY Pro Trader v3.5 â€” MOMO Top10")
st.caption("ê¸‰ë“± ì¶”ì„¸ í¬ì°©ìš© ë‹¨ì¼ Top10 | EV_SCORE Ã— MOMO_SCORE")

# ---------- Constants ----------
RAW_URL   = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/recommend_latest.csv"
LOCAL_RAW = "data/recommend_latest.csv"
CODES_URL = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/krx_codes.csv"
LOCAL_MAP = "data/krx_codes.csv"

PASS_SCORE_EBS = 4          # Top Picks ê¸°ë³¸ ì»·
MIN_TURNOVER   = 100        # (ì–µì›) ìœ ë™ì„± ì»·(ê³ ì •)
NEAR_BAND_DEF  = 1.5        # Now ê·¼ì ‘ë„ ë°´ë“œ(%), EV_SCORE ë‚´ë¶€ì—ì„œ ì‚¬ìš©

# ---------- IO helpers ----------
@st.cache_data(ttl=300)
def load_csv_url(url: str) -> pd.DataFrame:
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    return pd.read_csv(io.BytesIO(r.content))

@st.cache_data(ttl=300)
def load_csv_path(path: str) -> pd.DataFrame:
    return pd.read_csv(path)

def log_src(df: pd.DataFrame, src: str, url_or_path: str):
    st.info(f"ìƒíƒœ âœ… ë°ì´í„° ë¡œë“œ: {src}\n\n{url_or_path}")
    st.success(f"ğŸ“… í‘œì‹œì‹œê°: {pd.Timestamp.now(tz='Asia/Seoul').strftime('%Y-%m-%d %H:%M')} Â· í–‰ìˆ˜: {len(df):,}")

# ---------- Utils ----------
def z6(x) -> str:
    s = str(x)
    return s.zfill(6) if s.isdigit() else s

def ema(s: pd.Series, span: int):
    return s.ewm(span=span, adjust=False, min_periods=span).mean()

def rsi14(close: pd.Series, period=14):
    d = close.diff()
    up, dn = d.clip(lower=0), -d.clip(upper=0)
    au, ad = up.rolling(period).mean(), dn.rolling(period).mean()
    rs = au / ad.replace(0, np.nan)
    return 100 - 100/(1+rs)

def macd_feats(close: pd.Series):
    e12, e26 = ema(close,12), ema(close,26)
    macd = e12 - e26
    sig  = macd.ewm(span=9, adjust=False, min_periods=9).mean()
    hist = macd - sig
    return hist, hist.diff()

def atr14(h, l, c, period=14):
    prev = c.shift(1)
    tr = pd.concat([(h-l), (h-prev).abs(), (l-prev).abs()], axis=1).max(axis=1)
    return tr.rolling(period).mean()

def ensure_turnover(df: pd.DataFrame) -> pd.DataFrame:
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" not in df.columns:
        base = None
        if "ê±°ë˜ëŒ€ê¸ˆ(ì›)" in df.columns:
            base = pd.to_numeric(df["ê±°ë˜ëŒ€ê¸ˆ(ì›)"], errors="coerce")
        elif all(x in df.columns for x in ["ê±°ë˜ëŸ‰","ì¢…ê°€"]):
            base = pd.to_numeric(df["ê±°ë˜ëŸ‰"], errors="coerce") * pd.to_numeric(df["ì¢…ê°€"], errors="coerce")
        if base is not None:
            df["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] = (base/1e8).round(2)
    return df

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    cmap = {
        "Date":"ë‚ ì§œ","date":"ë‚ ì§œ",
        "Code":"ì¢…ëª©ì½”ë“œ","í‹°ì»¤":"ì¢…ëª©ì½”ë“œ","ticker":"ì¢…ëª©ì½”ë“œ",
        "Name":"ì¢…ëª©ëª…","name":"ì¢…ëª©ëª…",
        "Open":"ì‹œê°€","High":"ê³ ê°€","Low":"ì €ê°€","Close":"ì¢…ê°€","Volume":"ê±°ë˜ëŸ‰",
        "ê±°ë˜ëŒ€ê¸ˆ":"ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡":"ì‹œê°€ì´ì•¡(ì›)"
    }
    for k,v in cmap.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k:v})

    if "ë‚ ì§œ" in df.columns:
        try: df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"])
        except: pass
    if "ì¢…ëª©ì½”ë“œ" in df.columns:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.replace(".0","", regex=False).map(z6)
    else:
        df["ì¢…ëª©ì½”ë“œ"] = None
    if "ì‹œì¥" not in df.columns:
        df["ì‹œì¥"] = "ALL"
    if "ì¢…ëª©ëª…" not in df.columns:
        df["ì¢…ëª©ëª…"] = None

    for c in ["ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€","ê±°ë˜ëŸ‰","ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡(ì›)"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    df = ensure_turnover(df)
    return df

# ---------- Enrich from OHLCV (fallback) ----------
@st.cache_data(ttl=300)
def enrich_from_ohlcv(raw: pd.DataFrame) -> pd.DataFrame:
    need = {"ì¢…ëª©ì½”ë“œ","ë‚ ì§œ","ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€"}
    if not need.issubset(set(raw.columns)):
        return raw
    raw = raw.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"])
    g = raw.groupby("ì¢…ëª©ì½”ë“œ", group_keys=False)

    def _feat(x: pd.DataFrame):
        x = x.copy()
        x["MA20"] = x["ì¢…ê°€"].rolling(20).mean()
        x["ATR14"] = atr14(x["ê³ ê°€"], x["ì €ê°€"], x["ì¢…ê°€"], 14)
        x["RSI14"] = rsi14(x["ì¢…ê°€"])
        hist, slope = macd_feats(x["ì¢…ê°€"]); x["MACD_hist"], x["MACD_slope"] = hist, slope
        x["Vol_Z"] = (x["ê±°ë˜ëŸ‰"] - x["ê±°ë˜ëŸ‰"].rolling(20).mean())/x["ê±°ë˜ëŸ‰"].rolling(20).std()
        x["ä¹–é›¢%"] = (x["ì¢…ê°€"]/x["MA20"] - 1)*100
        x["ret_5d_%"]  = (x["ì¢…ê°€"]/x["ì¢…ê°€"].shift(5)  - 1)*100
        x["ret_10d_%"] = (x["ì¢…ê°€"]/x["ì¢…ê°€"].shift(10) - 1)*100

        last = x.iloc[-1:].copy()
        e, why = 0, []
        def nz(v): 
            return not (isinstance(v,float) and math.isnan(v))
        rsi = last["RSI14"].iloc[0];      c1 = nz(rsi) and 45<=rsi<=65;  e+=int(c1); why.append("RSI 45~65" if c1 else "")
        c2 = nz(last["MACD_slope"].iloc[0]) and last["MACD_slope"].iloc[0] > 0; e+=int(c2); why.append("MACDìƒìŠ¹" if c2 else "")
        close, ma20 = last["ì¢…ê°€"].iloc[0], last["MA20"].iloc[0]
        c3 = nz(ma20) and (0.99*ma20 <= close <= 1.04*ma20); e+=int(c3); why.append("MA20 ê·¼ì²˜" if c3 else "")
        c4 = nz(last["Vol_Z"].iloc[0]) and last["Vol_Z"].iloc[0] > 1.2; e+=int(c4); why.append("ê±°ë˜ëŸ‰ì¦ê°€" if c4 else "")
        m20p = x["MA20"].iloc[-2] if len(x)>=2 else np.nan
        c5 = nz(m20p) and (last["MA20"].iloc[0] - m20p > 0); e+=int(c5); why.append("ìƒìŠ¹êµ¬ì¡°" if c5 else "")
        c6 = nz(last["MACD_hist"].iloc[0]) and last["MACD_hist"].iloc[0] > 0; e+=int(c6); why.append("MACD>sig" if c6 else "")
        r5 = last["ret_5d_%"].iloc[0];    c7 = nz(r5) and r5 < 10;        e+=int(c7); why.append("ê³¼ì—´ì•„ë‹˜" if c7 else "")
        last["EBS"] = e; last["ê·¼ê±°"] = ", ".join([w for w in why if w])

        atr = last["ATR14"].iloc[0]
        if any([not nz(atr), not nz(ma20), not nz(close)]) or atr <= 0:
            entry=t1=t2=stp=np.nan
        else:
            band_lo, band_hi = ma20-0.5*atr, ma20+0.5*atr
            entry = min(max(close, band_lo), band_hi)
            t1, t2, stp = entry+1.0*atr, entry+1.8*atr, entry-1.2*atr
        last["ì¶”ì²œë§¤ìˆ˜ê°€"] = round(entry,2) if not math.isnan(entry) else np.nan
        last["ì¶”ì²œë§¤ë„ê°€1"] = round(t1,2)   if not math.isnan(t1)    else np.nan
        last["ì¶”ì²œë§¤ë„ê°€2"] = round(t2,2)   if not math.isnan(t2)    else np.nan
        last["ì†ì ˆê°€"]     = round(stp,2)   if not math.isnan(stp)   else np.nan
        return last

    try:
        out = g.apply(_feat, include_groups=False).reset_index(drop=True)
    except TypeError:
        out = g.apply(_feat).reset_index(drop=True)

    tail = raw.groupby("ì¢…ëª©ì½”ë“œ").tail(1).copy()
    tail = ensure_turnover(tail)
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in tail.columns:
        out = out.merge(tail[["ì¢…ëª©ì½”ë“œ","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"]], on="ì¢…ëª©ì½”ë“œ", how="left")
    if "ì‹œê°€ì´ì•¡(ì–µì›)" not in out.columns:
        out["ì‹œê°€ì´ì•¡(ì–µì›)"] = np.nan
    if "ì‹œì¥" not in out.columns:
        out["ì‹œì¥"] = "ALL"
    return out

# ---------- Name map ----------
@st.cache_data(ttl=6*60*60)
def load_name_map() -> pd.DataFrame | None:
    # 1) repo map
    try:
        m = load_csv_url(CODES_URL)
        if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
    except Exception:
        pass
    if os.path.exists(LOCAL_MAP):
        try:
            m = load_csv_path(LOCAL_MAP)
            if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
                m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
                return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass
    # 2) FDR
    if FDR_OK:
        try:
            lst = fdr.StockListing("KRX")
            m = lst.rename(columns={"Code":"ì¢…ëª©ì½”ë“œ","Name":"ì¢…ëª©ëª…"})[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]]
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m.drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass
    # 3) pykrx
    if PYKRX_OK:
        today = datetime.now().strftime("%Y%m%d")
        rows = []
        try:
            for mk in ["KOSPI","KOSDAQ","KONEX"]:
                try:
                    lst = stock.get_market_ticker_list(today, market=mk)
                except Exception:
                    lst = []
                for t in lst:
                    try:
                        nm = stock.get_market_ticker_name(t)
                    except Exception:
                        nm = None
                    rows.append({"ì¢…ëª©ì½”ë“œ": str(t).zfill(6), "ì¢…ëª©ëª…": nm})
            m = pd.DataFrame(rows).dropna().drop_duplicates("ì¢…ëª©ì½”ë“œ")
            return m if len(m) else None
        except Exception:
            return None
    return None

def apply_names(df: pd.DataFrame) -> pd.DataFrame:
    mp = load_name_map()
    if mp is not None:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
        if "ì¢…ëª©ëª…" not in df.columns: df["ì¢…ëª©ëª…"] = None
        df = df.merge(mp, on="ì¢…ëª©ì½”ë“œ", how="left", suffixes=("","_map"))
        df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna(df["ì¢…ëª©ëª…_map"])
        df = df.drop(columns=[c for c in df.columns if c.endswith("_map")], errors="ignore")
    df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna("(ì´ë¦„ì—†ìŒ)")
    return df

# ---------- EV_SCORE ----------
def add_eval_columns(df_in: pd.DataFrame, near_band_pct: float = NEAR_BAND_DEF) -> pd.DataFrame:
    df = df_in.copy()
    for col in ["ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","RSI14","MACD_slope","EBS"]:
        if col not in df.columns:
            df[col] = np.nan

    close = pd.to_numeric(df["ì¢…ê°€"], errors="coerce")
    entry = pd.to_numeric(df["ì¶”ì²œë§¤ìˆ˜ê°€"], errors="coerce")
    stop  = pd.to_numeric(df["ì†ì ˆê°€"], errors="coerce")
    t1    = pd.to_numeric(df["ì¶”ì²œë§¤ë„ê°€1"], errors="coerce")

    rr_den = (entry - stop)
    rr1 = (t1 - entry) / rr_den.replace(0, np.nan)
    rr1 = rr1.mask((entry.isna()) | (stop.isna()) | (t1.isna()))
    df["RR1"] = rr1

    df["Now%"]   = (close.sub(entry).abs() / entry * 100).replace([np.inf, -np.inf], np.nan)
    df["T1ì—¬ìœ %"] = (t1.sub(close) / close * 100).replace([np.inf, -np.inf], np.nan)
    df["SLì—¬ìœ %"] = (close.sub(stop) / close * 100).replace([np.inf, -np.inf], np.nan)

    ebs_ok  = (pd.to_numeric(df.get("EBS"), errors="coerce") >= PASS_SCORE_EBS).astype(int)
    macd_ok = (pd.to_numeric(df.get("MACD_slope"), errors="coerce") > 0).astype(int)
    rsi_ok  = ((pd.to_numeric(df.get("RSI14"), errors="coerce") >= 45) & (pd.to_numeric(df.get("RSI14"), errors="coerce") <= 65)).astype(int)
    df["ERS"] = (ebs_ok + macd_ok + rsi_ok).astype(float)

    rr_norm   = np.clip(df["RR1"], 0, 3) / 3
    sl_norm   = np.clip(df["SLì—¬ìœ %"]/5, 0, 1)
    t1_norm   = np.clip(df["T1ì—¬ìœ %"]/10, 0, 1)
    near_norm = 0.0
    if near_band_pct and near_band_pct > 0:
        near_norm = np.clip(1 - (df["Now%"] / near_band_pct), 0, 1)
    ers_norm  = np.clip(df["ERS"]/3, 0, 1)

    ev = 100*(0.35*rr_norm + 0.20*sl_norm + 0.20*t1_norm + 0.15*near_norm + 0.10*ers_norm)
    df["EV_SCORE"] = np.round(ev.fillna(0), 1)

    return df

# ---------- MOMO_SCORE ----------
def _scale_01(s, lo, hi):
    v = pd.to_numeric(s, errors="coerce")
    return np.clip((v - lo) / max(1e-9, (hi - lo)), 0, 1)

def _log_liq(x):
    v = pd.to_numeric(x, errors="coerce")
    return _scale_01(np.log1p(v*1e8), np.log1p(1e10), np.log1p(1.5e12))  # 100ì–µ~1500ì–µ

def add_momo_columns(df_in: pd.DataFrame) -> pd.DataFrame:
    df = df_in.copy()
    for c in ["ì¢…ê°€","ì‹œê°€","ê³ ê°€","ì €ê°€","RSI14","MACD_slope","ä¹–é›¢%","ret_5d_%","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","Vol_Z"]:
        if c not in df.columns: df[c] = np.nan

    close = pd.to_numeric(df["ì¢…ê°€"], errors="coerce")
    volz  = pd.to_numeric(df["Vol_Z"], errors="coerce")
    rsi   = pd.to_numeric(df["RSI14"], errors="coerce")
    kairi = pd.to_numeric(df["ä¹–é›¢%"], errors="coerce")
    r5    = pd.to_numeric(df["ret_5d_%"], errors="coerce")
    mslope= pd.to_numeric(df["MACD_slope"], errors="coerce")
    turn  = pd.to_numeric(df["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"], errors="coerce")

    # (A) Breakout proxy
    bo_rsi   = _scale_01(rsi, 55, 70)
    bo_kairi = (kairi.between(2, 8)).astype(float) * _scale_01(kairi, 2, 8)
    bo_r5    = (r5.between(3, 12)).astype(float) * _scale_01(r5, 3, 12)
    breakout = (0.4*bo_rsi + 0.3*bo_kairi + 0.3*bo_r5)

    # (B) ê±°ë˜ëŒ€ê¸ˆ/ë³¼ë¥¨ í™•ì¥
    volx = _scale_01(volz, 1.5, 4.0)
    liq  = _log_liq(turn)
    expansion = (0.6*volx + 0.4*liq)

    # (C) íŠ¸ë Œë“œ í’ˆì§ˆ
    macd_ok = (mslope > 0).astype(float)
    rsi_mid = _scale_01(rsi, 50, 65)
    rsi_hot_penalty = (rsi > 75).astype(float)*0.4
    trend = np.clip(0.5*macd_ok + 0.5*rsi_mid - rsi_hot_penalty, 0, 1)

    # (D) squeezeâ†’release (ì—†ìœ¼ë©´ 0)
    squeeze_release = 0.0
    if "BB_Width" in df.columns and "%B" in df.columns:
        bbw = _scale_01(df["BB_Width"], df["BB_Width"].quantile(0.05), df["BB_Width"].quantile(0.6))
        pb  = _scale_01(df["%B"], 0.8, 1.0)
        squeeze_release = (1 - bbw) * pb

    # (E) í˜ë„í‹°
    overhead_pen = ((kairi < -8).astype(float)*0.3 + (kairi > 12).astype(float)*0.3)
    low_liq_pen  = (turn < MIN_TURNOVER).astype(float)*0.4
    penalty = np.clip(overhead_pen + low_liq_pen, 0, 1)

    momo = 100*(0.35*breakout + 0.30*expansion + 0.25*trend + 0.10*squeeze_release)
    momo = momo * (1 - 0.6*penalty)
    df["MOMO_SCORE"] = np.round(momo.fillna(0), 1)
    return df

# ---------- GLOBAL_SCORE ----------
def add_global_score(df_in: pd.DataFrame) -> pd.DataFrame:
    df = df_in.copy()
    if "EV_SCORE" not in df.columns:
        df["EV_SCORE"] = 0.0
    df = add_momo_columns(df)
    glob = 0.6*pd.to_numeric(df["MOMO_SCORE"], errors="coerce") + \
           0.4*pd.to_numeric(df["EV_SCORE"], errors="coerce")
    df["GLOBAL_SCORE"] = np.round(glob.fillna(0), 1)
    return df

# ---------- Table formatting ----------
def cast_for_editor(df):
    df = df.copy()
    int_like = ["ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","EBS"]
    for c in int_like:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").round(0).astype("Int64")
    float_like = ["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_hist","MACD_slope",
                  "Vol_Z","ret_5d_%","ret_10d_%","EV_SCORE","MOMO_SCORE","GLOBAL_SCORE",
                  "ERS","RR1","Now%","T1ì—¬ìœ %","SLì—¬ìœ %"]
    for c in float_like:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

def column_config_for(df):
    cfg = {}
    def add(name, col):
        if name in df.columns: cfg[name]=col
    add("ì‹œì¥",       st.column_config.TextColumn("ì‹œì¥"))
    add("ì¢…ëª©ëª…",     st.column_config.TextColumn("ì¢…ëª©ëª…"))
    add("ì¢…ëª©ì½”ë“œ",   st.column_config.TextColumn("ì¢…ëª©ì½”ë“œ"))
    add("ê·¼ê±°",       st.column_config.TextColumn("ê·¼ê±°"))

    add("ì¢…ê°€",        st.column_config.NumberColumn("ì¢…ê°€",           format="%,d"))
    add("ì¶”ì²œë§¤ìˆ˜ê°€",  st.column_config.NumberColumn("ì¶”ì²œë§¤ìˆ˜ê°€",     format="%,d"))
    add("ì†ì ˆê°€",      st.column_config.NumberColumn("ì†ì ˆê°€",         format="%,d"))
    add("ì¶”ì²œë§¤ë„ê°€1", st.column_config.NumberColumn("ì¶”ì²œë§¤ë„ê°€1",    format="%,d"))
    add("ì¶”ì²œë§¤ë„ê°€2", st.column_config.NumberColumn("ì¶”ì²œë§¤ë„ê°€2",    format="%,d"))

    add("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", st.column_config.NumberColumn("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)",  format="%,.0f"))
    add("ì‹œê°€ì´ì•¡(ì–µì›)", st.column_config.NumberColumn("ì‹œê°€ì´ì•¡(ì–µì›)",  format="%,.0f"))

    add("GLOBAL_SCORE", st.column_config.NumberColumn("GLOBAL",        format="%.1f"))
    add("MOMO_SCORE",   st.column_config.NumberColumn("MOMO",          format="%.1f"))
    add("EV_SCORE",     st.column_config.NumberColumn("EV",            format="%.1f"))

    add("RR1",        st.column_config.NumberColumn("RR(ëª©í‘œ1/ì†ì ˆ)",    format="%.2f"))
    add("T1ì—¬ìœ %",    st.column_config.NumberColumn("ëª©í‘œ1ì—¬ìœ (%)",      format="%.2f"))
    add("SLì—¬ìœ %",    st.column_config.NumberColumn("ì†ì ˆì—¬ìœ (%)",      format="%.2f"))
    add("Now%",       st.column_config.NumberColumn("Now ê·¼ì ‘(%)",       format="%.2f"))

    add("RSI14",      st.column_config.NumberColumn("RSI14",          format="%.1f"))
    add("MACD_slope", st.column_config.NumberColumn("MACD_slope",     format="%.5f"))
    add("Vol_Z",      st.column_config.NumberColumn("Vol_Z",          format="%.2f"))
    add("ä¹–é›¢%",       st.column_config.NumberColumn("ä¹–é›¢%",           format="%.2f"))
    add("ret_5d_%",   st.column_config.NumberColumn("5dìˆ˜ìµ(%)",       format="%.2f"))
    add("ret_10d_%",  st.column_config.NumberColumn("10dìˆ˜ìµ(%)",      format="%.2f"))
    add("EBS",        st.column_config.NumberColumn("EBS",            format="%d"))
    return cfg

def render_table(df, *, key: str, height=560):
    st.data_editor(
        df,
        key=key,
        width="stretch",
        height=height,
        hide_index=True,
        disabled=True,
        num_rows="fixed",
        column_config=column_config_for(df),
    )

# ---------- Load raw ----------
try:
    df_raw = load_csv_url(RAW_URL); log_src(df_raw, "remote", RAW_URL)
except Exception:
    if os.path.exists(LOCAL_RAW):
        df_raw = load_csv_path(LOCAL_RAW); log_src(df_raw, "local", LOCAL_RAW)
    else:
        st.error("âŒ CSVê°€ ì—†ìŠµë‹ˆë‹¤. Actionsì—ì„œ collectorê°€ data/recommend_latest.csvë¥¼ ì˜¬ë ¸ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

df_raw = normalize_cols(df_raw)

# ì™„ì œí’ˆ(EBS/ì¶”ì²œê°€) ì—¬ë¶€ ì²´í¬
has_ebs  = "EBS" in df_raw.columns and df_raw["EBS"].notna().any()
has_reco = all(c in df_raw.columns for c in ["ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]) and \
           df_raw[["ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]].notna().any().any()

if has_ebs and has_reco:
    df = df_raw.copy()
else:
    with st.status("ğŸ§® ì›ì‹œ OHLCV â†’ ì§€í‘œ/ì ìˆ˜/ì¶”ì²œê°€ ìƒì„± ì¤‘...", expanded=False):
        df = enrich_from_ohlcv(df_raw)

latest = df.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"]).groupby("ì¢…ëª©ì½”ë“œ").tail(1) if "ë‚ ì§œ" in df.columns else df.copy()

with st.status("ğŸ·ï¸ ì¢…ëª©ëª… ë§¤í•‘ ì¤‘...", expanded=False):
    latest = apply_names(latest)

latest = ensure_turnover(latest)
for c in ["ì¢…ê°€","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","EBS","ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]:
    if c in latest.columns:
        latest[c] = pd.to_numeric(latest[c], errors="coerce")

# ---------- Scoring & Ranking ----------
scored = add_eval_columns(latest, near_band_pct=NEAR_BAND_DEF)
scored = add_global_score(scored)

# ê³ ì • ì»·: ê±°ë˜ëŒ€ê¸ˆ, EBS
if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in scored.columns:
    scored = scored[scored["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] >= MIN_TURNOVER]
if "EBS" in scored.columns:
    scored = scored[scored["EBS"] >= PASS_SCORE_EBS]

ranked = scored.sort_values(
    ["GLOBAL_SCORE","MOMO_SCORE","EV_SCORE","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"],
    ascending=[False, False, False, False]
).head(10)

# ---------- View ----------
st.subheader("ğŸ”¥ MOMO Top 10 (ê¸‰ë“± ì¶”ì„¸ í¬ì°©ìš©)", anchor=False)
cols_out = [
    "ì‹œì¥","ì¢…ëª©ëª…","ì¢…ëª©ì½”ë“œ","ì¢…ê°€",
    "GLOBAL_SCORE","MOMO_SCORE","EV_SCORE",
    "RR1","T1ì—¬ìœ %","SLì—¬ìœ %","Now%",
    "RSI14","MACD_slope","Vol_Z","ä¹–é›¢%","ret_5d_%","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)",
    "EBS","ê·¼ê±°",
]
for c in cols_out:
    if c not in ranked.columns: ranked[c]=np.nan

render_table(cast_for_editor(ranked[cols_out]), key="tbl_momo_top10")

st.download_button(
    "ğŸ“¥ MOMO Top 10 (CSV)",
    data=ranked[cols_out].to_csv(index=False, encoding="utf-8-sig"),
    file_name="ldy_momo_top10.csv",
    mime="text/csv",
    key="dl_momo_top10",
)

with st.expander("â„¹ï¸ ìŠ¤ì½”ì–´ í•´ì„ ê°€ì´ë“œ"):
    st.markdown("""
**GLOBAL_SCORE = 0.6Â·MOMO + 0.4Â·EV**  
- **MOMO_SCORE(0~100)**: ëŒíŒŒ(ì‹ ê³ ê°€ í”„ë¡ì‹œ), ê±°ë˜ëŒ€ê¸ˆ/ë³¼ë¥¨ í™•ì¥, íŠ¸ë Œë“œ í’ˆì§ˆ, ìŠ¤í€´ì¦ˆâ†’í™•ì¥(+), ê³¼ì—´/ì €ìœ ë™(â€“)  
- **EV_SCORE(0~100)**: RR(ëª©í‘œ1/ì†ì ˆ), ì†ì ˆì—¬ìœ Â·ëª©í‘œì—¬ìœ , Now ê·¼ì ‘ë„(Â±1.5%), ERS(=EBS ì»·+MACD_slope+RSI)  
**ì¶”ì²œ ìš´ìš©**: Top10 ì¤‘ **Now% â‰¤ 1.0~1.5**, **SLì—¬ìœ % â‰¥ 3**, **Vol_Z â‰¥ 2**, **RSI 55~70** ìš°ì„  ê²€í† .
""")
