# -*- coding: utf-8 -*-
"""
LDY Pro Trader v3.4.2 (Auto Update + EV Score + Top Picks)
- ê²°ì¸¡ ì¶”ì²œê°€(ì—”íŠ¸ë¦¬/ì†ì ˆ/ëª©í‘œ1) ìë™ ë³´ì •: OHLCVê°€ ë¶€ì¡±í•´ë„ EVê°€ 0ë§Œ ì°íˆì§€ ì•Šë„ë¡ ê¸°ë³¸ê°’ ìƒì„±
- EV ê²Œì´íŠ¸: MACD_hist/RSIê°€ NaNì´ì–´ë„ í˜ë„í‹°ë¡œ ë°˜ì˜(=0.90), slopeâ‰¤0ëŠ” ê°•í€ì¹˜(Ã—0.75)
- Streamlit DuplicateElementId ë°©ì§€ ìœ ì§€
"""

import os, io, math, requests, numpy as np, pandas as pd, streamlit as st
from datetime import datetime

# ---------------- optional deps ----------------
try:
    from pykrx import stock
    PYKRX_OK = True
except Exception:
    PYKRX_OK = False

try:
    import FinanceDataReader as fdr
    FDR_OK = True
except Exception:
    FDR_OK = False

# ---------------- page ----------------
st.set_page_config(page_title="LDY Pro Trader v3.4.2 (Auto Update)", layout="wide")
st.title("ğŸ“ˆ LDY Pro Trader v3.4.2 (Auto Update)")
st.caption("ë§¤ì¼ ì¥ë§ˆê° í›„ ìë™ ì—…ë°ì´íŠ¸ë˜ëŠ” ìŠ¤ìœ™ ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ | EVìŠ¤ì½”ì–´Â·TopPick ë‚´ì¥")

# ---------------- constants ----------------
RAW_URL   = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/recommend_latest.csv"
LOCAL_RAW = "data/recommend_latest.csv"
CODES_URL = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/krx_codes.csv"
LOCAL_MAP = "data/krx_codes.csv"
PASS_SCORE = 4

# ê²°ì¸¡ ë³´ì • ê¸°ë³¸ê°’(ì—”íŠ¸ë¦¬ ê¸°ì¤€ %)
DEF_T1_PCT = 0.06   # +6% ëª©í‘œ1
DEF_SL_PCT = 0.03   # -3% ì†ì ˆ
# ATRì´ ìˆìœ¼ë©´ ATR ê¸°ë°˜(ì—”íŠ¸ë¦¬Â±), ì—†ìœ¼ë©´ ìœ„ % ì‚¬ìš©

# ---------------- IO helpers ----------------
@st.cache_data(ttl=300)
def load_csv_url(url: str) -> pd.DataFrame:
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    return pd.read_csv(io.BytesIO(r.content))

@st.cache_data(ttl=300)
def load_csv_path(path: str) -> pd.DataFrame:
    return pd.read_csv(path)

def log_src(df: pd.DataFrame, src: str, url_or_path: str):
    st.info(f"ìƒíƒœ âœ… ë°ì´í„° ë¡œë“œ: {src}\n\n{url_or_path}")
    st.success(f"ğŸ“… í‘œì‹œì‹œê°: {pd.Timestamp.now(tz='Asia/Seoul').strftime('%Y-%m-%d %H:%M')} Â· í–‰ìˆ˜: {len(df):,}")

# ---------------- utils ----------------
def z6(x) -> str:
    s = str(x)
    return s.zfill(6) if s.isdigit() else s

def ema(s: pd.Series, span: int):
    return s.ewm(span=span, adjust=False, min_periods=span).mean()

def rsi14(close: pd.Series, period=14):
    d = close.diff()
    up, dn = d.clip(lower=0), -d.clip(upper=0)
    au, ad = up.rolling(period).mean(), dn.rolling(period).mean()
    rs = au / ad.replace(0, np.nan)
    return 100 - 100/(1+rs)

def macd_feats(close: pd.Series):
    e12, e26 = ema(close,12), ema(close,26)
    macd = e12 - e26
    sig  = macd.ewm(span=9, adjust=False, min_periods=9).mean()
    hist = macd - sig
    return hist, hist.diff()

def atr14(h, l, c, period=14):
    prev = c.shift(1)
    tr = pd.concat([(h-l), (h-prev).abs(), (l-prev).abs()], axis=1).max(axis=1)
    return tr.rolling(period).mean()

def ensure_turnover(df: pd.DataFrame) -> pd.DataFrame:
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" not in df.columns:
        base = None
        if "ê±°ë˜ëŒ€ê¸ˆ(ì›)" in df.columns:
            base = pd.to_numeric(df["ê±°ë˜ëŒ€ê¸ˆ(ì›)"], errors="coerce")
        elif all(x in df.columns for x in ["ê±°ë˜ëŸ‰","ì¢…ê°€"]):
            base = pd.to_numeric(df["ê±°ë˜ëŸ‰"], errors="coerce") * pd.to_numeric(df["ì¢…ê°€"], errors="coerce")
        if base is not None:
            df["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] = (base/1e8).round(2)
    return df

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    cmap = {
        "Date":"ë‚ ì§œ","date":"ë‚ ì§œ",
        "Code":"ì¢…ëª©ì½”ë“œ","í‹°ì»¤":"ì¢…ëª©ì½”ë“œ","ticker":"ì¢…ëª©ì½”ë“œ",
        "Name":"ì¢…ëª©ëª…","name":"ì¢…ëª©ëª…",
        "Open":"ì‹œê°€","High":"ê³ ê°€","Low":"ì €ê°€","Close":"ì¢…ê°€","Volume":"ê±°ë˜ëŸ‰",
        "ê±°ë˜ëŒ€ê¸ˆ":"ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡":"ì‹œê°€ì´ì•¡(ì›)"
    }
    for k,v in cmap.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k:v})

    if "ë‚ ì§œ" in df.columns:
        try: df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"])
        except: pass
    if "ì¢…ëª©ì½”ë“œ" in df.columns:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.replace(".0","", regex=False).map(z6)
    else:
        df["ì¢…ëª©ì½”ë“œ"] = None
    if "ì‹œì¥" not in df.columns:
        df["ì‹œì¥"] = "ALL"
    if "ì¢…ëª©ëª…" not in df.columns:
        df["ì¢…ëª©ëª…"] = None

    for c in ["ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€","ê±°ë˜ëŸ‰","ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡(ì›)"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    df = ensure_turnover(df)
    return df

# --------- enrich from OHLCV (fallback) ----------
@st.cache_data(ttl=300)
def enrich_from_ohlcv(raw: pd.DataFrame) -> pd.DataFrame:
    need = {"ì¢…ëª©ì½”ë“œ","ë‚ ì§œ","ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€"}
    if not need.issubset(set(raw.columns)):
        return raw
    raw = raw.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"])
    g = raw.groupby("ì¢…ëª©ì½”ë“œ", group_keys=False)

    def _feat(x: pd.DataFrame):
        x = x.copy()
        x["MA20"] = x["ì¢…ê°€"].rolling(20).mean()
        x["ATR14"] = atr14(x["ê³ ê°€"], x["ì €ê°€"], x["ì¢…ê°€"], 14)
        x["RSI14"] = rsi14(x["ì¢…ê°€"])
        hist, slope = macd_feats(x["ì¢…ê°€"]); x["MACD_hist"], x["MACD_slope"] = hist, slope
        x["Vol_Z"] = (x["ê±°ë˜ëŸ‰"] - x["ê±°ë˜ëŸ‰"].rolling(20).mean())/x["ê±°ë˜ëŸ‰"].rolling(20).std()
        x["ä¹–é›¢%"] = (x["ì¢…ê°€"]/x["MA20"] - 1)*100
        x["ret_5d_%"]  = (x["ì¢…ê°€"]/x["ì¢…ê°€"].shift(5)  - 1)*100
        x["ret_10d_%"] = (x["ì¢…ê°€"]/x["ì¢…ê°€"].shift(10) - 1)*100

        last = x.iloc[-1:].copy()
        e, why = 0, []
        def nz(v): 
            return not (isinstance(v,float) and math.isnan(v))
        rsi = last["RSI14"].iloc[0];      c1 = nz(rsi) and 45<=rsi<=65;  e+=int(c1); why.append("RSI 45~65" if c1 else "")
        c2 = nz(last["MACD_slope"].iloc[0]) and last["MACD_slope"].iloc[0] > 0; e+=int(c2); why.append("MACDâ†‘" if c2 else "")
        close, ma20 = last["ì¢…ê°€"].iloc[0], last["MA20"].iloc[0]
        c3 = nz(ma20) and (0.99*ma20 <= close <= 1.04*ma20); e+=int(c3); why.append("MA20Â±4%" if c3 else "")
        c4 = nz(last["Vol_Z"].iloc[0]) and last["Vol_Z"].iloc[0] > 1.2; e+=int(c4); why.append("VolZ>1.2" if c4 else "")
        m20p = x["MA20"].iloc[-2] if len(x)>=2 else np.nan
        c5 = nz(m20p) and (last["MA20"].iloc[0] - m20p > 0); e+=int(c5); why.append("MA20â†‘" if c5 else "")
        c6 = nz(last["MACD_hist"].iloc[0]) and last["MACD_hist"].iloc[0] > 0; e+=int(c6); why.append("MACD>0" if c6 else "")
        r5 = last["ret_5d_%"].iloc[0];    c7 = nz(r5) and r5 < 10;        e+=int(c7); why.append("5d<10%" if c7 else "")
        last["EBS"] = e; last["ê·¼ê±°"] = " / ".join([w for w in why if w])

        atr = last["ATR14"].iloc[0]
        if any([not nz(atr), not nz(ma20), not nz(close)]) or atr <= 0:
            entry=t1=t2=stp=np.nan
        else:
            band_lo, band_hi = ma20 - 0.5*atr, ma20 + 0.5*atr
            base_entry = ma20
            entry = min(max(base_entry, band_lo), band_hi)
            t1, t2, stp = entry + 1.0*atr, entry + 1.8*atr, entry - 1.2*atr
        last["ì¶”ì²œë§¤ìˆ˜ê°€"] = round(entry,2) if not math.isnan(entry) else np.nan
        last["ì¶”ì²œë§¤ë„ê°€1"] = round(t1,2)   if not math.isnan(t1)    else np.nan
        last["ì¶”ì²œë§¤ë„ê°€2"] = round(t2,2)   if not math.isnan(t2)    else np.nan
        last["ì†ì ˆê°€"]     = round(stp,2)   if not math.isnan(stp)   else np.nan
        return last

    try:
        out = g.apply(_feat, include_groups=False).reset_index(drop=True)
    except TypeError:
        out = g.apply(_feat).reset_index(drop=True)

    tail = raw.groupby("ì¢…ëª©ì½”ë“œ").tail(1).copy()
    tail = ensure_turnover(tail)
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in tail.columns:
        out = out.merge(tail[["ì¢…ëª©ì½”ë“œ","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"]], on="ì¢…ëª©ì½”ë“œ", how="left")
    if "ì‹œê°€ì´ì•¡(ì–µì›)" not in out.columns:
        out["ì‹œê°€ì´ì•¡(ì–µì›)"] = np.nan
    if "ì‹œì¥" not in out.columns:
        out["ì‹œì¥"] = "ALL"
    return out

# -------- name map (robust) --------
@st.cache_data(ttl=6*60*60)
def load_name_map() -> pd.DataFrame | None:
    try:
        m = load_csv_url(CODES_URL)
        if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
    except Exception:
        pass
    if os.path.exists(LOCAL_MAP):
        try:
            m = load_csv_path(LOCAL_MAP)
            if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
                m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
                return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass
    if FDR_OK:
        try:
            lst = fdr.StockListing("KRX")
            m = lst.rename(columns={"Code":"ì¢…ëª©ì½”ë“œ","Name":"ì¢…ëª©ëª…"})[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]]
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m.drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass
    if PYKRX_OK:
        today = datetime.now().strftime("%Y%m%d")
        rows = []
        try:
            for mk in ["KOSPI","KOSDAQ","KONEX"]:
                try:
                    lst = stock.get_market_ticker_list(today, market=mk)
                except Exception:
                    lst = []
                for t in lst:
                    try:
                        nm = stock.get_market_ticker_name(t)
                    except Exception:
                        nm = None
                    rows.append({"ì¢…ëª©ì½”ë“œ": str(t).zfill(6), "ì¢…ëª©ëª…": nm})
            m = pd.DataFrame(rows).dropna().drop_duplicates("ì¢…ëª©ì½”ë“œ")
            return m if len(m) else None
        except Exception:
            return None
    return None

def apply_names(df: pd.DataFrame) -> pd.DataFrame:
    mp = load_name_map()
    if mp is not None:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
        if "ì¢…ëª©ëª…" not in df.columns: df["ì¢…ëª©ëª…"] = None
        df = df.merge(mp, on="ì¢…ëª©ì½”ë“œ", how="left", suffixes=("","_map"))
        df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna(df["ì¢…ëª©ëª…_map"])
        df = df.drop(columns=[c for c in df.columns if c.endswith("_map")], errors="ignore")
    df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna("(ì´ë¦„ì—†ìŒ)")
    return df

# -------- ê²°ì¸¡ ì¶”ì²œê°€ ë³´ì •(í•µì‹¬) --------
def fill_reco_if_missing(df: pd.DataFrame) -> pd.DataFrame:
    """ì¶”ì²œë§¤ìˆ˜ê°€/ì†ì ˆê°€/ëª©í‘œ1 ê²°ì¸¡ ì‹œ ê¸°ë³¸ ê·œì¹™ìœ¼ë¡œ ìë™ ìƒì„±"""
    df = df.copy()
    for col in ["ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ATR14","MA20"]:
        if col not in df.columns:
            df[col] = np.nan

    close = pd.to_numeric(df["ì¢…ê°€"], errors="coerce")
    entry = pd.to_numeric(df["ì¶”ì²œë§¤ìˆ˜ê°€"], errors="coerce")
    stop  = pd.to_numeric(df["ì†ì ˆê°€"], errors="coerce")
    t1    = pd.to_numeric(df["ì¶”ì²œë§¤ë„ê°€1"], errors="coerce")
    t2    = pd.to_numeric(df["ì¶”ì²œë§¤ë„ê°€2"], errors="coerce")
    atr   = pd.to_numeric(df.get("ATR14"), errors="coerce")
    ma20  = pd.to_numeric(df.get("MA20"), errors="coerce")

    # entry ê²°ì¸¡ â†’ MA20ì´ ìˆìœ¼ë©´ MA20ì„ Â±0.5*ATRë¡œ í´ë¨í”„, ì—†ìœ¼ë©´ close ì‚¬ìš©
    use_atr = atr.notna() & (atr > 0) & ma20.notna()
    entry_calc = np.where(use_atr, np.clip(ma20, ma20 - 0.5*atr, ma20 + 0.5*atr), close)
    df.loc[entry.isna(), "ì¶”ì²œë§¤ìˆ˜ê°€"] = np.round(entry_calc[entry.isna()], 0)

    # stop/t1 ê²°ì¸¡ â†’ ATR ìˆìœ¼ë©´ ATR ê¸°ë°˜, ì—†ìœ¼ë©´ % ê¸°ë°˜
    entry = pd.to_numeric(df["ì¶”ì²œë§¤ìˆ˜ê°€"], errors="coerce")  # ì—…ë°ì´íŠ¸ëœ entry ë‹¤ì‹œ ë¡œë“œ
    use_atr = atr.notna() & (atr > 0) & entry.notna()

    stop_calc = np.where(use_atr, entry - 1.2*atr, entry * (1 - DEF_SL_PCT))
    t1_calc   = np.where(use_atr, entry + 1.0*atr, entry * (1 + DEF_T1_PCT))
    t2_calc   = np.where(use_atr, entry + 1.8*atr, entry * (1 + DEF_T1_PCT*1.8))

    df.loc[stop.isna() & entry.notna(), "ì†ì ˆê°€"]      = np.round(stop_calc[stop.isna() & entry.notna()], 0)
    df.loc[t1.isna()   & entry.notna(), "ì¶”ì²œë§¤ë„ê°€1"] = np.round(t1_calc[t1.isna()   & entry.notna()], 0)
    df.loc[t2.isna()   & entry.notna(), "ì¶”ì²œë§¤ë„ê°€2"] = np.round(t2_calc[t2.isna()   & entry.notna()], 0)

    return df

# ---------------- load raw ----------------
try:
    df_raw = load_csv_url(RAW_URL); log_src(df_raw, "remote", RAW_URL)
except Exception:
    if os.path.exists(LOCAL_RAW):
        df_raw = load_csv_path(LOCAL_RAW); log_src(df_raw, "local", LOCAL_RAW)
    else:
        st.error("âŒ CSVê°€ ì—†ìŠµë‹ˆë‹¤. Actionsì—ì„œ collectorê°€ data/recommend_latest.csvë¥¼ ì˜¬ë ¸ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

df_raw = normalize_cols(df_raw)

# ì™„ì œí’ˆ ì²´í¬ â†’ ë¯¸ì™„ì´ë©´ enrich ì‹œë„, ê·¸ë˜ë„ ë¹„ë©´ ë³´ì • ì±„ì›€
has_ebs  = "EBS" in df_raw.columns and df_raw["EBS"].notna().any()
has_reco = all(c in df_raw.columns for c in ["ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]) and \
           df_raw[["ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]].notna().any().any()

if has_ebs and has_reco:
    df = df_raw.copy()
else:
    with st.status("ğŸ§® ì›ì‹œ OHLCV â†’ ì§€í‘œ/ì ìˆ˜/ì¶”ì²œê°€ ìƒì„± ì¤‘...", expanded=False):
        df = enrich_from_ohlcv(df_raw)
    # ì—¬ì „íˆ ì¶”ì²œê°€ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ ê·œì¹™ìœ¼ë¡œ ìƒì„±
    df = fill_reco_if_missing(df)

# ìµœì‹  í–‰ë§Œ
latest = df.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"]).groupby("ì¢…ëª©ì½”ë“œ").tail(1) if "ë‚ ì§œ" in df.columns else df.copy()

# ì´ë¦„ ë§¤í•‘
with st.status("ğŸ·ï¸ ì¢…ëª©ëª… ë§¤í•‘ ì¤‘...", expanded=False):
    latest = apply_names(latest)

# ìˆ«ì ìºìŠ¤íŒ… & ê±°ë˜ëŒ€ê¸ˆ ë³´ê°•
latest = ensure_turnover(latest)
for c in ["ì¢…ê°€","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","EBS","ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€","ATR14","MA20"]:
    if c in latest.columns:
        latest[c] = pd.to_numeric(latest[c], errors="coerce")

# ---------------- EV score ----------------
def _clip01(x):
    try:
        if pd.isna(x): return 0.0
        return float(max(0.0, min(1.0, x)))
    except Exception:
        return 0.0

def make_ev_score(df: pd.DataFrame) -> pd.Series:
    """
    ê¸°ëŒ€ê°’ ê¸°ë°˜ EV ì ìˆ˜ 0~100.
    NaNì€ ë³´ìˆ˜ì ìœ¼ë¡œ í˜ë„í‹° ì²˜ë¦¬.
    """
    rr1  = (pd.to_numeric(df.get("RR1"), errors="coerce") - 1.0) / (3.0 - 1.0)
    rr1  = np.vectorize(_clip01)(rr1)

    t1r  = np.vectorize(_clip01)(pd.to_numeric(df.get("T1ì—¬ìœ %"), errors="coerce") / 8.0)   # 8%ì—ì„œ 1.0
    slr  = np.vectorize(_clip01)(pd.to_numeric(df.get("SLì—¬ìœ %"), errors="coerce") / 4.0)   # 4%ì—ì„œ 1.0
    ers  = np.vectorize(_clip01)(pd.to_numeric(df.get("ERS"), errors="coerce") / 3.0)
    near = np.vectorize(_clip01)(1.0 - (pd.to_numeric(df.get("Now%"), errors="coerce").abs() / 1.0))  # Â±1% ê·¼ì ‘=1
    liq  = np.vectorize(_clip01)(np.log10(pd.to_numeric(df.get("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"), errors="coerce").fillna(0) + 1) / 3.0)

    base = 0.25*rr1 + 0.20*t1r + 0.15*slr + 0.20*ers + 0.10*near + 0.10*liq

    hist  = pd.to_numeric(df.get("MACD_hist"), errors="coerce")
    slope = pd.to_numeric(df.get("MACD_slope"), errors="coerce")
    rsi   = pd.to_numeric(df.get("RSI14"), errors="coerce")

    # NaNë„ í˜ë„í‹°: >ì¡°ê±´ì„ ë§Œì¡±í•˜ì§€ ì•Šìœ¼ë©´ í˜ë„í‹°ë¡œ ê°„ì£¼
    cond_hist_pos = (hist > 0)
    cond_slope_pos = (slope > 0)
    cond_rsi_in = (rsi >= 45) & (rsi <= 68)

    gate = np.ones(len(df), dtype=float)
    gate *= np.where(cond_hist_pos.fillna(False), 1.00, 0.90)  # hist ì–‘ìˆ˜ ì•„ë‹ˆë©´ 0.90
    gate *= np.where(cond_slope_pos.fillna(False), 1.00, 0.75) # slope ì–‘ìˆ˜ ì•„ë‹ˆë©´ 0.75
    gate *= np.where(cond_rsi_in.fillna(False), 1.00, 0.90)    # RSI ë²”ìœ„ ë°–/NaN 0.90

    ev_raw = base * gate
    ev = (100.0 * ev_raw).clip(0, 100).round(1)

    # ìƒìœ„ í¼ì„¼íƒ€ì¼ ê¸°ì¤€ ë¦¬ìŠ¤ì¼€ì¼ (ìŠ¤ì½”ì–´ê°€ ê³¼ë„í•˜ê²Œ ë‚®ê²Œ ëª°ë¦¬ëŠ” ê²ƒ ì™„í™”)
    try:
        p95 = np.nanpercentile(ev, 95)
        if p95 > 0:
            ev = (ev * (95.0 / p95)).clip(0, 100).round(1)
    except Exception:
        pass

    return ev

# ---------------- helper: scoring ----------------
def add_eval_columns(df_in: pd.DataFrame, near_band_pct: float) -> pd.DataFrame:
    """RR1/ì—¬ìœ %/ERS/EV_SCORE ê³„ì‚° ì»¬ëŸ¼ ì¶”ê°€"""
    df = df_in.copy()
    for col in ["ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","RSI14","MACD_slope","MACD_hist","EBS","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"]:
        if col not in df.columns:
            df[col] = np.nan

    close = pd.to_numeric(df["ì¢…ê°€"], errors="coerce")
    entry = pd.to_numeric(df["ì¶”ì²œë§¤ìˆ˜ê°€"], errors="coerce")
    stop  = pd.to_numeric(df["ì†ì ˆê°€"], errors="coerce")
    t1    = pd.to_numeric(df["ì¶”ì²œë§¤ë„ê°€1"], errors="coerce")

    rr_den = (entry - stop)
    rr1 = (t1 - entry) / rr_den.replace(0, np.nan)
    rr1 = rr1.mask((entry.isna()) | (stop.isna()) | (t1.isna()))
    df["RR1"] = rr1

    df["Now%"]    = (close.sub(entry).abs() / entry * 100).replace([np.inf, -np.inf], np.nan)
    df["T1ì—¬ìœ %"] = (t1.sub(close) / close * 100).replace([np.inf, -np.inf], np.nan)
    df["SLì—¬ìœ %"] = (close.sub(stop) / close * 100).replace([np.inf, -np.inf], np.nan)

    ebs_ok  = (pd.to_numeric(df.get("EBS"), errors="coerce") >= PASS_SCORE).astype(int)
    macd_ok = (pd.to_numeric(df.get("MACD_slope"), errors="coerce") > 0).astype(int)
    rsi_v   = pd.to_numeric(df.get("RSI14"), errors="coerce")
    rsi_ok  = ((rsi_v >= 45) & (rsi_v <= 65)).astype(int)
    df["ERS"] = (ebs_ok + macd_ok + rsi_ok).astype(float)

    df["EV_SCORE"] = make_ev_score(df)
    return df

def cast_for_editor(df):
    df = df.copy()
    int_like = ["ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","EBS"]
    for c in int_like:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce").round(0).astype("Int64")
    float_like = [
        "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_hist","MACD_slope",
        "Vol_Z","ret_5d_%","ret_10d_%","EV_SCORE","ERS","RR1","Now%","T1ì—¬ìœ %","SLì—¬ìœ %"
    ]
    for c in float_like:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df

def column_config_for(df):
    cfg = {}
    def add(name, col):
        if name in df.columns: cfg[name]=col
    add("í†µê³¼",       st.column_config.TextColumn(" "))
    add("ì‹œì¥",       st.column_config.TextColumn("ì‹œì¥"))
    add("ì¢…ëª©ëª…",     st.column_config.TextColumn("ì¢…ëª©ëª…"))
    add("ì¢…ëª©ì½”ë“œ",   st.column_config.TextColumn("ì¢…ëª©ì½”ë“œ"))
    add("ê·¼ê±°",       st.column_config.TextColumn("ê·¼ê±°"))
    add("ì¢…ê°€",        st.column_config.NumberColumn("ì¢…ê°€",           format="%,d"))
    add("ì¶”ì²œë§¤ìˆ˜ê°€",  st.column_config.NumberColumn("ì¶”ì²œë§¤ìˆ˜ê°€",     format="%,d"))
    add("ì†ì ˆê°€",      st.column_config.NumberColumn("ì†ì ˆê°€",         format="%,d"))
    add("ì¶”ì²œë§¤ë„ê°€1", st.column_config.NumberColumn("ì¶”ì²œë§¤ë„ê°€1",    format="%,d"))
    add("ì¶”ì²œë§¤ë„ê°€2", st.column_config.NumberColumn("ì¶”ì²œë§¤ë„ê°€2",    format="%,d"))
    add("EBS",        st.column_config.NumberColumn("EBS",            format="%d"))
    add("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", st.column_config.NumberColumn("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)",  format="%,.0f"))
    add("ì‹œê°€ì´ì•¡(ì–µì›)", st.column_config.NumberColumn("ì‹œê°€ì´ì•¡(ì–µì›)",  format="%,.0f"))
    add("RSI14",      st.column_config.NumberColumn("RSI14",          format="%.1f"))
    add("ä¹–é›¢%",       st.column_config.NumberColumn("ä¹–é›¢%",           format="%.2f"))
    add("MACD_hist",  st.column_config.NumberColumn("MACD_hist",      format="%.4f"))
    add("MACD_slope", st.column_config.NumberColumn("MACD_slope",     format="%.5f"))
    add("Vol_Z",      st.column_config.NumberColumn("Vol_Z",          format="%.2f"))
    add("ret_5d_%",   st.column_config.NumberColumn("ret_5d_%",       format="%.2f"))
    add("ret_10d_%",  st.column_config.NumberColumn("ret_10d_%",      format="%.2f"))
    add("EV_SCORE",   st.column_config.NumberColumn("EV_SCORE",       format="%.1f"))
    add("ERS",        st.column_config.NumberColumn("ERS",            format="%.2f"))
    add("RR1",        st.column_config.NumberColumn("RR1(ëª©í‘œ1/ì†ì ˆ)", format="%.2f"))
    add("Now%",       st.column_config.NumberColumn("Now ê·¼ì ‘(%)",      format="%.2f"))
    add("T1ì—¬ìœ %",    st.column_config.NumberColumn("ëª©í‘œ1ì—¬ìœ (%)",     format="%.2f"))
    add("SLì—¬ìœ %",    st.column_config.NumberColumn("ì†ì ˆì—¬ìœ (%)",      format="%.2f"))
    return cfg

def render_table(df, *, key: str, height=620):
    st.data_editor(
        df,
        key=key,
        width="stretch",
        height=height,
        hide_index=True,
        disabled=True,
        num_rows="fixed",
        column_config=column_config_for(df),
    )

# ---------------- Filters (ê³µí†µ) ----------------
with st.container():
    c1, c2, c3, c4, c5 = st.columns([1,1,1,1,2])
    with c1:
        min_turn = st.slider("ìµœì†Œ ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", 0, 5000, 0, step=50, key="flt_turn")
    with c2:
        sort_key = st.selectbox("ì •ë ¬", ["EV_SCOREâ–¼","EBSâ–¼","ê±°ë˜ëŒ€ê¸ˆâ–¼","ì‹œê°€ì´ì•¡â–¼","RSIâ–²","RSIâ–¼","ì¢…ê°€â–²","ì¢…ê°€â–¼"], index=0, key="flt_sort")
    with c3:
        topn = st.slider("í‘œì‹œ ìˆ˜(Top N)", 10, 500, 200, step=10, key="flt_topn")
    with c4:
        q_text = st.text_input("ğŸ” ì¢…ëª©ëª…/ì½”ë“œ ê²€ìƒ‰", value="", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì ë˜ëŠ” 005930", key="flt_query")

view_base = latest.copy()
if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in view_base.columns:
    view_base = view_base[view_base["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] >= float(min_turn)]
if q_text:
    q = q_text.strip().lower()
    view_base = view_base[
        view_base["ì¢…ëª©ëª…"].fillna("").astype(str).str.lower().str.contains(q) |
        view_base["ì¢…ëª©ì½”ë“œ"].fillna("").astype(str).str.contains(q)
    ]

def safe_sort(dfv, key):
    try:
        if key=="EV_SCOREâ–¼" and "EV_SCORE" in dfv.columns:
            return dfv.sort_values("EV_SCORE", ascending=False, na_position="last")
        if key=="EBSâ–¼" and "EBS" in dfv.columns:
            by = ["EBS"] + (["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in dfv.columns else [])
            return dfv.sort_values(by=by, ascending=[False]+[False]*(len(by)-1))
        if key=="ê±°ë˜ëŒ€ê¸ˆâ–¼" and "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in dfv.columns:
            return dfv.sort_values("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", ascending=False)
        if key=="ì‹œê°€ì´ì•¡â–¼" and "ì‹œê°€ì´ì•¡(ì–µì›)" in dfv.columns:
            return dfv.sort_values("ì‹œê°€ì´ì•¡(ì–µì›)", ascending=False, na_position="last")
        if key=="RSIâ–²" and "RSI14" in dfv.columns:
            return dfv.sort_values("RSI14", ascending=True, na_position="last")
        if key=="RSIâ–¼" and "RSI14" in dfv.columns:
            return dfv.sort_values("RSI14", ascending=False, na_position="last")
        if key=="ì¢…ê°€â–²" and "ì¢…ê°€" in dfv.columns:
            return dfv.sort_values("ì¢…ê°€", ascending=True, na_position="last")
        if key=="ì¢…ê°€â–¼" and "ì¢…ê°€" in dfv.columns:
            return dfv.sort_values("ì¢…ê°€", ascending=False, na_position="last")
    except Exception:
        pass
    for alt in ["EV_SCORE","EBS","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","ì¢…ê°€"]:
        if alt in dfv.columns:
            return dfv.sort_values(alt, ascending=False, na_position="last")
    return dfv

# ---------------- Tabs ----------------
tab1, tab2 = st.tabs(["ğŸŸ¢ Top Picks", "ğŸ“‹ ì „ì²´ ë³´ê¸°"])

with tab1:
    st.subheader("ğŸ›  Top Picks ì¡°ê±´", anchor=False)
    c1, c2, c3, c4, c5 = st.columns(5)
    with c1:
        rr_min = st.slider("ìµœì†Œ RR(ëª©í‘œ1/ì†ì ˆ)", 1.00, 3.00, 1.00, step=0.25, key="tp_rr")
    with c2:
        ers_min = st.slider("ERS â‰¥", 0.00, 3.00, 1.00, step=0.50, key="tp_ers")
    with c3:
        sl_min = st.slider("ì†ì ˆì—¬ìœ  â‰¥ (%)", 0.00, 10.00, 0.00, step=0.50, key="tp_sl")
    with c4:
        t1_min = st.slider("ëª©í‘œ1ì—¬ìœ  â‰¥ (%)", 0.00, 15.00, 0.00, step=0.50, key="tp_t1")
    with c5:
        near_band = st.slider("Now ê·¼ì ‘ ë°´ë“œ(Â±%)", 0.00, 3.00, 0.00, step=0.10, key="tp_near")

    scored = add_eval_columns(view_base, near_band)

    tp = scored.copy()
    tp = tp[tp["EBS"] >= PASS_SCORE]
    tp = tp.dropna(subset=["ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¢…ê°€"])

    if rr_min > 0:
        tp = tp[tp["RR1"] >= rr_min]
    if ers_min > 0:
        tp = tp[tp["ERS"] >= ers_min]
    if sl_min > 0:
        tp = tp[tp["SLì—¬ìœ %"] >= sl_min]
    if t1_min > 0:
        tp = tp[tp["T1ì—¬ìœ %"] >= t1_min]
    if near_band > 0:
        tp = tp[tp["Now%"] <= near_band]

    tp = safe_sort(tp, sort_key).head(int(topn))

    if "EBS" in tp.columns:
        tp["í†µê³¼"] = np.where(tp["EBS"]>=PASS_SCORE, "ğŸš€", "")

    cols = [
        "í†µê³¼","ì‹œì¥","ì¢…ëª©ëª…","ì¢…ëª©ì½”ë“œ",
        "ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2",
        "EV_SCORE","ERS","RR1","Now%","T1ì—¬ìœ %","SLì—¬ìœ %",
        "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)",
        "EBS","ê·¼ê±°",
        "RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%"
    ]
    for c in cols:
        if c not in tp.columns: tp[c]=np.nan

    st.write(f"ğŸ“‹ ì´ {len(view_base):,}ê°œ / í‘œì‹œ {min(len(tp), int(topn)):,}ê°œ")
    tp_fmt = cast_for_editor(tp[cols])
    render_table(tp_fmt, key="tbl_top_picks")

    st.download_button(
        "ğŸ“¥ Top Picks ë‹¤ìš´ë¡œë“œ (CSV)",
        data=tp[cols].to_csv(index=False, encoding="utf-8-sig"),
        file_name="ldy_top_picks.csv",
        mime="text/csv",
        key="dl_top_picks",
    )

with tab2:
    scored_all = add_eval_columns(view_base, near_band_pct=0.0)
    view = safe_sort(scored_all, sort_key).head(int(topn))

    if "EBS" in view.columns:
        view["í†µê³¼"] = np.where(view["EBS"]>=PASS_SCORE, "ğŸš€", "")

    cols = [
        "í†µê³¼","ì‹œì¥","ì¢…ëª©ëª…","ì¢…ëª©ì½”ë“œ",
        "ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2",
        "EV_SCORE","ERS","RR1","Now%","T1ì—¬ìœ %","SLì—¬ìœ %",
        "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)",
        "EBS","ê·¼ê±°",
        "RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%"
    ]
    for c in cols:
        if c not in view.columns: view[c]=np.nan

    st.write(f"ğŸ“‹ ì´ {len(view_base):,}ê°œ / í‘œì‹œ {min(len(view), int(topn)):,}ê°œ")
    v_fmt = cast_for_editor(view[cols])
    render_table(v_fmt, key="tbl_full_view")

    st.download_button(
        "ğŸ“¥ ì „ì²´ ë³´ê¸° ë‹¤ìš´ë¡œë“œ (CSV)",
        data=view[cols].to_csv(index=False, encoding="utf-8-sig"),
        file_name="ldy_entry_candidates.csv",
        mime="text/csv",
        key="dl_full_view",
    )

with st.expander("â„¹ï¸ ì ìˆ˜/ì§€í‘œ ì„¤ëª…", expanded=False):
    st.markdown("""
**EBS(0~7)**: RSI 45~65 / MACDâ†‘ / MA20Â±4% / VolZ>1.2 / MA20â†‘ / MACD>0 / 5d<10%  
**RR1**: (ëª©í‘œ1âˆ’ì¶”ì²œë§¤ìˆ˜) / (ì¶”ì²œë§¤ìˆ˜âˆ’ì†ì ˆ)  
**Now%**: |í˜„ì¬ê°€âˆ’ì¶”ì²œë§¤ìˆ˜|/ì¶”ì²œë§¤ìˆ˜Ã—100  
**T1ì—¬ìœ %**: (ëª©í‘œ1âˆ’í˜„ì¬ê°€)/í˜„ì¬ê°€Ã—100  
**SLì—¬ìœ %**: (í˜„ì¬ê°€âˆ’ì†ì ˆ)/í˜„ì¬ê°€Ã—100  
**ERS(0~3)**: EBS í†µê³¼(â‰¥4) + MACD_slope>0 + RSI 45~65  
**EV_SCORE**: 0.25Â·RR + 0.20Â·T1ì—¬ìœ  + 0.15Â·SLì—¬ìœ  + 0.20Â·ERS + 0.10Â·ê·¼ì ‘ + 0.10Â·ìœ ë™ì„±  
â†’ ì´í›„ MACD_hist ì–‘ìˆ˜ ì•„ë‹˜ Ã—0.90, MACD_slopeâ‰¤0 Ã—0.75, RSI ë²”ìœ„ ë°–/NaN Ã—0.90, p95 ë¦¬ìŠ¤ì¼€ì¼
""")
