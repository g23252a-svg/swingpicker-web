# -*- coding: utf-8 -*-
"""
LDY Pro Trader v3.4.1 (Auto Update + EV Score + Top Picks)
- CSV: data/recommend_latest.csv (remote ìš°ì„ )
- ì´ë¦„ë§µ: data/krx_codes.csv (remote/FDR/pykrx í´ë°±)
- Now-Entry(%)ê°€ 0%ë¡œ ë­‰ê°œì§€ì§€ ì•Šë„ë¡: float ê³„ì‚° â†’ í‘œì‹œëŠ” í¬ë§·ë§Œ ë°˜ì˜¬ë¦¼
- EV_SCORE/Top Picks ë‚´ì¥ (í•„í„°: ìµœì†Œ RR, ì†ì ˆì—¬ìœ , ëª©í‘œ1ì—¬ìœ , ERS, Now ê·¼ì ‘ ë°´ë“œ)
"""

import os, io, math, requests, numpy as np, pandas as pd, streamlit as st
from datetime import datetime

# optional deps
try:
    from pykrx import stock
    PYKRX_OK = True
except Exception:
    PYKRX_OK = False

try:
    import FinanceDataReader as fdr
    FDR_OK = True
except Exception:
    FDR_OK = False

st.set_page_config(page_title="LDY Pro Trader v3.4.1 (Auto Update)", layout="wide")
st.title("ğŸ“ˆ LDY Pro Trader v3.4 (Auto Update)")
st.caption("ë§¤ì¼ ì¥ë§ˆê° í›„ ìë™ ì—…ë°ì´íŠ¸ë˜ëŠ” ìŠ¤ìœ™ ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ | EVìŠ¤ì½”ì–´Â·TopPick ë‚´ì¥")

RAW_URL   = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/recommend_latest.csv"
LOCAL_RAW = "data/recommend_latest.csv"
CODES_URL = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/krx_codes.csv"
LOCAL_MAP = "data/krx_codes.csv"
PASS_SCORE = 4

# ---------------- IO ----------------
@st.cache_data(ttl=300)
def load_csv_url(url: str) -> pd.DataFrame:
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    return pd.read_csv(io.BytesIO(r.content))

@st.cache_data(ttl=300)
def load_csv_path(path: str) -> pd.DataFrame:
    return pd.read_csv(path)

def log_src(df: pd.DataFrame, src: str, url_or_path: str):
    st.info(f"ìƒíƒœ âœ… ë°ì´í„° ë¡œë“œ: {src}\n\n{url_or_path}")
    st.success(f"ğŸ“… í‘œì‹œì‹œê°: {pd.Timestamp.now(tz='Asia/Seoul').strftime('%Y-%m-%d %H:%M')} Â· í–‰ìˆ˜: {len(df):,}")

# --------------- utils --------------
def z6(x) -> str:
    s = str(x)
    return s.zfill(6) if s.isdigit() else s

def ensure_turnover(df: pd.DataFrame) -> pd.DataFrame:
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" not in df.columns:
        base = None
        if "ê±°ë˜ëŒ€ê¸ˆ(ì›)" in df.columns:
            base = pd.to_numeric(df["ê±°ë˜ëŒ€ê¸ˆ(ì›)"], errors="coerce")
        elif all(x in df.columns for x in ["ê±°ë˜ëŸ‰","ì¢…ê°€"]):
            base = pd.to_numeric(df["ê±°ë˜ëŸ‰"], errors="coerce") * pd.to_numeric(df["ì¢…ê°€"], errors="coerce")
        if base is not None:
            df["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] = (base/1e8).round(2)
    return df

def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:
    cmap = {
        "Date":"ë‚ ì§œ","date":"ë‚ ì§œ",
        "Code":"ì¢…ëª©ì½”ë“œ","í‹°ì»¤":"ì¢…ëª©ì½”ë“œ","ticker":"ì¢…ëª©ì½”ë“œ",
        "Name":"ì¢…ëª©ëª…","name":"ì¢…ëª©ëª…",
        "Open":"ì‹œê°€","High":"ê³ ê°€","Low":"ì €ê°€","Close":"ì¢…ê°€","Volume":"ê±°ë˜ëŸ‰",
        "ê±°ë˜ëŒ€ê¸ˆ":"ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡":"ì‹œê°€ì´ì•¡(ì›)"
    }
    for k,v in cmap.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k:v})

    if "ë‚ ì§œ" in df.columns:
        with pd.option_context('future.no_silent_downcasting', True):
            try: df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"])
            except: pass
    if "ì¢…ëª©ì½”ë“œ" in df.columns:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.replace(".0","", regex=False).map(z6)
    else:
        df["ì¢…ëª©ì½”ë“œ"] = None
    if "ì‹œì¥" not in df.columns:
        df["ì‹œì¥"] = "ALL"
    if "ì¢…ëª©ëª…" not in df.columns:
        df["ì¢…ëª©ëª…"] = None

    for c in ["ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€","ê±°ë˜ëŸ‰","ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡(ì›)"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    df = ensure_turnover(df)
    return df

# -------- name map (robust) --------
@st.cache_data(ttl=6*60*60)
def load_name_map() -> pd.DataFrame | None:
    # 1) repoì˜ data/krx_codes.csv ìš°ì„ 
    try:
        m = load_csv_url(CODES_URL)
        if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
    except Exception:
        pass
    if os.path.exists(LOCAL_MAP):
        try:
            m = load_csv_path(LOCAL_MAP)
            if {"ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"}.issubset(m.columns):
                m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
                return m[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]].drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass

    # 2) FDR í´ë°±
    if FDR_OK:
        try:
            lst = fdr.StockListing("KRX")
            m = lst.rename(columns={"Code":"ì¢…ëª©ì½”ë“œ","Name":"ì¢…ëª©ëª…"})[["ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]]
            m["ì¢…ëª©ì½”ë“œ"] = m["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
            return m.drop_duplicates("ì¢…ëª©ì½”ë“œ")
        except Exception:
            pass

    # 3) pykrx ê°œë³„ ì¡°íšŒ
    if PYKRX_OK:
        today = datetime.now().strftime("%Y%m%d")
        rows = []
        try:
            for mk in ["KOSPI","KOSDAQ","KONEX"]:
                try:
                    lst = stock.get_market_ticker_list(today, market=mk)
                except Exception:
                    lst = []
                for t in lst:
                    try:
                        nm = stock.get_market_ticker_name(t)
                    except Exception:
                        nm = None
                    rows.append({"ì¢…ëª©ì½”ë“œ": str(t).zfill(6), "ì¢…ëª©ëª…": nm})
            m = pd.DataFrame(rows).dropna().drop_duplicates("ì¢…ëª©ì½”ë“œ")
            return m if len(m) else None
        except Exception:
            return None
    return None

def apply_names(df: pd.DataFrame) -> pd.DataFrame:
    mp = load_name_map()
    if mp is not None:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).map(z6)
        if "ì¢…ëª©ëª…" not in df.columns: df["ì¢…ëª©ëª…"] = None
        df = df.merge(mp, on="ì¢…ëª©ì½”ë“œ", how="left", suffixes=("","_map"))
        df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna(df["ì¢…ëª©ëª…_map"])
        df = df.drop(columns=[c for c in df.columns if c.endswith("_map")], errors="ignore")
    df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna("(ì´ë¦„ì—†ìŒ)")
    return df

# -------- ë°ì´í„° ë¡œë“œ --------
try:
    df_raw = load_csv_url(RAW_URL); log_src(df_raw, "remote", RAW_URL)
except Exception:
    if os.path.exists(LOCAL_RAW):
        df_raw = load_csv_path(LOCAL_RAW); log_src(df_raw, "local", LOCAL_RAW)
    else:
        st.error("âŒ CSVê°€ ì—†ìŠµë‹ˆë‹¤. Actionsì—ì„œ collectorê°€ data/recommend_latest.csvë¥¼ ì˜¬ë ¸ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

df = normalize_cols(df_raw.copy())
df = apply_names(df)

# ìˆ«ì ìºìŠ¤íŒ…
num_cols = [
    "ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2",
    "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_hist",
    "MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","EBS"
]
for c in num_cols:
    if c in df.columns:
        df[c] = pd.to_numeric(df[c], errors="coerce")

# ---------- íŒŒìƒì§€í‘œ(ì§„ì…ì„±) ----------
# ê·¼ì ‘ë„/ì—¬ìœ /ë¦¬ìŠ¤í¬-ë¦¬ì›Œë“œ
df["NOW_ENTRY_%"] = 100.0 * ((df["ì¢…ê°€"] - df["ì¶”ì²œë§¤ìˆ˜ê°€"]) / df["ì¶”ì²œë§¤ìˆ˜ê°€"])
df["NOW_ENTRY_ABS_%"] = df["NOW_ENTRY_%"].abs()
df["STOP_GAP_%"] = 100.0 * ((df["ì¶”ì²œë§¤ìˆ˜ê°€"] - df["ì†ì ˆê°€"]) / df["ì¶”ì²œë§¤ìˆ˜ê°€"])
df["T1_GAP_%"]   = 100.0 * ((df["ì¶”ì²œë§¤ë„ê°€1"] - df["ì¶”ì²œë§¤ìˆ˜ê°€"]) / df["ì¶”ì²œë§¤ìˆ˜ê°€"])
df["RR_T1"] = np.where(df["STOP_GAP_%"] > 0, df["T1_GAP_%"] / df["STOP_GAP_%"], np.nan)

# ERS(ê°„ì´ EV): p_hit ì¶”ì • * T1_GAP - (1-p)*STOP_GAP
def p_hit_est(row):
    ebs = row.get("EBS", np.nan)
    macds = row.get("MACD_slope", np.nan)
    volz = row.get("Vol_Z", np.nan)
    p = 0.40
    if pd.notna(ebs):  p += 0.06 * min(max(ebs, 0), 7)
    if pd.notna(macds) and macds > 0: p += 0.02
    if pd.notna(volz) and volz > 1.2: p += 0.01
    return float(np.clip(p, 0.25, 0.85))

p = df.apply(p_hit_est, axis=1)
df["ERS_%"] = p * df["T1_GAP_%"] - (1 - p) * df["STOP_GAP_%"]

# EV_SCORE (í‘œì¤€í™” ê°€ì¤‘ í•©)
def zsafe(s):
    s = pd.to_numeric(s, errors="coerce")
    m, v = np.nanmean(s), np.nanstd(s)
    if not np.isfinite(v) or v == 0: return pd.Series(np.zeros(len(s)), index=s.index)
    return (s - m) / v

df["EV_SCORE"] = (
    0.35 * zsafe(df["EBS"]) +
    0.25 * zsafe(df["RR_T1"]) +
    0.20 * zsafe(df["T1_GAP_%"]) +
   -0.10 * zsafe(df["NOW_ENTRY_ABS_%"]) +
    0.10 * zsafe(df["Vol_Z"])
)

# ---------- ë³´ê¸° ëª¨ë“œ ----------
mode = st.radio("ë³´ê¸° ëª¨ë“œ", ["Top Picks", "ì „ì²´ ë³´ê¸°"], horizontal=True)

with st.expander("ğŸ” ë³´ê¸°/í•„í„°", expanded=True):
    c1,c2,c3,c4,c5 = st.columns([1,1,1,1,2])
    with c1:
        min_turn = st.slider("ìµœì†Œ ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", 0, 5000, 50, step=10)
    with c2:
        sort_key = st.selectbox("ì •ë ¬", ["EV_SCOREâ–¼","EBSâ–¼","ê±°ë˜ëŒ€ê¸ˆâ–¼","RSIâ–²","RSIâ–¼","ì¢…ê°€â–²","ì¢…ê°€â–¼"], index=0)
    with c3:
        topn = st.slider("í‘œì‹œ ìˆ˜(Top N)", 10, 500, 200, step=10)
    with c4:
        q_text = st.text_input("ğŸ” ì¢…ëª©ëª…/ì½”ë“œ ê²€ìƒ‰", value="", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì ë˜ëŠ” 005930")
    with c5:
        pass

view = df.copy()
view = view[view["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] >= float(min_turn)]
if q_text:
    q = q_text.strip().lower()
    view = view[
        view["ì¢…ëª©ëª…"].fillna("").astype(str).str.lower().str.contains(q) |
        view["ì¢…ëª©ì½”ë“œ"].fillna("").astype(str).str.contains(q)
    ]

if mode == "Top Picks":
    with st.expander("ğŸ›  Top Picks ì¡°ê±´", expanded=True):
        c1,c2,c3,c4,c5 = st.columns(5)
        with c1:
            min_rr = st.slider("ìµœì†Œ RR(ëª©í‘œ1/ì†ì ˆ)", 1.00, 3.00, 1.20, step=0.05)
        with c2:
            min_stop = st.slider("ì†ì ˆì—¬ìœ  â‰¥ (%)", 0.00, 5.00, 1.00, step=0.25)
        with c3:
            min_t1 = st.slider("ëª©í‘œ1ì—¬ìœ  â‰¥ (%)", 0.00, 10.00, 3.00, step=0.5)
        with c4:
            min_ers = st.slider("ERS â‰¥", 0.00, 3.00, 0.20, step=0.05)
        with c5:
            band = st.slider("Now ê·¼ì ‘ ë°´ë“œ(Â±%)", 0.00, 3.00, 1.50, step=0.25)

    # í•„í„°
    view = view[
        (view["RR_T1"] >= min_rr) &
        (view["STOP_GAP_%"] >= min_stop) &
        (view["T1_GAP_%"] >= min_t1) &
        (view["ERS_%"] >= min_ers) &
        (view["NOW_ENTRY_ABS_%"] <= band)
    ]

# ì •ë ¬
def safe_sort(dfv, key):
    try:
        if key=="EV_SCOREâ–¼": return dfv.sort_values("EV_SCORE", ascending=False, na_position="last")
        if key=="EBSâ–¼":      return dfv.sort_values(["EBS","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"], ascending=[False,False])
        if key=="ê±°ë˜ëŒ€ê¸ˆâ–¼":  return dfv.sort_values("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", ascending=False)
        if key=="RSIâ–²":      return dfv.sort_values("RSI14", ascending=True, na_position="last")
        if key=="RSIâ–¼":      return dfv.sort_values("RSI14", ascending=False, na_position="last")
        if key=="ì¢…ê°€â–²":      return dfv.sort_values("ì¢…ê°€", ascending=True, na_position="last")
        if key=="ì¢…ê°€â–¼":      return dfv.sort_values("ì¢…ê°€", ascending=False, na_position="last")
    except Exception:
        pass
    for alt in ["EV_SCORE","EBS","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì¢…ê°€"]:
        if alt in dfv.columns:
            return dfv.sort_values(alt, ascending=False, na_position="last")
    return dfv

view = safe_sort(view, sort_key)
view = view.head(int(topn))

st.write(f"ğŸ“‹ ì´ {len(df):,}ê°œ / í‘œì‹œ {len(view):,}ê°œ")

# ---------- í‘œ ë Œë”ë§: íƒ€ì… ì•ˆì „ + í¬ë§· ----------
cols = [
    "ì‹œì¥","ì¢…ëª©ëª…","ì¢…ëª©ì½”ë“œ",
    "ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2",
    "NOW_ENTRY_%","NOW_ENTRY_ABS_%","STOP_GAP_%","T1_GAP_%","RR_T1","ERS_%","EV_SCORE",
    "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","EBS","ê·¼ê±°",
    "RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%"
]
for c in cols:
    if c not in view.columns: view[c] = np.nan

# í‘œì‹œëŠ” ë³„ë„ ì‚¬ë³¸
vf = view[cols].copy()

# ê°€ê²©ë¥˜ â†’ Int64 (NaN í—ˆìš© ì •ìˆ˜)
for c in ["ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","EBS"]:
    if c in vf.columns:
        vf[c] = pd.to_numeric(vf[c], errors="coerce").round(0).astype("Int64")

# ë‚˜ë¨¸ì§€ ìˆ˜ì¹˜ â†’ float ìœ ì§€(í¼ì„¼íŠ¸/ì§€í‘œ í¬ë§·ì€ í‘œì‹œì—ì„œ ì²˜ë¦¬)
for c in ["NOW_ENTRY_%","NOW_ENTRY_ABS_%","STOP_GAP_%","T1_GAP_%","RR_T1","ERS_%","EV_SCORE",
          "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%"]:
    if c in vf.columns:
        vf[c] = pd.to_numeric(vf[c], errors="coerce")

st.data_editor(
    vf,
    width="stretch",
    height=680,
    hide_index=True,
    disabled=True,
    num_rows="fixed",
    column_config={
        # í…ìŠ¤íŠ¸
        "ì‹œì¥":         st.column_config.TextColumn("ì‹œì¥"),
        "ì¢…ëª©ëª…":       st.column_config.TextColumn("ì¢…ëª©ëª…"),
        "ì¢…ëª©ì½”ë“œ":     st.column_config.TextColumn("ì¢…ëª©ì½”ë“œ"),
        "ê·¼ê±°":         st.column_config.TextColumn("ê·¼ê±°"),
        # ê°€ê²©/ì •ìˆ˜
        "ì¢…ê°€":          st.column_config.NumberColumn("ì¢…ê°€",           format="%,d"),
        "ì¶”ì²œë§¤ìˆ˜ê°€":    st.column_config.NumberColumn("ì¶”ì²œë§¤ìˆ˜ê°€",     format="%,d"),
        "ì†ì ˆê°€":        st.column_config.NumberColumn("ì†ì ˆê°€",         format="%,d"),
        "ì¶”ì²œë§¤ë„ê°€1":   st.column_config.NumberColumn("ì¶”ì²œë§¤ë„ê°€1",    format="%,d"),
        "ì¶”ì²œë§¤ë„ê°€2":   st.column_config.NumberColumn("ì¶”ì²œë§¤ë„ê°€2",    format="%,d"),
        "EBS":          st.column_config.NumberColumn("EBS",            format="%d"),
        # í¼ì„¼íŠ¸/ìŠ¤ì½”ì–´
        "NOW_ENTRY_%":      st.column_config.NumberColumn("Now-Entry(%)",     format="%.2f%%"),
        "NOW_ENTRY_ABS_%":  st.column_config.NumberColumn("|Now-Entry|(%)",   format="%.2f%%"),
        "STOP_GAP_%":       st.column_config.NumberColumn("ì†ì ˆì—¬ìœ (%)",      format="%.2f%%"),
        "T1_GAP_%":         st.column_config.NumberColumn("ëª©í‘œ1ì—¬ìœ (%)",     format="%.2f%%"),
        "RR_T1":            st.column_config.NumberColumn("RR(ëª©í‘œ1/ì†ì ˆ)",   format="%.2f"),
        "ERS_%":            st.column_config.NumberColumn("ERS",              format="%.2f"),
        "EV_SCORE":         st.column_config.NumberColumn("EV_SCORE",         format="%.2f"),
        # ì–µì›/ì§€í‘œ
        "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)": st.column_config.NumberColumn("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)",  format="%,.0f"),
        "ì‹œê°€ì´ì•¡(ì–µì›)": st.column_config.NumberColumn("ì‹œê°€ì´ì•¡(ì–µì›)",  format="%,.0f"),
        "RSI14":        st.column_config.NumberColumn("RSI14",          format="%.1f"),
        "ä¹–é›¢%":         st.column_config.NumberColumn("ä¹–é›¢%",           format="%.2f"),
        "MACD_hist":    st.column_config.NumberColumn("MACD_hist",      format="%.4f"),
        "MACD_slope":   st.column_config.NumberColumn("MACD_slope",     format="%.5f"),
        "Vol_Z":        st.column_config.NumberColumn("Vol_Z",          format="%.2f"),
        "ret_5d_%":     st.column_config.NumberColumn("ret_5d_%",       format="%.2f"),
        "ret_10d_%":    st.column_config.NumberColumn("ret_10d_%",      format="%.2f"),
    },
)

st.download_button(
    "ğŸ“¥ í˜„ì¬ ë³´ê¸° ë‹¤ìš´ë¡œë“œ (CSV)",
    data=vf.to_csv(index=False, encoding="utf-8-sig"),
    file_name="ldy_entry_candidates.csv",
    mime="text/csv"
)

with st.expander("â„¹ï¸ ì ìˆ˜/ì§€í‘œ ì„¤ëª…"):
    st.markdown("""
**EBS(0~7)**: RSI 45~65 / MACDìƒìŠ¹ / MA20 ê·¼ì²˜ / ê±°ë˜ëŸ‰ì¦ê°€ / ìƒìŠ¹êµ¬ì¡°(MA20>MA60) / MACD>sig / 5ì¼ìˆ˜ìµ<10%  
**Now-Entry(%)**: (ì¢…ê°€âˆ’ì¶”ì²œë§¤ìˆ˜)/ì¶”ì²œë§¤ìˆ˜Ã—100 â†’ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ 'ì§€ê¸ˆ ê°€ê²©ì´ ì—”íŠ¸ë¦¬ì™€ ê·¼ì ‘'  
**ì†ì ˆì—¬ìœ (%)**: (ì¶”ì²œë§¤ìˆ˜âˆ’ì†ì ˆ)/ì¶”ì²œë§¤ìˆ˜Ã—100  
**ëª©í‘œ1ì—¬ìœ (%)**: (ëª©í‘œ1âˆ’ì¶”ì²œë§¤ìˆ˜)/ì¶”ì²œë§¤ìˆ˜Ã—100  
**RR(ëª©í‘œ1/ì†ì ˆ)**: ëª©í‘œ1ì—¬ìœ  Ã· ì†ì ˆì—¬ìœ  (â‰¥1.2 ê¶Œì¥)  
**ERS**: p_hit ì¶”ì • ê¸°ë°˜ ê°„ì´ ê¸°ëŒ€ê°’(ë†’ì„ìˆ˜ë¡ ìœ ë¦¬)  
**EV_SCORE**: EBS, RR, ëª©í‘œì—¬ìœ , Nowê·¼ì ‘ë„, Vol_Z í‘œì¤€í™” ê°€ì¤‘í•© (ë†’ì„ìˆ˜ë¡ ìš°ì„ ìˆœìœ„â†‘)
""")
