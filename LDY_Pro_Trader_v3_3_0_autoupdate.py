# -*- coding: utf-8 -*-
"""
LDY Pro Trader v3.3.1 (Auto Update + Name Enrich + Safe Sort/Turnover Fallback)
- GitHub raw CSV ìš°ì„  ë¡œë“œ, ì‹¤íŒ¨ì‹œ ë¡œì»¬ data/recommend_latest.csv í´ë°±
- CSVê°€ ì›ì‹œ OHLCVë§Œ ìˆì–´ë„ í™”ë©´ì—ì„œ RSI/MACD/ATR/MA/VolZ/ìˆ˜ìµë¥  â†’ EBS/ì¶”ì²œê°€ ì‚°ì¶œ
- ì¢…ëª©ëª… ì—†ìœ¼ë©´ pykrxë¡œ ì‹¤ì‹œê°„ ë§¤í•‘(6ìë¦¬ 0íŒ¨ë”© í¬í•¨, ìºì‹œ)
- ê±°ë˜ëŒ€ê¸ˆ(ì–µì›) ì—†ì„ ë•Œë„ ì•ˆì „ ë³´ê°•: ê±°ë˜ëŒ€ê¸ˆ(ì›) ë˜ëŠ” ê±°ë˜ëŸ‰*ì¢…ê°€ë¡œ ê³„ì‚°
- ì •ë ¬ ì‹œ ì»¬ëŸ¼ ì—†ìœ¼ë©´ ì•ˆì „ í´ë°±( KeyError ë°©ì§€ )
- 'use_container_width' ê²½ê³  ëŒ€ì‘: width="stretch" ì‚¬ìš©
"""

import os, io, math, requests, numpy as np, pandas as pd, streamlit as st
from datetime import datetime

# pykrx(ì„ íƒ): ì—†ë”ë¼ë„ ì•±ì€ ë™ì‘(ì´ë¦„ ë§¤í•‘ë§Œ ìƒëµ)
try:
    from pykrx import stock
    PYKRX_OK = True
except Exception:
    PYKRX_OK = False

st.set_page_config(page_title="LDY Pro Trader v3.3.1 (Auto Update)", layout="wide")
st.title("ğŸ“ˆ LDY Pro Trader v3.3.1 (Auto Update)")
st.caption("ë§¤ì¼ ì¥ë§ˆê° í›„ ìë™ ì—…ë°ì´íŠ¸ë˜ëŠ” ìŠ¤ìœ™ ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ | Made by LDY")

RAW_URL = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/recommend_latest.csv"
LOCAL_PATH = "data/recommend_latest.csv"
PASS_SCORE = 4

# ------------------------- IO -------------------------
@st.cache_data(ttl=300, show_spinner=False)
def load_remote_csv(url: str) -> pd.DataFrame:
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    return pd.read_csv(io.BytesIO(r.content))

@st.cache_data(ttl=300, show_spinner=False)
def load_local_csv(path: str) -> pd.DataFrame:
    return pd.read_csv(path)

def info_src(df: pd.DataFrame, src_text: str):
    st.info(f"ìƒíƒœ\nâœ… ë°ì´í„° ë¡œë“œ: {src_text}\n\n{RAW_URL if 'remote' in src_text else LOCAL_PATH}")
    st.success(f"ğŸ“… ì¶”ì²œ ê¸°ì¤€(í‘œì‹œ ì‹œê°): {pd.Timestamp.now(tz='Asia/Seoul').strftime('%Y-%m-%d %H:%M')} Â· ì›ì‹œ í–‰ìˆ˜: {len(df):,}")

# ------------------------- ì§€í‘œ -------------------------
def ema(s: pd.Series, span: int):
    return s.ewm(span=span, adjust=False, min_periods=span).mean()

def rsi14(close: pd.Series, period: int = 14):
    delta = close.diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.rolling(period).mean()
    avg_loss = loss.rolling(period).mean()
    rs = avg_gain / avg_loss.replace(0, np.nan)
    return 100 - (100 / (1 + rs))

def macd_features(close: pd.Series):
    ema12 = ema(close, 12)
    ema26 = ema(close, 26)
    macd_line = ema12 - ema26
    signal = macd_line.ewm(span=9, adjust=False, min_periods=9).mean()
    hist = macd_line - signal
    slope = hist.diff()
    return hist, slope

def atr14(high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):
    prev = close.shift(1)
    tr = pd.concat([(high - low), (high - prev).abs(), (low - prev).abs()], axis=1).max(axis=1)
    return tr.rolling(period).mean()

# ------------------------- ì •ê·œí™”/ë³´ê°• -------------------------
def z6(x) -> str:
    s = str(x)
    return s.zfill(6) if s.isdigit() else s

def ensure_turnover_cols(df: pd.DataFrame) -> pd.DataFrame:
    """
    ê±°ë˜ëŒ€ê¸ˆ(ì–µì›) ë³´ê°•:
    1) ê±°ë˜ëŒ€ê¸ˆ(ì–µì›) ìˆìœ¼ë©´ ìœ ì§€
    2) ê±°ë˜ëŒ€ê¸ˆ(ì›) ìˆìœ¼ë©´ /1e8
    3) ê±°ë˜ëŸ‰ & ì¢…ê°€ ìˆìœ¼ë©´ ê±°ë˜ëŸ‰*ì¢…ê°€ /1e8
    """
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" not in df.columns:
        base = None
        if "ê±°ë˜ëŒ€ê¸ˆ(ì›)" in df.columns:
            base = pd.to_numeric(df["ê±°ë˜ëŒ€ê¸ˆ(ì›)"], errors="coerce")
        elif all(c in df.columns for c in ["ê±°ë˜ëŸ‰","ì¢…ê°€"]):
            vol = pd.to_numeric(df["ê±°ë˜ëŸ‰"], errors="coerce")
            cls = pd.to_numeric(df["ì¢…ê°€"], errors="coerce")
            base = vol * cls
        if base is not None:
            df["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] = (base / 1e8).round(2)
    return df

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    # ì»¬ëŸ¼ëª… í†µì¼
    colmap = {
        "Date":"ë‚ ì§œ","date":"ë‚ ì§œ",
        "Code":"ì¢…ëª©ì½”ë“œ","í‹°ì»¤":"ì¢…ëª©ì½”ë“œ","ticker":"ì¢…ëª©ì½”ë“œ",
        "Name":"ì¢…ëª©ëª…","name":"ì¢…ëª©ëª…",
        "Open":"ì‹œê°€","High":"ê³ ê°€","Low":"ì €ê°€","Close":"ì¢…ê°€","Volume":"ê±°ë˜ëŸ‰",
        "ê±°ë˜ëŒ€ê¸ˆ":"ê±°ë˜ëŒ€ê¸ˆ(ì›)",  # pykrx ì¼ê´„ ëŒ€ì‘
        "ì‹œê°€ì´ì•¡":"ì‹œê°€ì´ì•¡(ì›)"
    }
    for k,v in colmap.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k:v})

    # íƒ€ì… ìºìŠ¤íŒ…
    for c in ["ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€","ê±°ë˜ëŸ‰","ê±°ë˜ëŒ€ê¸ˆ(ì›)","ì‹œê°€ì´ì•¡(ì›)"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    # ë‚ ì§œ
    if "ë‚ ì§œ" in df.columns:
        try:
            df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"])
        except Exception:
            pass

    # ì½”ë“œ 6ìë¦¬
    if "ì¢…ëª©ì½”ë“œ" in df.columns:
        df["ì¢…ëª©ì½”ë“œ"] = df["ì¢…ëª©ì½”ë“œ"].astype(str).str.replace(".0","", regex=False).map(z6)
    else:
        df["ì¢…ëª©ì½”ë“œ"] = None

    # ì‹œì¥/ì¢…ëª©ëª… ê¸°ë³¸ê°’
    if "ì‹œì¥" not in df.columns:
        df["ì‹œì¥"] = "ALL"
    if "ì¢…ëª©ëª…" not in df.columns:
        df["ì¢…ëª©ëª…"] = None

    # ê±°ë˜ëŒ€ê¸ˆ(ì–µì›) ë³´ê°•
    df = ensure_turnover_cols(df)

    return df

@st.cache_data(ttl=300, show_spinner=True)
def enrich_from_ohlcv(raw: pd.DataFrame) -> pd.DataFrame:
    must = {"ì¢…ëª©ì½”ë“œ","ë‚ ì§œ","ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€"}
    if not must.issubset(set(raw.columns)):
        return raw
    raw = raw.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"])
    g = raw.groupby("ì¢…ëª©ì½”ë“œ", group_keys=False)

    def _feat(x: pd.DataFrame):
        x = x.copy()
        x["MA20"] = x["ì¢…ê°€"].rolling(20).mean()
        x["ATR14"] = atr14(x["ê³ ê°€"], x["ì €ê°€"], x["ì¢…ê°€"], 14)
        x["RSI14"] = rsi14(x["ì¢…ê°€"], 14)
        hist, slope = macd_features(x["ì¢…ê°€"])
        x["MACD_hist"] = hist
        x["MACD_slope"] = slope
        x["Vol_Z"] = (x["ê±°ë˜ëŸ‰"] - x["ê±°ë˜ëŸ‰"].rolling(20).mean()) / x["ê±°ë˜ëŸ‰"].rolling(20).std()
        x["ä¹–é›¢%"] = (x["ì¢…ê°€"]/x["MA20"] - 1.0)*100
        x["ret_5d_%"] = (x["ì¢…ê°€"]/x["ì¢…ê°€"].shift(5) - 1.0)*100
        x["ret_10d_%"] = (x["ì¢…ê°€"]/x["ì¢…ê°€"].shift(10) - 1.0)*100

        last = x.iloc[-1:].copy()
        e = 0; why=[]
        def nz(v, fallback=-999): 
            return v if (v is not None and not (isinstance(v, float) and math.isnan(v))) else fallback

        rsi_v = nz(last["RSI14"].iloc[0])
        c1 = 45 <= rsi_v <= 65; e += int(c1);  why.append("RSI 45~65" if c1 else "")
        c2 = nz(last["MACD_slope"].iloc[0]) > 0; e+=int(c2); why.append("MACDâ†‘" if c2 else "")
        close, ma20 = last["ì¢…ê°€"].iloc[0], last["MA20"].iloc[0]
        c3 = (not math.isnan(ma20)) and (0.99*ma20 <= close <= 1.04*ma20); e+=int(c3); why.append("MA20Â±4%" if c3 else "")
        c4 = nz(last["Vol_Z"].iloc[0]) > 1.2; e+=int(c4); why.append("VolZ>1.2" if c4 else "")
        m20_prev = x["MA20"].iloc[-2] if len(x)>=2 else np.nan
        c5 = (not math.isnan(m20_prev)) and (last["MA20"].iloc[0] - m20_prev > 0); e+=int(c5); why.append("MA20â†‘" if c5 else "")
        c6 = nz(last["MACD_hist"].iloc[0]) > 0; e+=int(c6); why.append("MACD>0" if c6 else "")
        r5 = last["ret_5d_%"].iloc[0]; c7 = (not math.isnan(r5)) and (r5 < 10); e+=int(c7); why.append("5d<10%" if c7 else "")

        last["EBS"] = e
        last["ê·¼ê±°"] = " / ".join([w for w in why if w])

        atr = last["ATR14"].iloc[0]
        if math.isnan(atr) or math.isnan(ma20) or math.isnan(close) or atr <= 0:
            entry=t1=t2=stp=np.nan
        else:
            band_low, band_high = ma20 - 0.5*atr, ma20 + 0.5*atr
            entry = min(max(close, band_low), band_high)
            t1, t2, stp = entry + 1.0*atr, entry + 1.8*atr, entry - 1.2*atr
        last["ì¶”ì²œë§¤ìˆ˜ê°€"] = round(entry,2) if not math.isnan(entry) else np.nan
        last["ì¶”ì²œë§¤ë„ê°€1"] = round(t1,2) if not math.isnan(t1) else np.nan
        last["ì¶”ì²œë§¤ë„ê°€2"] = round(t2,2) if not math.isnan(t2) else np.nan
        last["ì†ì ˆê°€"] = round(stp,2) if not math.isnan(stp) else np.nan
        return last

    out = g.apply(_feat).reset_index(drop=True)

    # ê±°ë˜ëŒ€ê¸ˆ(ì–µì›) ìµœì‹ í–‰ ë³´ê°•
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" not in out.columns:
        # rawì—ì„œ ìµœì‹ í–‰ ì¶”ì¶œ í›„ ê³„ì‚°
        tail = raw.groupby("ì¢…ëª©ì½”ë“œ").tail(1).copy()
        tail = ensure_turnover_cols(tail)
        if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in tail.columns:
            out = out.merge(tail[["ì¢…ëª©ì½”ë“œ","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"]], on="ì¢…ëª©ì½”ë“œ", how="left")

    if "ì‹œê°€ì´ì•¡(ì–µì›)" not in out.columns:
        out["ì‹œê°€ì´ì•¡(ì–µì›)"] = np.nan
    if "ì‹œì¥" not in out.columns:
        out["ì‹œì¥"] = "ALL"
    return out

# ------------------------- ì¢…ëª©ëª… ë§¤í•‘ -------------------------
@st.cache_data(ttl=6*60*60, show_spinner=False)
def name_map_from_pykrx(codes: list[str]) -> dict:
    """pykrxë¡œ ì½”ë“œâ†’ì´ë¦„ ë§¤í•‘(ìºì‹œ 6ì‹œê°„). ì‹¤íŒ¨ëŠ” None."""
    if not PYKRX_OK:
        return {}
    out = {}
    for t in codes:
        try:
            out[t] = stock.get_market_ticker_name(t)
        except Exception:
            out[t] = None
    return out

def fill_names(df: pd.DataFrame) -> pd.DataFrame:
    if "ì¢…ëª©ì½”ë“œ" not in df.columns:
        return df
    need = df[df["ì¢…ëª©ëª…"].isna() | (df["ì¢…ëª©ëª…"]=="")]["ì¢…ëª©ì½”ë“œ"].dropna().astype(str).map(z6).unique().tolist()
    if len(need)==0:
        return df
    m = name_map_from_pykrx(need) if PYKRX_OK else {}
    if not m and not PYKRX_OK:
        st.warning("pykrxê°€ ì—†ì–´ì„œ ì¢…ëª©ëª… ë§¤í•‘ì„ ê±´ë„ˆëœë‹ˆë‹¤. (requirements.txt í™•ì¸)")
        df.loc[df["ì¢…ëª©ëª…"].isna() | (df["ì¢…ëª©ëª…"]==""), "ì¢…ëª©ëª…"] = "(ì´ë¦„ì—†ìŒ)"
        return df
    df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].where(df["ì¢…ëª©ëª…"].notna() & (df["ì¢…ëª©ëª…"]!=""), df["ì¢…ëª©ì½”ë“œ"].map(m))
    df["ì¢…ëª©ëª…"] = df["ì¢…ëª©ëª…"].fillna("(ì´ë¦„ì—†ìŒ)")
    return df

# ------------------------- ë¡œë“œ & ê°€ê³µ -------------------------
try:
    df_raw = load_remote_csv(RAW_URL)
    info_src(df_raw, "remote")
except Exception:
    if os.path.exists(LOCAL_PATH):
        df_raw = load_local_csv(LOCAL_PATH)
        info_src(df_raw, "local")
    else:
        st.error("âŒ CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. collectorê°€ data/recommend_latest.csvë¥¼ ì˜¬ë ¸ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

df_raw = normalize_columns(df_raw)

# EBS/ì¶”ì²œê°€ ì¡´ì¬ ì—¬ë¶€
has_ebs = "EBS" in df_raw.columns and df_raw["EBS"].notna().any()
has_reco = all(c in df_raw.columns for c in ["ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]) and \
           df_raw[["ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]].notna().any().any()

if has_ebs and has_reco:
    df = df_raw.copy()
else:
    with st.status("ğŸ§® ì›ì‹œ OHLCV â†’ ì§€í‘œ/ì ìˆ˜/ì¶”ì²œê°€ ìƒì„± ì¤‘...", expanded=False):
        df = enrich_from_ohlcv(df_raw)

# ìµœì‹  ì¼ìë§Œ ì§‘ê³„
if "ë‚ ì§œ" in df.columns:
    latest_by_code = df.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"]).groupby("ì¢…ëª©ì½”ë“œ").tail(1).copy()
else:
    latest_by_code = df.copy()

# ì¢…ëª©ëª… ë§¤í•‘
with st.status("ğŸ·ï¸ ì¢…ëª©ëª… ë§¤í•‘ ì¤‘...", expanded=False):
    latest_by_code = fill_names(latest_by_code)

# ì•ˆì „ ìºìŠ¤íŒ… + ê±°ë˜ëŒ€ê¸ˆ(ì–µì›) ìµœì¢… ë³´ê°•(í•œ ë²ˆ ë”)
latest_by_code = ensure_turnover_cols(latest_by_code)
for c in ["ì¢…ê°€","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","EBS","ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]:
    if c in latest_by_code.columns:
        latest_by_code[c] = pd.to_numeric(latest_by_code[c], errors="coerce")

# ------------------------- UI -------------------------
with st.expander("ğŸ” ë³´ê¸°/í•„í„°", expanded=True):
    c1,c2,c3,c4,c5 = st.columns([1,1,1,1,2])

    default_entry = True
    if "EBS" not in latest_by_code.columns or latest_by_code["EBS"].notna().sum()==0:
        default_entry = False
        st.warning("EBS ì ìˆ˜ê°€ ì—†ì–´ â€˜ğŸš€ ì´ˆì… í›„ë³´ë§Œâ€™ í•„í„°ë¥¼ ìë™ í•´ì œí•©ë‹ˆë‹¤. (ì›ì‹œ OHLCV ê³„ì‚° ì‹¤íŒ¨/ë°ì´í„° ë¶€ì¡±)")
    with c1:
        only_entry = st.checkbox("ğŸš€ ì´ˆì… í›„ë³´ë§Œ (EBSâ‰¥4)", value=default_entry)
    with c2:
        min_turn = st.slider("ìµœì†Œ ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", 0, 5000, 50, step=10)
    with c3:
        sort_key = st.selectbox("ì •ë ¬",
            ["EBSâ–¼","ê±°ë˜ëŒ€ê¸ˆâ–¼","ì‹œê°€ì´ì•¡â–¼","RSIâ–²","RSIâ–¼","ì¢…ê°€â–²","ì¢…ê°€â–¼"],
            index=0 if "EBS" in latest_by_code.columns else 1)
    with c4:
        topn = st.slider("í‘œì‹œ ìˆ˜(Top N)", 10, 500, 200, step=10)
    with c5:
        q_text = st.text_input("ğŸ” ì¢…ëª©ëª…/ì½”ë“œ ê²€ìƒ‰", value="", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì ë˜ëŠ” 005930")

view = latest_by_code.copy()

# í•„í„°
if only_entry and "EBS" in view.columns:
    view = view[view["EBS"] >= PASS_SCORE]
if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in view.columns:
    view = view[view["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] >= float(min_turn)]

if q_text:
    q = q_text.strip().lower()
    name_hit = view["ì¢…ëª©ëª…"].fillna("").astype(str).str.lower().str.contains(q, na=False)
    code_hit = view["ì¢…ëª©ì½”ë“œ"].fillna("").astype(str).str.contains(q, na=False)
    view = view[name_hit | code_hit]

# ì•ˆì „ ì •ë ¬
def safe_sort(dfv: pd.DataFrame, key: str) -> pd.DataFrame:
    try:
        if key == "EBSâ–¼" and "EBS" in dfv.columns:
            by = ["EBS"] + (["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in dfv.columns else [])
            return dfv.sort_values(by=by, ascending=[False] + [False]* (len(by)-1))
        if key == "ê±°ë˜ëŒ€ê¸ˆâ–¼" and "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in dfv.columns:
            return dfv.sort_values("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", ascending=False)
        if key == "ì‹œê°€ì´ì•¡â–¼" and "ì‹œê°€ì´ì•¡(ì–µì›)" in dfv.columns:
            return dfv.sort_values("ì‹œê°€ì´ì•¡(ì–µì›)", ascending=False, na_position="last")
        if key == "RSIâ–²" and "RSI14" in dfv.columns:
            return dfv.sort_values("RSI14", ascending=True, na_position="last")
        if key == "RSIâ–¼" and "RSI14" in dfv.columns:
            return dfv.sort_values("RSI14", ascending=False, na_position="last")
        if key == "ì¢…ê°€â–²" and "ì¢…ê°€" in dfv.columns:
            return dfv.sort_values("ì¢…ê°€", ascending=True, na_position="last")
        if key == "ì¢…ê°€â–¼" and "ì¢…ê°€" in dfv.columns:
            return dfv.sort_values("ì¢…ê°€", ascending=False, na_position="last")
    except Exception:
        pass
    # í´ë°±: ê°€ëŠ¥í•œ ì»¬ëŸ¼ ìš°ì„ ìˆœìœ„
    for alt in ["EBS","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","ì¢…ê°€"]:
        if alt in dfv.columns:
            return dfv.sort_values(alt, ascending=False, na_position="last")
    return dfv

view = safe_sort(view, sort_key)

# í‘œì‹œ ì»¬ëŸ¼
show_cols = [
    "í†µê³¼","ì‹œì¥","ì¢…ëª©ëª…","ì¢…ëª©ì½”ë“œ",
    "ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2",
    "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)",
    "EBS","ê·¼ê±°",
    "RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%"
]
if "EBS" in view.columns:
    view["í†µê³¼"] = np.where(view["EBS"]>=PASS_SCORE, "ğŸš€", "")

for c in show_cols:
    if c not in view.columns:
        view[c] = np.nan

st.write(f"ğŸ“‹ ì´ {len(latest_by_code):,}ê°œ / í‘œì‹œ {min(len(view), int(topn)):,}ê°œ")
st.dataframe(view[show_cols].head(int(topn)), width="stretch", height=640)

st.download_button(
    "ğŸ“¥ í˜„ì¬ ë³´ê¸° ë‹¤ìš´ë¡œë“œ (CSV)",
    data=view[show_cols].head(int(topn)).to_csv(index=False, encoding="utf-8-sig"),
    file_name="ldy_entry_candidates.csv",
    mime="text/csv"
)

with st.expander("â„¹ï¸ EBS êµ¬ì„±(ê¸‰ë“± ì´ˆì… ë¡œì§)", expanded=False):
    st.markdown(
        """
- ê¸°ë³¸ ì»·(collector ê¶Œì¥): ê±°ë˜ëŒ€ê¸ˆ â‰¥ **50ì–µì›**, ì‹œê°€ì´ì•¡ â‰¥ **1,000ì–µì›**
- ì ìˆ˜(0~7):
  1) RSI 45~65  
  2) MACD íˆìŠ¤í† ê·¸ë¨ ê¸°ìš¸ê¸° > 0  
  3) ì¢…ê°€ê°€ MA20 ê·¼ì²˜(-1%~+4%)  
  4) ìƒëŒ€ê±°ë˜ëŸ‰(20ì¼) > 1.2  
  5) MA20 ìƒìŠ¹(ê¸°ìš¸ê¸° > 0)  
  6) MACD íˆìŠ¤í† ê·¸ë¨ > 0  
  7) 5ì¼ ìˆ˜ìµë¥  < 10%(ê³¼ì—´ ë°©ì§€)  
- **í†µê³¼(ğŸš€ì´ˆì…)**: EBS â‰¥ 4  
- ì¶”ì²œê°€: ATR/MA ê¸°ë°˜ ë³´ìˆ˜ì  ê°€ì´ë“œ  
  - ì—”íŠ¸ë¦¬: MA20Â±0.5Ã—ATR ë²”ìœ„ ë‚´ ìŠ¤ëƒ…  
  - T1: +1.0Ã—ATR, T2: +1.8Ã—ATR, ì†ì ˆ: âˆ’1.2Ã—ATR
        """
    )
