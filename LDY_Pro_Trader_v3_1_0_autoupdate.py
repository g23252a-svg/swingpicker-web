# -*- coding: utf-8 -*-
"""
LDY Pro Trader v3.2.0 (Auto Update Viewer, self-enrich)
- GitHub raw CSVë¥¼ ìš°ì„  ë¡œë“œ, ì‹¤íŒ¨ ì‹œ ë¡œì»¬ data/recommend_latest.csv í´ë°±
- CSVê°€ ì›ì‹œ OHLCVë§Œ ìˆì–´ë„, ì´ í™”ë©´ì—ì„œ RSI/MACD/ATR/MA20/VolZ/ìˆ˜ìµë¥  ê³„ì‚° â†’ EBS/ì¶”ì²œê°€ ìƒì„±
- EBS ì»¬ëŸ¼ì´ ì—†ê±°ë‚˜ ì „ë¶€ NaNì´ë©´ 'ì´ˆì… í›„ë³´ë§Œ' í•„í„° ìë™ í•´ì œ
- ê±°ë˜ëŒ€ê¸ˆ(ì›)ë§Œ ìˆìœ¼ë©´ 'ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)'ìœ¼ë¡œ ìë™ ë³€í™˜
"""

import os, io, math, requests
import numpy as np
import pandas as pd
import streamlit as st

# ------------------------- ê¸°ë³¸ ì„¤ì • -------------------------
st.set_page_config(page_title="LDY Pro Trader v3.2.0 (Auto Update)", layout="wide")
st.title("ğŸ“ˆ LDY Pro Trader v3.2.0 (Auto Update)")
st.caption("ë§¤ì¼ ì¥ë§ˆê° í›„ ìë™ ì—…ë°ì´íŠ¸ë˜ëŠ” ìŠ¤ìœ™ ì¶”ì²œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ | Made by LDY")

RAW_URL = "https://raw.githubusercontent.com/g23252a-svg/swingpicker-web/main/data/recommend_latest.csv"
LOCAL_PATH = "data/recommend_latest.csv"
PASS_SCORE = 4

# ------------------------- ë¡œë”© -------------------------
@st.cache_data(ttl=300, show_spinner=False)
def load_remote_csv(url: str) -> pd.DataFrame:
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    return pd.read_csv(io.BytesIO(r.content))

@st.cache_data(ttl=300, show_spinner=False)
def load_local_csv(path: str) -> pd.DataFrame:
    return pd.read_csv(path)

def info_src(df: pd.DataFrame, src_text: str):
    st.info(f"ìƒíƒœ\nâœ… ë°ì´í„° ë¡œë“œ: {src_text}\n\n{RAW_URL if 'remote' in src_text else LOCAL_PATH}")
    st.success(f"ğŸ“… ì¶”ì²œ ê¸°ì¤€(í‘œì‹œ ì‹œê°): {pd.Timestamp.now(tz='Asia/Seoul').strftime('%Y-%m-%d %H:%M')} Â· ì›ì‹œ í–‰ìˆ˜: {len(df):,}")

# ------------------------- ì§€í‘œ ê³„ì‚° ìœ í‹¸ -------------------------
def ema(s: pd.Series, span: int):
    return s.ewm(span=span, adjust=False, min_periods=span).mean()

def rsi14(close: pd.Series, period: int = 14):
    delta = close.diff()
    gain = delta.clip(lower=0)
    loss = -delta.clip(upper=0)
    avg_gain = gain.rolling(period).mean()
    avg_loss = loss.rolling(period).mean()
    rs = avg_gain / avg_loss.replace(0, np.nan)
    out = 100 - (100 / (1 + rs))
    return out

def macd_features(close: pd.Series):
    ema12 = ema(close, 12)
    ema26 = ema(close, 26)
    macd_line = ema12 - ema26
    signal = macd_line.ewm(span=9, adjust=False, min_periods=9).mean()
    hist = macd_line - signal
    slope = hist.diff()  # íˆìŠ¤í† ê·¸ë¨ ê¸°ìš¸ê¸°
    return hist, slope

def atr14(high: pd.Series, low: pd.Series, close: pd.Series, period: int = 14):
    prev_close = close.shift(1)
    tr = pd.concat([
        (high - low),
        (high - prev_close).abs(),
        (low - prev_close).abs()
    ], axis=1).max(axis=1)
    return tr.rolling(period).mean()

# ------------------------- ìŠ¤í‚¤ë§ˆ ì •ë¦¬ -------------------------
def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    # ì»¬ëŸ¼ ì´ë¦„ í‘œì¤€í™”(ê°€ëŠ¥í•œ ë§¤í•‘)
    colmap = {
        "Date": "ë‚ ì§œ", "date": "ë‚ ì§œ",
        "Code": "ì¢…ëª©ì½”ë“œ", "í‹°ì»¤": "ì¢…ëª©ì½”ë“œ", "ticker": "ì¢…ëª©ì½”ë“œ",
        "Name": "ì¢…ëª©ëª…", "name": "ì¢…ëª©ëª…",
        "Open": "ì‹œê°€", "High": "ê³ ê°€", "Low": "ì €ê°€", "Close": "ì¢…ê°€",
        "Volume": "ê±°ë˜ëŸ‰",
        "ê±°ë˜ëŒ€ê¸ˆ": "ê±°ë˜ëŒ€ê¸ˆ(ì›)",
        "ì‹œê°€ì´ì•¡": "ì‹œê°€ì´ì•¡(ì›)"
    }
    for k, v in colmap.items():
        if k in df.columns and v not in df.columns:
            df = df.rename(columns={k: v})

    # ê±°ë˜ëŒ€ê¸ˆ(ì–µì›) ë§Œë“¤ê¸°
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" not in df.columns:
        if "ê±°ë˜ëŒ€ê¸ˆ(ì›)" in df.columns:
            df["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] = (pd.to_numeric(df["ê±°ë˜ëŒ€ê¸ˆ(ì›)"], errors="coerce") / 1e8).round(2)
        elif "ê±°ë˜ëŒ€ê¸ˆ" in df.columns:
            df["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] = (pd.to_numeric(df["ê±°ë˜ëŒ€ê¸ˆ"], errors="coerce") / 1e8).round(2)

    # ìˆ«ì ìºìŠ¤íŒ…
    for c in ["ì‹œê°€","ê³ ê°€","ì €ê°€","ì¢…ê°€","ê±°ë˜ëŸ‰","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")

    # ë‚ ì§œ ì²˜ë¦¬
    if "ë‚ ì§œ" in df.columns:
        try:
            df["ë‚ ì§œ"] = pd.to_datetime(df["ë‚ ì§œ"])
        except Exception:
            pass

    # í•„ìˆ˜ ê¸°ë³¸ ì»¬ëŸ¼ ë³´ê°•
    for c in ["ì‹œì¥","ì¢…ëª©ì½”ë“œ","ì¢…ëª©ëª…"]:
        if c not in df.columns:
            df[c] = None

    return df

# ------------------------- ì›ì‹œ OHLCV â†’ ìŠ¤ì½”ì–´/ì¶”ì²œê°€ ìƒì„± -------------------------
@st.cache_data(ttl=300, show_spinner=True)
def enrich_from_ohlcv(raw: pd.DataFrame) -> pd.DataFrame:
    # ìµœì†Œ í•„ìˆ˜: ë‚ ì§œ/ì½”ë“œ/ì‹œê°€/ê³ ê°€/ì €ê°€/ì¢…ê°€/ê±°ë˜ëŸ‰, (ê±°ë˜ëŒ€ê¸ˆ(ì–µì›) ê¶Œì¥)
    must_cols = {"ì¢…ëª©ì½”ë“œ", "ë‚ ì§œ", "ì‹œê°€", "ê³ ê°€", "ì €ê°€", "ì¢…ê°€"}
    if not must_cols.issubset(set(raw.columns)):
        return raw  # ëª» ë§Œë“¤ë©´ ì›ë³¸ ë°˜í™˜(ë·°ì–´ëŠ” ë³´í˜¸ ë¡œì§ìœ¼ë¡œ í‘œì‹œ)
    g = raw.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"]).groupby("ì¢…ëª©ì½”ë“œ", group_keys=False)

    def _feat(group: pd.DataFrame):
        group = group.copy()
        # ì§€í‘œ
        group["MA20"] = group["ì¢…ê°€"].rolling(20).mean()
        group["ATR14"] = atr14(group["ê³ ê°€"], group["ì €ê°€"], group["ì¢…ê°€"], 14)
        group["RSI14"] = rsi14(group["ì¢…ê°€"], 14)
        hist, slope = macd_features(group["ì¢…ê°€"])
        group["MACD_hist"] = hist
        group["MACD_slope"] = slope
        group["Vol_Z"] = (group["ê±°ë˜ëŸ‰"] - group["ê±°ë˜ëŸ‰"].rolling(20).mean()) / group["ê±°ë˜ëŸ‰"].rolling(20).std()
        group["ä¹–é›¢%"] = (group["ì¢…ê°€"] / group["MA20"] - 1.0) * 100.0
        group["ret_5d_%"] = (group["ì¢…ê°€"] / group["ì¢…ê°€"].shift(5) - 1.0) * 100.0
        group["ret_10d_%"] = (group["ì¢…ê°€"] / group["ì¢…ê°€"].shift(10) - 1.0) * 100.0

        # EBS 7ì ì œ
        last = group.iloc[-1:].copy()
        conds = []
        ebs = 0
        # 1) RSI 45~65
        c1 = 45 <= (last["RSI14"].iloc[0] if not last["RSI14"].isna().iloc[0] else -999) <= 65
        ebs += int(c1);  conds.append("RSI 45~65" if c1 else "")
        # 2) MACD slope > 0
        c2 = (last["MACD_slope"].iloc[0] if not last["MACD_slope"].isna().iloc[0] else -999) > 0
        ebs += int(c2);  conds.append("MACDâ†‘" if c2 else "")
        # 3) ì¢…ê°€ê°€ MA20 -1% ~ +4%
        close = last["ì¢…ê°€"].iloc[0]; ma20 = last["MA20"].iloc[0]
        c3 = (not np.isnan(ma20)) and (0.99*ma20 <= close <= 1.04*ma20)
        ebs += int(c3);  conds.append("MA20Â±4%" if c3 else "")
        # 4) Vol_Z > 1.2
        c4 = (last["Vol_Z"].iloc[0] if not last["Vol_Z"].isna().iloc[0] else -999) > 1.2
        ebs += int(c4);  conds.append("VolZ>1.2" if c4 else "")
        # 5) MA20 > MA60? (MA60 ì—†ìœ¼ë©´ MA20 ê¸°ìš¸ê¸°>0ë¡œ ëŒ€ì²´)
        ma20_slope = last["MA20"].iloc[0] - group["MA20"].iloc[-2] if len(group) >= 2 else np.nan
        c5 = (not np.isnan(ma20_slope)) and (ma20_slope > 0)
        ebs += int(c5);  conds.append("MA20â†‘" if c5 else "")
        # 6) MACD_hist > 0
        c6 = (last["MACD_hist"].iloc[0] if not last["MACD_hist"].isna().iloc[0] else -999) > 0
        ebs += int(c6);  conds.append("MACD>0" if c6 else "")
        # 7) 5ì¼ ìˆ˜ìµë¥  < 10% (ê³¼ì—´ ë°©ì§€)
        r5 = last["ret_5d_%"].iloc[0]
        c7 = (not np.isnan(r5)) and (r5 < 10)
        ebs += int(c7);  conds.append("5d<10%" if c7 else "")

        last["EBS"] = ebs
        last["ê·¼ê±°"] = " / ".join([c for c in conds if c])

        # ì¶”ì²œê°€ (ë³´ìˆ˜ì ): ì—”íŠ¸ë¦¬=MA20Â±0.5*ATR ë²”ìœ„ ë‚´ë¡œ ìŠ¤ëƒ…, T1=+1*ATR, T2=+1.8*ATR, ì†ì ˆ=-1.2*ATR
        atr = last["ATR14"].iloc[0]
        if np.isnan(atr) or np.isnan(ma20) or np.isnan(close) or atr <= 0:
            entry, t1, t2, stp = np.nan, np.nan, np.nan, np.nan
        else:
            band_low = ma20 - 0.5 * atr
            band_high = ma20 + 0.5 * atr
            entry = min(max(close, band_low), band_high)
            t1 = entry + 1.0 * atr
            t2 = entry + 1.8 * atr
            stp = entry - 1.2 * atr

        last["ì¶”ì²œë§¤ìˆ˜ê°€"] = round(entry, 2) if not np.isnan(entry) else np.nan
        last["ì¶”ì²œë§¤ë„ê°€1"] = round(t1, 2) if not np.isnan(t1) else np.nan
        last["ì¶”ì²œë§¤ë„ê°€2"] = round(t2, 2) if not np.isnan(t2) else np.nan
        last["ì†ì ˆê°€"] = round(stp, 2) if not np.isnan(stp) else np.nan

        return last

    out = g.apply(_feat).reset_index(drop=True)

    # ê±°ë˜ëŒ€ê¸ˆ(ì–µì›) ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ë‚  ê¸°ì¤€ ê·¸ë£¹í•©/í‰ê·  ë“±ìœ¼ë¡œ ì±„ìš°ê¸°(ê°€ëŠ¥í•œ ê²½ìš°)
    if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" not in out.columns and "ê±°ë˜ëŒ€ê¸ˆ(ì›)" in raw.columns:
        tv_last = raw.sort_values(["ì¢…ëª©ì½”ë“œ","ë‚ ì§œ"]).groupby("ì¢…ëª©ì½”ë“œ").tail(1)[["ì¢…ëª©ì½”ë“œ","ê±°ë˜ëŒ€ê¸ˆ(ì›)"]]
        tv_last["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] = (tv_last["ê±°ë˜ëŒ€ê¸ˆ(ì›)"]/1e8).round(2)
        out = out.merge(tv_last[["ì¢…ëª©ì½”ë“œ","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"]], on="ì¢…ëª©ì½”ë“œ", how="left")

    # ì‹œì´(ì–µì›) ì—†ìœ¼ë©´ NaN ìœ ì§€(collectorì—ì„œ ì±„ìš°ëŠ” ê±¸ ê¶Œì¥)
    if "ì‹œê°€ì´ì•¡(ì–µì›)" not in out.columns:
        out["ì‹œê°€ì´ì•¡(ì–µì›)"] = np.nan
    # ì‹œì¥ ì—†ìœ¼ë©´ ALLë¡œ
    if "ì‹œì¥" not in out.columns:
        out["ì‹œì¥"] = "ALL"

    return out

# ------------------------- ë°ì´í„° ë¡œë“œ & ì •ê·œí™” -------------------------
try:
    df_raw = load_remote_csv(RAW_URL)
    info_src(df_raw, "remote")
except Exception:
    if os.path.exists(LOCAL_PATH):
        df_raw = load_local_csv(LOCAL_PATH)
        info_src(df_raw, "local")
    else:
        st.error("âŒ CSVë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. collectorê°€ data/recommend_latest.csvë¥¼ ì˜¬ë ¸ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

df_raw = normalize_columns(df_raw)

# ------------------------- ìŠ¤í‚¤ë§ˆ ê°ì§€: EBS/ì¶”ì²œê°€ê°€ ìˆë‚˜? -------------------------
has_ebs = "EBS" in df_raw.columns and df_raw["EBS"].notna().any()
has_reco = all(c in df_raw.columns for c in ["ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]) and df_raw[["ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]].notna().any().any()

if has_ebs and has_reco:
    df = df_raw.copy()
else:
    # ì›ì‹œ OHLCVì—ì„œ ìŠ¤ìŠ¤ë¡œ ìƒì„±
    with st.status("ğŸ§® ì›ì‹œ OHLCV â†’ ì§€í‘œ/ì ìˆ˜/ì¶”ì²œê°€ ìƒì„± ì¤‘...", expanded=False):
        df = enrich_from_ohlcv(df_raw)

# ë‹¹ì¼(ë˜ëŠ” ìµœì‹ ì¼) í•œ ì¤„ ìš”ì•½ ë·° ë§Œë“¤ê¸°
if "ë‚ ì§œ" in df.columns:
    latest_by_code = df.sort_values(["ì¢…ëª©ì½”ë“œ", "ë‚ ì§œ"]).groupby("ì¢…ëª©ì½”ë“œ").tail(1).copy()
else:
    latest_by_code = df.copy()

# ìµœì¢… ì•ˆì „ ìºìŠ¤íŒ…
for c in ["ì¢…ê°€","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)","RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%","EBS","ì¶”ì²œë§¤ìˆ˜ê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2","ì†ì ˆê°€"]:
    if c in latest_by_code.columns:
        latest_by_code[c] = pd.to_numeric(latest_by_code[c], errors="coerce")

# ------------------------- UI: í•„í„°/ì •ë ¬ -------------------------
with st.expander("ğŸ” ë³´ê¸°/í•„í„°", expanded=True):
    c1, c2, c3, c4, c5 = st.columns([1,1,1,1,2])
    # EBS ëª¨ë‘ NaNì´ë©´ ìë™ í•´ì œ
    default_entry = True
    if "EBS" not in latest_by_code.columns or latest_by_code["EBS"].notna().sum() == 0:
        default_entry = False
        st.warning("EBS ì ìˆ˜ê°€ ì—†ì–´ â€˜ğŸš€ ì´ˆì… í›„ë³´ë§Œâ€™ í•„í„°ë¥¼ ìë™ í•´ì œí•©ë‹ˆë‹¤. (ì›ì‹œ OHLCVì—ì„œ ê³„ì‚° ì‹¤íŒ¨ ë˜ëŠ” ë°ì´í„° ë¶€ì¡±)")
    with c1:
        only_entry = st.checkbox("ğŸš€ ì´ˆì… í›„ë³´ë§Œ (EBSâ‰¥4)", value=default_entry)
    with c2:
        min_turn = st.slider("ìµœì†Œ ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", 0, 5000, 50, step=10)
    with c3:
        sort_key = st.selectbox(
            "ì •ë ¬",
            ["EBSâ–¼", "ê±°ë˜ëŒ€ê¸ˆâ–¼", "ì‹œê°€ì´ì•¡â–¼", "RSIâ–²", "RSIâ–¼", "ì¢…ê°€â–²", "ì¢…ê°€â–¼"],
            index=0 if "EBS" in latest_by_code.columns else 1
        )
    with c4:
        topn = st.slider("í‘œì‹œ ìˆ˜(Top N)", 10, 500, 200, step=10)
    with c5:
        q_text = st.text_input("ğŸ” ì¢…ëª©ëª…/ì½”ë“œ ê²€ìƒ‰", value="", placeholder="ì˜ˆ: ì‚¼ì„±ì „ì ë˜ëŠ” 005930")

view = latest_by_code.copy()

# ì¢…ëª©ëª… ì—†ìœ¼ë©´ ì½”ë“œë§Œ í‘œì‹œ(ì´ë¦„ì€ collectorì—ì„œ ë§µíŒŒì¼ ìƒì„± ê¶Œì¥)
if "ì¢…ëª©ëª…" not in view.columns or view["ì¢…ëª©ëª…"].isna().all():
    view["ì¢…ëª©ëª…"] = "(ì´ë¦„ì—†ìŒ)"

# í•„í„°ë“¤
if only_entry and "EBS" in view.columns:
    view = view[view["EBS"] >= PASS_SCORE]
if "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in view.columns:
    view = view[view["ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"] >= float(min_turn)]

if q_text:
    q = q_text.strip().lower()
    name_hit = view["ì¢…ëª©ëª…"].fillna("").astype(str).str.lower().str.contains(q, na=False)
    code_hit = view["ì¢…ëª©ì½”ë“œ"].fillna("").astype(str).str.contains(q, na=False)
    view = view[name_hit | code_hit]

# ì •ë ¬
if sort_key == "EBSâ–¼" and "EBS" in view.columns:
    view = view.sort_values(["EBS","ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)"], ascending=[False, False])
elif sort_key == "ê±°ë˜ëŒ€ê¸ˆâ–¼" and "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)" in view.columns:
    view = view.sort_values("ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)", ascending=False)
elif sort_key == "ì‹œê°€ì´ì•¡â–¼" and "ì‹œê°€ì´ì•¡(ì–µì›)" in view.columns:
    view = view.sort_values("ì‹œê°€ì´ì•¡(ì–µì›)", ascending=False, na_position="last")
elif sort_key == "RSIâ–²" and "RSI14" in view.columns:
    view = view.sort_values("RSI14", ascending=True, na_position="last")
elif sort_key == "RSIâ–¼" and "RSI14" in view.columns:
    view = view.sort_values("RSI14", ascending=False, na_position="last")
elif sort_key == "ì¢…ê°€â–²" and "ì¢…ê°€" in view.columns:
    view = view.sort_values("ì¢…ê°€", ascending=True, na_position="last")
elif sort_key == "ì¢…ê°€â–¼" and "ì¢…ê°€" in view.columns:
    view = view.sort_values("ì¢…ê°€", ascending=False, na_position="last")

# ------------------------- í‘œ ì¶œë ¥ -------------------------
show_cols = [
    "í†µê³¼","ì‹œì¥","ì¢…ëª©ëª…","ì¢…ëª©ì½”ë“œ",
    "ì¢…ê°€","ì¶”ì²œë§¤ìˆ˜ê°€","ì†ì ˆê°€","ì¶”ì²œë§¤ë„ê°€1","ì¶”ì²œë§¤ë„ê°€2",
    "ê±°ë˜ëŒ€ê¸ˆ(ì–µì›)","ì‹œê°€ì´ì•¡(ì–µì›)",
    "EBS","ê·¼ê±°",
    "RSI14","ä¹–é›¢%","MACD_hist","MACD_slope","Vol_Z","ret_5d_%","ret_10d_%"
]
# í†µê³¼ í‘œì‹œ
if "EBS" in view.columns:
    view["í†µê³¼"] = np.where(view["EBS"] >= PASS_SCORE, "ğŸš€", "")

# ëˆ„ë½ ì»¬ëŸ¼ ì±„ì›€
for c in show_cols:
    if c not in view.columns:
        view[c] = np.nan

st.write(f"ğŸ“‹ ì´ {len(latest_by_code):,}ê°œ / í‘œì‹œ {min(len(view), int(topn)):,}ê°œ")
st.dataframe(view[show_cols].head(int(topn)), width="stretch", height=640)

# ------------------------- ë‹¤ìš´ë¡œë“œ -------------------------
st.download_button(
    "ğŸ“¥ í˜„ì¬ ë³´ê¸° ë‹¤ìš´ë¡œë“œ (CSV)",
    data=view[show_cols].head(int(topn)).to_csv(index=False, encoding="utf-8-sig"),
    file_name="ldy_entry_candidates.csv",
    mime="text/csv"
)

with st.expander("â„¹ï¸ EBS êµ¬ì„±(ê¸‰ë“± ì´ˆì… ë¡œì§)", expanded=False):
    st.markdown(
        """
- ê¸°ë³¸ ì»·(collector ê¶Œì¥): ê±°ë˜ëŒ€ê¸ˆ â‰¥ **50ì–µì›**, ì‹œê°€ì´ì•¡ â‰¥ **1,000ì–µì›**
- ì ìˆ˜(0~7):
  1) RSI 45~65  
  2) MACD íˆìŠ¤í† ê·¸ë¨ ê¸°ìš¸ê¸° > 0  
  3) ì¢…ê°€ê°€ MA20 ê·¼ì²˜(-1%~+4%)  
  4) ìƒëŒ€ê±°ë˜ëŸ‰(20ì¼) > 1.2  
  5) MA20 ìƒìŠ¹(ê¸°ìš¸ê¸° > 0)  
  6) MACD íˆìŠ¤í† ê·¸ë¨ > 0  
  7) 5ì¼ ìˆ˜ìµë¥  < 10%(ê³¼ì—´ ë°©ì§€)  
- **í†µê³¼(ğŸš€ì´ˆì…)**: EBS â‰¥ 4  
- ì¶”ì²œê°€: ATR/MA ê¸°ë°˜ ë³´ìˆ˜ì  ê°€ì´ë“œ (ì—”íŠ¸ë¦¬ = MA20Â±0.5*ATR ë²”ìœ„ ë‚´ ìŠ¤ëƒ…, T1=+1*ATR, T2=+1.8*ATR, ì†ì ˆ=-1.2*ATR)
        """
    )
